15:07:20 Log file: logs/train_20250524_150720.log
15:07:52 ✔ Data split: 1958081/279725/559453 rows ➜ splits
15:07:54 train.csv: samples=1957961  class_dist=[609313 731512 617256]
15:07:55 val.csv: samples=279605  class_dist=[90467 94550 94708]
15:07:56 test.csv: samples=559333  class_dist=[183495 190446 185512]
15:08:01 [train] batch 200/7649 | loss 1.0480 | acc 0.3262
15:08:04 [train] batch 400/7649 | loss 1.0314 | acc 0.3208
15:08:07 [train] batch 600/7649 | loss 1.0263 | acc 0.3184
15:08:10 [train] batch 800/7649 | loss 1.0223 | acc 0.3185
15:08:13 [train] batch 1000/7649 | loss 1.0195 | acc 0.3185
15:08:17 [train] batch 1200/7649 | loss 1.0177 | acc 0.3187
15:08:20 [train] batch 1400/7649 | loss 1.0163 | acc 0.3190
15:08:23 [train] batch 1600/7649 | loss 1.0151 | acc 0.3190
15:08:26 [train] batch 1800/7649 | loss 1.0140 | acc 0.3194
15:08:30 [train] batch 2000/7649 | loss 1.0134 | acc 0.3194
15:08:33 [train] batch 2200/7649 | loss 1.0129 | acc 0.3192
15:08:36 [train] batch 2400/7649 | loss 1.0124 | acc 0.3191
15:08:39 [train] batch 2600/7649 | loss 1.0119 | acc 0.3191
15:08:43 [train] batch 2800/7649 | loss 1.0115 | acc 0.3192
15:08:46 [train] batch 3000/7649 | loss 1.0110 | acc 0.3194
15:08:49 [train] batch 3200/7649 | loss 1.0105 | acc 0.3197
15:08:53 [train] batch 3400/7649 | loss 1.0100 | acc 0.3199
15:08:56 [train] batch 3600/7649 | loss 1.0097 | acc 0.3201
15:08:59 [train] batch 3800/7649 | loss 1.0094 | acc 0.3201
15:09:02 [train] batch 4000/7649 | loss 1.0092 | acc 0.3201
15:09:06 [train] batch 4200/7649 | loss 1.0090 | acc 0.3201
15:09:09 [train] batch 4400/7649 | loss 1.0089 | acc 0.3202
15:09:12 [train] batch 4600/7649 | loss 1.0086 | acc 0.3203
15:09:15 [train] batch 4800/7649 | loss 1.0085 | acc 0.3203
15:09:19 [train] batch 5000/7649 | loss 1.0082 | acc 0.3205
15:09:22 [train] batch 5200/7649 | loss 1.0079 | acc 0.3205
15:09:25 [train] batch 5400/7649 | loss 1.0078 | acc 0.3207
15:09:28 [train] batch 5600/7649 | loss 1.0076 | acc 0.3208
15:09:32 [train] batch 5800/7649 | loss 1.0075 | acc 0.3209
15:09:35 [train] batch 6000/7649 | loss 1.0074 | acc 0.3210
15:09:38 [train] batch 6200/7649 | loss 1.0072 | acc 0.3210
15:09:42 [train] batch 6400/7649 | loss 1.0071 | acc 0.3211
15:09:45 [train] batch 6600/7649 | loss 1.0068 | acc 0.3213
15:09:48 [train] batch 6800/7649 | loss 1.0067 | acc 0.3213
15:09:51 [train] batch 7000/7649 | loss 1.0066 | acc 0.3214
15:09:55 [train] batch 7200/7649 | loss 1.0065 | acc 0.3213
15:09:58 [train] batch 7400/7649 | loss 1.0064 | acc 0.3214
15:10:01 [train] batch 7600/7649 | loss 1.0063 | acc 0.3216
15:10:02 [train] batch 7649/7649 | loss 1.0062 | acc 0.3216
15:10:09 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_01.png
15:10:09 Epoch 01 | train 1.0062/0.3216 | val 0.9827/0.3428 | lr 1.00e-05
15:10:09 ✓ save best
15:10:12 [train] batch 200/7649 | loss 1.0026 | acc 0.3230
15:10:16 [train] batch 400/7649 | loss 1.0022 | acc 0.3247
15:10:19 [train] batch 600/7649 | loss 1.0020 | acc 0.3256
15:10:22 [train] batch 800/7649 | loss 1.0016 | acc 0.3260
15:10:25 [train] batch 1000/7649 | loss 1.0016 | acc 0.3260
15:10:29 [train] batch 1200/7649 | loss 1.0016 | acc 0.3262
15:10:32 [train] batch 1400/7649 | loss 1.0017 | acc 0.3257
15:10:35 [train] batch 1600/7649 | loss 1.0017 | acc 0.3259
15:10:39 [train] batch 1800/7649 | loss 1.0021 | acc 0.3255
15:10:42 [train] batch 2000/7649 | loss 1.0022 | acc 0.3253
15:10:45 [train] batch 2200/7649 | loss 1.0021 | acc 0.3253
15:10:48 [train] batch 2400/7649 | loss 1.0021 | acc 0.3255
15:10:52 [train] batch 2600/7649 | loss 1.0021 | acc 0.3256
15:10:55 [train] batch 2800/7649 | loss 1.0020 | acc 0.3256
15:10:59 [train] batch 3000/7649 | loss 1.0021 | acc 0.3256
15:11:02 [train] batch 3200/7649 | loss 1.0021 | acc 0.3255
15:11:05 [train] batch 3400/7649 | loss 1.0020 | acc 0.3257
15:11:08 [train] batch 3600/7649 | loss 1.0020 | acc 0.3258
15:11:12 [train] batch 3800/7649 | loss 1.0021 | acc 0.3258
15:11:15 [train] batch 4000/7649 | loss 1.0020 | acc 0.3259
15:11:18 [train] batch 4200/7649 | loss 1.0020 | acc 0.3260
15:11:21 [train] batch 4400/7649 | loss 1.0019 | acc 0.3261
15:11:25 [train] batch 4600/7649 | loss 1.0019 | acc 0.3262
15:11:28 [train] batch 4800/7649 | loss 1.0019 | acc 0.3262
15:11:31 [train] batch 5000/7649 | loss 1.0018 | acc 0.3264
15:11:35 [train] batch 5200/7649 | loss 1.0019 | acc 0.3264
15:11:38 [train] batch 5400/7649 | loss 1.0019 | acc 0.3263
15:11:41 [train] batch 5600/7649 | loss 1.0019 | acc 0.3263
15:11:44 [train] batch 5800/7649 | loss 1.0018 | acc 0.3264
15:11:48 [train] batch 6000/7649 | loss 1.0018 | acc 0.3265
15:11:51 [train] batch 6200/7649 | loss 1.0018 | acc 0.3264
15:11:54 [train] batch 6400/7649 | loss 1.0018 | acc 0.3265
15:11:58 [train] batch 6600/7649 | loss 1.0017 | acc 0.3266
15:12:01 [train] batch 6800/7649 | loss 1.0017 | acc 0.3267
15:12:04 [train] batch 7000/7649 | loss 1.0016 | acc 0.3268
15:12:08 [train] batch 7200/7649 | loss 1.0016 | acc 0.3269
15:12:11 [train] batch 7400/7649 | loss 1.0016 | acc 0.3269
15:12:14 [train] batch 7600/7649 | loss 1.0016 | acc 0.3269
15:12:15 [train] batch 7649/7649 | loss 1.0016 | acc 0.3269
15:12:22 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_02.png
15:12:22 Epoch 02 | train 1.0016/0.3269 | val 0.9830/0.3439 | lr 1.00e-05
15:12:22 ✓ save best
15:12:25 [train] batch 200/7649 | loss 1.0014 | acc 0.3265
15:12:28 [train] batch 400/7649 | loss 1.0022 | acc 0.3268
15:12:32 [train] batch 600/7649 | loss 1.0019 | acc 0.3274
15:12:35 [train] batch 800/7649 | loss 1.0014 | acc 0.3275
15:12:38 [train] batch 1000/7649 | loss 1.0014 | acc 0.3273
15:12:42 [train] batch 1200/7649 | loss 1.0016 | acc 0.3272
15:12:45 [train] batch 1400/7649 | loss 1.0013 | acc 0.3276
15:12:48 [train] batch 1600/7649 | loss 1.0012 | acc 0.3281
15:12:52 [train] batch 1800/7649 | loss 1.0012 | acc 0.3285
15:12:55 [train] batch 2000/7649 | loss 1.0011 | acc 0.3286
15:12:58 [train] batch 2200/7649 | loss 1.0009 | acc 0.3289
15:13:01 [train] batch 2400/7649 | loss 1.0010 | acc 0.3286
15:13:05 [train] batch 2600/7649 | loss 1.0009 | acc 0.3288
15:13:08 [train] batch 2800/7649 | loss 1.0010 | acc 0.3286
15:13:12 [train] batch 3000/7649 | loss 1.0009 | acc 0.3287
15:13:15 [train] batch 3200/7649 | loss 1.0010 | acc 0.3286
15:13:18 [train] batch 3400/7649 | loss 1.0009 | acc 0.3286
15:13:21 [train] batch 3600/7649 | loss 1.0008 | acc 0.3287
15:13:25 [train] batch 3800/7649 | loss 1.0009 | acc 0.3287
15:13:28 [train] batch 4000/7649 | loss 1.0010 | acc 0.3288
15:13:31 [train] batch 4200/7649 | loss 1.0009 | acc 0.3288
15:13:34 [train] batch 4400/7649 | loss 1.0009 | acc 0.3290
15:13:38 [train] batch 4600/7649 | loss 1.0008 | acc 0.3291
15:13:41 [train] batch 4800/7649 | loss 1.0009 | acc 0.3291
15:13:44 [train] batch 5000/7649 | loss 1.0009 | acc 0.3291
15:13:48 [train] batch 5200/7649 | loss 1.0008 | acc 0.3290
15:13:51 [train] batch 5400/7649 | loss 1.0009 | acc 0.3290
15:13:54 [train] batch 5600/7649 | loss 1.0009 | acc 0.3290
15:13:57 [train] batch 5800/7649 | loss 1.0008 | acc 0.3291
15:14:01 [train] batch 6000/7649 | loss 1.0007 | acc 0.3292
15:14:04 [train] batch 6200/7649 | loss 1.0007 | acc 0.3293
15:14:07 [train] batch 6400/7649 | loss 1.0007 | acc 0.3293
15:14:11 [train] batch 6600/7649 | loss 1.0007 | acc 0.3293
15:14:14 [train] batch 6800/7649 | loss 1.0007 | acc 0.3293
15:14:17 [train] batch 7000/7649 | loss 1.0007 | acc 0.3293
15:14:21 [train] batch 7200/7649 | loss 1.0007 | acc 0.3293
15:14:24 [train] batch 7400/7649 | loss 1.0007 | acc 0.3293
15:14:27 [train] batch 7600/7649 | loss 1.0007 | acc 0.3293
15:14:28 [train] batch 7649/7649 | loss 1.0006 | acc 0.3294
15:14:35 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_03.png
15:14:35 Epoch 03 | train 1.0006/0.3294 | val 0.9825/0.3464 | lr 1.00e-05
15:14:35 ✓ save best
15:14:38 [train] batch 200/7649 | loss 1.0013 | acc 0.3321
15:14:41 [train] batch 400/7649 | loss 1.0009 | acc 0.3307
15:14:45 [train] batch 600/7649 | loss 1.0004 | acc 0.3301
15:14:48 [train] batch 800/7649 | loss 1.0005 | acc 0.3314
15:14:51 [train] batch 1000/7649 | loss 1.0008 | acc 0.3308
15:14:55 [train] batch 1200/7649 | loss 1.0008 | acc 0.3304
15:14:58 [train] batch 1400/7649 | loss 1.0005 | acc 0.3304
15:15:01 [train] batch 1600/7649 | loss 1.0007 | acc 0.3303
15:15:04 [train] batch 1800/7649 | loss 1.0007 | acc 0.3303
15:15:08 [train] batch 2000/7649 | loss 1.0008 | acc 0.3300
15:15:11 [train] batch 2200/7649 | loss 1.0008 | acc 0.3300
15:15:15 [train] batch 2400/7649 | loss 1.0007 | acc 0.3298
15:15:18 [train] batch 2600/7649 | loss 1.0007 | acc 0.3298
15:15:21 [train] batch 2800/7649 | loss 1.0006 | acc 0.3299
15:15:24 [train] batch 3000/7649 | loss 1.0005 | acc 0.3300
15:15:28 [train] batch 3200/7649 | loss 1.0004 | acc 0.3302
15:15:31 [train] batch 3400/7649 | loss 1.0003 | acc 0.3302
15:15:34 [train] batch 3600/7649 | loss 1.0004 | acc 0.3301
15:15:38 [train] batch 3800/7649 | loss 1.0004 | acc 0.3300
15:15:41 [train] batch 4000/7649 | loss 1.0002 | acc 0.3302
15:15:44 [train] batch 4200/7649 | loss 1.0002 | acc 0.3303
15:15:47 [train] batch 4400/7649 | loss 1.0001 | acc 0.3303
15:15:51 [train] batch 4600/7649 | loss 1.0001 | acc 0.3304
15:15:54 [train] batch 4800/7649 | loss 1.0001 | acc 0.3305
15:15:57 [train] batch 5000/7649 | loss 1.0000 | acc 0.3305
15:16:01 [train] batch 5200/7649 | loss 1.0002 | acc 0.3304
15:16:04 [train] batch 5400/7649 | loss 1.0001 | acc 0.3306
15:16:07 [train] batch 5600/7649 | loss 1.0002 | acc 0.3306
15:16:11 [train] batch 5800/7649 | loss 1.0001 | acc 0.3307
15:16:14 [train] batch 6000/7649 | loss 1.0001 | acc 0.3307
15:16:17 [train] batch 6200/7649 | loss 1.0001 | acc 0.3308
15:16:21 [train] batch 6400/7649 | loss 1.0001 | acc 0.3310
15:16:24 [train] batch 6600/7649 | loss 1.0000 | acc 0.3310
15:16:27 [train] batch 6800/7649 | loss 1.0000 | acc 0.3311
15:16:30 [train] batch 7000/7649 | loss 1.0000 | acc 0.3311
15:16:34 [train] batch 7200/7649 | loss 1.0000 | acc 0.3310
15:16:37 [train] batch 7400/7649 | loss 1.0000 | acc 0.3310
15:16:40 [train] batch 7600/7649 | loss 1.0000 | acc 0.3310
15:16:41 [train] batch 7649/7649 | loss 1.0000 | acc 0.3311
15:16:48 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_04.png
15:16:48 Epoch 04 | train 1.0000/0.3311 | val 0.9823/0.3481 | lr 1.00e-05
15:16:48 ✓ save best
15:16:51 [train] batch 200/7649 | loss 1.0002 | acc 0.3297
15:16:55 [train] batch 400/7649 | loss 0.9997 | acc 0.3306
15:16:58 [train] batch 600/7649 | loss 1.0006 | acc 0.3304
15:17:01 [train] batch 800/7649 | loss 1.0006 | acc 0.3306
15:17:05 [train] batch 1000/7649 | loss 1.0005 | acc 0.3308
15:17:08 [train] batch 1200/7649 | loss 1.0005 | acc 0.3308
15:17:11 [train] batch 1400/7649 | loss 1.0006 | acc 0.3306
15:17:14 [train] batch 1600/7649 | loss 1.0003 | acc 0.3313
15:17:18 [train] batch 1800/7649 | loss 1.0002 | acc 0.3311
15:17:21 [train] batch 2000/7649 | loss 1.0002 | acc 0.3310
15:17:25 [train] batch 2200/7649 | loss 1.0001 | acc 0.3312
15:17:28 [train] batch 2400/7649 | loss 1.0001 | acc 0.3312
15:17:31 [train] batch 2600/7649 | loss 1.0001 | acc 0.3313
15:17:35 [train] batch 2800/7649 | loss 1.0001 | acc 0.3313
15:17:38 [train] batch 3000/7649 | loss 1.0001 | acc 0.3312
15:17:41 [train] batch 3200/7649 | loss 1.0001 | acc 0.3311
15:17:44 [train] batch 3400/7649 | loss 1.0000 | acc 0.3310
15:17:48 [train] batch 3600/7649 | loss 1.0000 | acc 0.3310
15:17:51 [train] batch 3800/7649 | loss 0.9999 | acc 0.3313
15:17:54 [train] batch 4000/7649 | loss 1.0000 | acc 0.3314
15:17:58 [train] batch 4200/7649 | loss 0.9998 | acc 0.3316
15:18:01 [train] batch 4400/7649 | loss 0.9998 | acc 0.3318
15:18:04 [train] batch 4600/7649 | loss 0.9998 | acc 0.3319
15:18:07 [train] batch 4800/7649 | loss 0.9997 | acc 0.3318
15:18:11 [train] batch 5000/7649 | loss 0.9996 | acc 0.3319
15:18:14 [train] batch 5200/7649 | loss 0.9996 | acc 0.3320
15:18:17 [train] batch 5400/7649 | loss 0.9997 | acc 0.3318
15:18:21 [train] batch 5600/7649 | loss 0.9996 | acc 0.3319
15:18:24 [train] batch 5800/7649 | loss 0.9996 | acc 0.3320
15:18:27 [train] batch 6000/7649 | loss 0.9995 | acc 0.3321
15:18:31 [train] batch 6200/7649 | loss 0.9996 | acc 0.3321
15:18:34 [train] batch 6400/7649 | loss 0.9995 | acc 0.3321
15:18:37 [train] batch 6600/7649 | loss 0.9995 | acc 0.3321
15:18:40 [train] batch 6800/7649 | loss 0.9996 | acc 0.3319
15:18:44 [train] batch 7000/7649 | loss 0.9995 | acc 0.3319
15:18:47 [train] batch 7200/7649 | loss 0.9995 | acc 0.3319
15:18:50 [train] batch 7400/7649 | loss 0.9995 | acc 0.3319
15:18:54 [train] batch 7600/7649 | loss 0.9996 | acc 0.3318
15:18:54 [train] batch 7649/7649 | loss 0.9996 | acc 0.3318
15:19:01 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_05.png
15:19:01 Epoch 05 | train 0.9996/0.3318 | val 0.9828/0.3479 | lr 1.00e-05
15:19:05 [train] batch 200/7649 | loss 1.0010 | acc 0.3317
15:19:08 [train] batch 400/7649 | loss 0.9989 | acc 0.3340
15:19:11 [train] batch 600/7649 | loss 0.9985 | acc 0.3346
15:19:14 [train] batch 800/7649 | loss 0.9991 | acc 0.3335
15:19:18 [train] batch 1000/7649 | loss 0.9994 | acc 0.3331
15:19:21 [train] batch 1200/7649 | loss 0.9996 | acc 0.3326
15:19:24 [train] batch 1400/7649 | loss 0.9999 | acc 0.3324
15:19:28 [train] batch 1600/7649 | loss 0.9994 | acc 0.3325
15:19:31 [train] batch 1800/7649 | loss 0.9996 | acc 0.3321
15:19:35 [train] batch 2000/7649 | loss 0.9999 | acc 0.3321
15:19:38 [train] batch 2200/7649 | loss 0.9996 | acc 0.3325
15:19:41 [train] batch 2400/7649 | loss 0.9995 | acc 0.3322
15:19:44 [train] batch 2600/7649 | loss 0.9995 | acc 0.3322
15:19:48 [train] batch 2800/7649 | loss 0.9994 | acc 0.3323
15:19:51 [train] batch 3000/7649 | loss 0.9995 | acc 0.3323
15:19:54 [train] batch 3200/7649 | loss 0.9994 | acc 0.3327
15:19:58 [train] batch 3400/7649 | loss 0.9993 | acc 0.3328
15:20:01 [train] batch 3600/7649 | loss 0.9992 | acc 0.3330
15:20:04 [train] batch 3800/7649 | loss 0.9992 | acc 0.3330
15:20:07 [train] batch 4000/7649 | loss 0.9992 | acc 0.3331
15:20:11 [train] batch 4200/7649 | loss 0.9992 | acc 0.3331
15:20:14 [train] batch 4400/7649 | loss 0.9992 | acc 0.3332
15:20:17 [train] batch 4600/7649 | loss 0.9992 | acc 0.3332
15:20:21 [train] batch 4800/7649 | loss 0.9993 | acc 0.3331
15:20:24 [train] batch 5000/7649 | loss 0.9993 | acc 0.3331
15:20:27 [train] batch 5200/7649 | loss 0.9993 | acc 0.3331
15:20:31 [train] batch 5400/7649 | loss 0.9993 | acc 0.3331
15:20:34 [train] batch 5600/7649 | loss 0.9993 | acc 0.3332
15:20:37 [train] batch 5800/7649 | loss 0.9993 | acc 0.3332
15:20:41 [train] batch 6000/7649 | loss 0.9992 | acc 0.3332
15:20:44 [train] batch 6200/7649 | loss 0.9993 | acc 0.3332
15:20:47 [train] batch 6400/7649 | loss 0.9993 | acc 0.3332
15:20:50 [train] batch 6600/7649 | loss 0.9993 | acc 0.3331
15:20:54 [train] batch 6800/7649 | loss 0.9993 | acc 0.3331
15:20:57 [train] batch 7000/7649 | loss 0.9993 | acc 0.3330
15:21:00 [train] batch 7200/7649 | loss 0.9992 | acc 0.3331
15:21:04 [train] batch 7400/7649 | loss 0.9992 | acc 0.3331
15:21:07 [train] batch 7600/7649 | loss 0.9992 | acc 0.3332
15:21:08 [train] batch 7649/7649 | loss 0.9992 | acc 0.3332
15:21:14 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_06.png
15:21:14 Epoch 06 | train 0.9992/0.3332 | val 0.9830/0.3485 | lr 1.00e-05
15:21:14 ✓ save best
15:21:18 [train] batch 200/7649 | loss 1.0000 | acc 0.3310
15:21:21 [train] batch 400/7649 | loss 0.9986 | acc 0.3335
15:21:24 [train] batch 600/7649 | loss 0.9986 | acc 0.3338
15:21:28 [train] batch 800/7649 | loss 0.9990 | acc 0.3332
15:21:31 [train] batch 1000/7649 | loss 0.9993 | acc 0.3332
15:21:35 [train] batch 1200/7649 | loss 0.9994 | acc 0.3333
15:21:38 [train] batch 1400/7649 | loss 0.9996 | acc 0.3327
15:21:41 [train] batch 1600/7649 | loss 0.9996 | acc 0.3329
15:21:45 [train] batch 1800/7649 | loss 0.9994 | acc 0.3332
15:21:48 [train] batch 2000/7649 | loss 0.9992 | acc 0.3334
15:21:51 [train] batch 2200/7649 | loss 0.9994 | acc 0.3332
15:21:54 [train] batch 2400/7649 | loss 0.9994 | acc 0.3331
15:21:58 [train] batch 2600/7649 | loss 0.9992 | acc 0.3335
15:22:01 [train] batch 2800/7649 | loss 0.9993 | acc 0.3334
15:22:04 [train] batch 3000/7649 | loss 0.9991 | acc 0.3337
15:22:07 [train] batch 3200/7649 | loss 0.9992 | acc 0.3334
15:22:11 [train] batch 3400/7649 | loss 0.9992 | acc 0.3333
15:22:14 [train] batch 3600/7649 | loss 0.9992 | acc 0.3333
15:22:17 [train] batch 3800/7649 | loss 0.9991 | acc 0.3334
15:22:21 [train] batch 4000/7649 | loss 0.9991 | acc 0.3333
15:22:24 [train] batch 4200/7649 | loss 0.9991 | acc 0.3334
15:22:27 [train] batch 4400/7649 | loss 0.9992 | acc 0.3332
15:22:31 [train] batch 4600/7649 | loss 0.9992 | acc 0.3333
15:22:34 [train] batch 4800/7649 | loss 0.9993 | acc 0.3332
15:22:37 [train] batch 5000/7649 | loss 0.9993 | acc 0.3331
15:22:40 [train] batch 5200/7649 | loss 0.9993 | acc 0.3332
15:22:44 [train] batch 5400/7649 | loss 0.9992 | acc 0.3334
15:22:47 [train] batch 5600/7649 | loss 0.9991 | acc 0.3335
15:22:50 [train] batch 5800/7649 | loss 0.9991 | acc 0.3335
15:22:54 [train] batch 6000/7649 | loss 0.9991 | acc 0.3336
15:22:57 [train] batch 6200/7649 | loss 0.9992 | acc 0.3336
15:23:00 [train] batch 6400/7649 | loss 0.9991 | acc 0.3336
15:23:04 [train] batch 6600/7649 | loss 0.9991 | acc 0.3336
15:23:07 [train] batch 6800/7649 | loss 0.9990 | acc 0.3337
15:23:10 [train] batch 7000/7649 | loss 0.9990 | acc 0.3337
15:23:13 [train] batch 7200/7649 | loss 0.9989 | acc 0.3337
15:23:17 [train] batch 7400/7649 | loss 0.9989 | acc 0.3338
15:23:20 [train] batch 7600/7649 | loss 0.9989 | acc 0.3338
15:23:21 [train] batch 7649/7649 | loss 0.9989 | acc 0.3338
15:23:27 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_07.png
15:23:27 Epoch 07 | train 0.9989/0.3338 | val 0.9830/0.3471 | lr 1.00e-05
15:23:31 [train] batch 200/7649 | loss 0.9998 | acc 0.3325
15:23:34 [train] batch 400/7649 | loss 0.9997 | acc 0.3325
15:23:38 [train] batch 600/7649 | loss 0.9995 | acc 0.3330
15:23:41 [train] batch 800/7649 | loss 1.0000 | acc 0.3323
15:23:44 [train] batch 1000/7649 | loss 1.0002 | acc 0.3326
15:23:48 [train] batch 1200/7649 | loss 0.9999 | acc 0.3332
15:23:51 [train] batch 1400/7649 | loss 0.9996 | acc 0.3335
15:23:54 [train] batch 1600/7649 | loss 0.9996 | acc 0.3334
15:23:58 [train] batch 1800/7649 | loss 0.9996 | acc 0.3332
15:24:01 [train] batch 2000/7649 | loss 0.9998 | acc 0.3327
15:24:04 [train] batch 2200/7649 | loss 0.9998 | acc 0.3328
15:24:08 [train] batch 2400/7649 | loss 0.9997 | acc 0.3331
15:24:11 [train] batch 2600/7649 | loss 0.9996 | acc 0.3331
15:24:14 [train] batch 2800/7649 | loss 0.9995 | acc 0.3333
15:24:17 [train] batch 3000/7649 | loss 0.9994 | acc 0.3335
15:24:21 [train] batch 3200/7649 | loss 0.9993 | acc 0.3338
15:24:24 [train] batch 3400/7649 | loss 0.9992 | acc 0.3339
15:24:27 [train] batch 3600/7649 | loss 0.9991 | acc 0.3340
15:24:31 [train] batch 3800/7649 | loss 0.9991 | acc 0.3340
15:24:34 [train] batch 4000/7649 | loss 0.9990 | acc 0.3340
15:24:37 [train] batch 4200/7649 | loss 0.9990 | acc 0.3340
15:24:40 [train] batch 4400/7649 | loss 0.9990 | acc 0.3341
15:24:44 [train] batch 4600/7649 | loss 0.9990 | acc 0.3343
15:24:47 [train] batch 4800/7649 | loss 0.9989 | acc 0.3343
15:24:50 [train] batch 5000/7649 | loss 0.9989 | acc 0.3344
15:24:54 [train] batch 5200/7649 | loss 0.9988 | acc 0.3345
15:24:57 [train] batch 5400/7649 | loss 0.9988 | acc 0.3345
15:25:00 [train] batch 5600/7649 | loss 0.9988 | acc 0.3345
15:25:04 [train] batch 5800/7649 | loss 0.9988 | acc 0.3344
15:25:07 [train] batch 6000/7649 | loss 0.9988 | acc 0.3345
15:25:10 [train] batch 6200/7649 | loss 0.9988 | acc 0.3344
15:25:13 [train] batch 6400/7649 | loss 0.9988 | acc 0.3344
15:25:17 [train] batch 6600/7649 | loss 0.9987 | acc 0.3345
15:25:20 [train] batch 6800/7649 | loss 0.9987 | acc 0.3345
15:25:23 [train] batch 7000/7649 | loss 0.9986 | acc 0.3346
15:25:27 [train] batch 7200/7649 | loss 0.9986 | acc 0.3346
15:25:30 [train] batch 7400/7649 | loss 0.9986 | acc 0.3346
15:25:33 [train] batch 7600/7649 | loss 0.9986 | acc 0.3347
15:25:34 [train] batch 7649/7649 | loss 0.9985 | acc 0.3348
15:25:41 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_08.png
15:25:41 Epoch 08 | train 0.9985/0.3348 | val 0.9827/0.3486 | lr 5.00e-06
15:25:41 ✓ save best
15:25:44 [train] batch 200/7649 | loss 0.9990 | acc 0.3340
15:25:48 [train] batch 400/7649 | loss 0.9998 | acc 0.3329
15:25:51 [train] batch 600/7649 | loss 0.9993 | acc 0.3331
15:25:55 [train] batch 800/7649 | loss 0.9991 | acc 0.3335
15:25:58 [train] batch 1000/7649 | loss 0.9991 | acc 0.3345
15:26:01 [train] batch 1200/7649 | loss 0.9986 | acc 0.3357
15:26:04 [train] batch 1400/7649 | loss 0.9985 | acc 0.3357
15:26:08 [train] batch 1600/7649 | loss 0.9985 | acc 0.3356
15:26:11 [train] batch 1800/7649 | loss 0.9984 | acc 0.3358
15:26:14 [train] batch 2000/7649 | loss 0.9985 | acc 0.3357
15:26:18 [train] batch 2200/7649 | loss 0.9987 | acc 0.3355
15:26:21 [train] batch 2400/7649 | loss 0.9986 | acc 0.3357
15:26:24 [train] batch 2600/7649 | loss 0.9986 | acc 0.3354
15:26:27 [train] batch 2800/7649 | loss 0.9985 | acc 0.3354
15:26:31 [train] batch 3000/7649 | loss 0.9984 | acc 0.3356
15:26:34 [train] batch 3200/7649 | loss 0.9983 | acc 0.3359
15:26:37 [train] batch 3400/7649 | loss 0.9982 | acc 0.3361
15:26:41 [train] batch 3600/7649 | loss 0.9983 | acc 0.3360
15:26:44 [train] batch 3800/7649 | loss 0.9983 | acc 0.3359
15:26:47 [train] batch 4000/7649 | loss 0.9984 | acc 0.3358
15:26:51 [train] batch 4200/7649 | loss 0.9985 | acc 0.3357
15:26:54 [train] batch 4400/7649 | loss 0.9984 | acc 0.3357
15:26:57 [train] batch 4600/7649 | loss 0.9984 | acc 0.3357
15:27:00 [train] batch 4800/7649 | loss 0.9984 | acc 0.3357
15:27:04 [train] batch 5000/7649 | loss 0.9984 | acc 0.3358
15:27:07 [train] batch 5200/7649 | loss 0.9983 | acc 0.3358
15:27:10 [train] batch 5400/7649 | loss 0.9984 | acc 0.3358
15:27:14 [train] batch 5600/7649 | loss 0.9984 | acc 0.3358
15:27:17 [train] batch 5800/7649 | loss 0.9983 | acc 0.3359
15:27:20 [train] batch 6000/7649 | loss 0.9983 | acc 0.3359
15:27:23 [train] batch 6200/7649 | loss 0.9983 | acc 0.3359
15:27:27 [train] batch 6400/7649 | loss 0.9982 | acc 0.3359
15:27:30 [train] batch 6600/7649 | loss 0.9983 | acc 0.3359
15:27:33 [train] batch 6800/7649 | loss 0.9983 | acc 0.3359
15:27:37 [train] batch 7000/7649 | loss 0.9983 | acc 0.3358
15:27:40 [train] batch 7200/7649 | loss 0.9983 | acc 0.3358
15:27:43 [train] batch 7400/7649 | loss 0.9983 | acc 0.3358
15:27:46 [train] batch 7600/7649 | loss 0.9983 | acc 0.3358
15:27:47 [train] batch 7649/7649 | loss 0.9983 | acc 0.3359
15:27:54 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_09.png
15:27:54 Epoch 09 | train 0.9983/0.3359 | val 0.9828/0.3496 | lr 5.00e-06
15:27:54 ✓ save best
15:27:58 [train] batch 200/7649 | loss 0.9982 | acc 0.3366
15:28:02 [train] batch 400/7649 | loss 0.9986 | acc 0.3356
15:28:05 [train] batch 600/7649 | loss 0.9991 | acc 0.3351
15:28:08 [train] batch 800/7649 | loss 0.9994 | acc 0.3349
15:28:11 [train] batch 1000/7649 | loss 0.9994 | acc 0.3349
15:28:15 [train] batch 1200/7649 | loss 0.9994 | acc 0.3344
15:28:18 [train] batch 1400/7649 | loss 0.9990 | acc 0.3351
15:28:21 [train] batch 1600/7649 | loss 0.9990 | acc 0.3353
15:28:25 [train] batch 1800/7649 | loss 0.9989 | acc 0.3351
15:28:28 [train] batch 2000/7649 | loss 0.9987 | acc 0.3354
15:28:31 [train] batch 2200/7649 | loss 0.9988 | acc 0.3352
15:28:34 [train] batch 2400/7649 | loss 0.9987 | acc 0.3353
15:28:38 [train] batch 2600/7649 | loss 0.9986 | acc 0.3354
15:28:41 [train] batch 2800/7649 | loss 0.9985 | acc 0.3358
15:28:44 [train] batch 3000/7649 | loss 0.9984 | acc 0.3358
15:28:48 [train] batch 3200/7649 | loss 0.9983 | acc 0.3359
15:28:51 [train] batch 3400/7649 | loss 0.9984 | acc 0.3358
15:28:54 [train] batch 3600/7649 | loss 0.9983 | acc 0.3358
15:28:57 [train] batch 3800/7649 | loss 0.9983 | acc 0.3359
15:29:01 [train] batch 4000/7649 | loss 0.9982 | acc 0.3361
15:29:04 [train] batch 4200/7649 | loss 0.9982 | acc 0.3361
15:29:08 [train] batch 4400/7649 | loss 0.9982 | acc 0.3362
15:29:11 [train] batch 4600/7649 | loss 0.9982 | acc 0.3362
15:29:14 [train] batch 4800/7649 | loss 0.9982 | acc 0.3362
15:29:17 [train] batch 5000/7649 | loss 0.9981 | acc 0.3363
15:29:21 [train] batch 5200/7649 | loss 0.9981 | acc 0.3363
15:29:24 [train] batch 5400/7649 | loss 0.9982 | acc 0.3362
15:29:27 [train] batch 5600/7649 | loss 0.9982 | acc 0.3362
15:29:30 [train] batch 5800/7649 | loss 0.9982 | acc 0.3363
15:29:34 [train] batch 6000/7649 | loss 0.9982 | acc 0.3363
15:29:37 [train] batch 6200/7649 | loss 0.9981 | acc 0.3364
15:29:40 [train] batch 6400/7649 | loss 0.9981 | acc 0.3364
15:29:44 [train] batch 6600/7649 | loss 0.9981 | acc 0.3364
15:29:47 [train] batch 6800/7649 | loss 0.9981 | acc 0.3363
15:29:50 [train] batch 7000/7649 | loss 0.9981 | acc 0.3364
15:29:53 [train] batch 7200/7649 | loss 0.9981 | acc 0.3364
15:29:57 [train] batch 7400/7649 | loss 0.9981 | acc 0.3364
15:30:00 [train] batch 7600/7649 | loss 0.9981 | acc 0.3364
15:30:01 [train] batch 7649/7649 | loss 0.9980 | acc 0.3364
15:30:08 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_10.png
15:30:08 Epoch 10 | train 0.9980/0.3364 | val 0.9825/0.3501 | lr 5.00e-06
15:30:08 ✓ save best
15:30:12 [train] batch 200/7649 | loss 0.9991 | acc 0.3370
15:30:15 [train] batch 400/7649 | loss 0.9986 | acc 0.3372
15:30:18 [train] batch 600/7649 | loss 0.9983 | acc 0.3369
15:30:21 [train] batch 800/7649 | loss 0.9984 | acc 0.3368
15:30:25 [train] batch 1000/7649 | loss 0.9987 | acc 0.3362
15:30:28 [train] batch 1200/7649 | loss 0.9984 | acc 0.3364
15:30:31 [train] batch 1400/7649 | loss 0.9981 | acc 0.3369
15:30:35 [train] batch 1600/7649 | loss 0.9979 | acc 0.3369
15:30:38 [train] batch 1800/7649 | loss 0.9982 | acc 0.3362
15:30:41 [train] batch 2000/7649 | loss 0.9980 | acc 0.3364
15:30:44 [train] batch 2200/7649 | loss 0.9980 | acc 0.3363
15:30:48 [train] batch 2400/7649 | loss 0.9980 | acc 0.3364
15:30:51 [train] batch 2600/7649 | loss 0.9980 | acc 0.3364
15:30:54 [train] batch 2800/7649 | loss 0.9979 | acc 0.3366
15:30:58 [train] batch 3000/7649 | loss 0.9979 | acc 0.3365
15:31:01 [train] batch 3200/7649 | loss 0.9978 | acc 0.3367
15:31:04 [train] batch 3400/7649 | loss 0.9978 | acc 0.3366
15:31:08 [train] batch 3600/7649 | loss 0.9979 | acc 0.3367
15:31:11 [train] batch 3800/7649 | loss 0.9979 | acc 0.3367
15:31:14 [train] batch 4000/7649 | loss 0.9979 | acc 0.3368
15:31:18 [train] batch 4200/7649 | loss 0.9978 | acc 0.3369
15:31:21 [train] batch 4400/7649 | loss 0.9978 | acc 0.3370
15:31:24 [train] batch 4600/7649 | loss 0.9977 | acc 0.3370
15:31:27 [train] batch 4800/7649 | loss 0.9977 | acc 0.3371
15:31:31 [train] batch 5000/7649 | loss 0.9976 | acc 0.3371
15:31:34 [train] batch 5200/7649 | loss 0.9976 | acc 0.3370
15:31:37 [train] batch 5400/7649 | loss 0.9976 | acc 0.3371
15:31:41 [train] batch 5600/7649 | loss 0.9976 | acc 0.3371
15:31:44 [train] batch 5800/7649 | loss 0.9977 | acc 0.3370
15:31:47 [train] batch 6000/7649 | loss 0.9977 | acc 0.3370
15:31:50 [train] batch 6200/7649 | loss 0.9977 | acc 0.3369
15:31:54 [train] batch 6400/7649 | loss 0.9977 | acc 0.3369
15:31:57 [train] batch 6600/7649 | loss 0.9977 | acc 0.3368
15:32:00 [train] batch 6800/7649 | loss 0.9978 | acc 0.3368
15:32:04 [train] batch 7000/7649 | loss 0.9978 | acc 0.3368
15:32:07 [train] batch 7200/7649 | loss 0.9978 | acc 0.3368
15:32:10 [train] batch 7400/7649 | loss 0.9978 | acc 0.3368
15:32:14 [train] batch 7600/7649 | loss 0.9978 | acc 0.3368
15:32:14 [train] batch 7649/7649 | loss 0.9978 | acc 0.3368
15:32:22 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_11.png
15:32:22 Epoch 11 | train 0.9978/0.3368 | val 0.9826/0.3514 | lr 5.00e-06
15:32:22 ✓ save best
15:32:25 [train] batch 200/7649 | loss 0.9971 | acc 0.3367
15:32:29 [train] batch 400/7649 | loss 0.9970 | acc 0.3370
15:32:32 [train] batch 600/7649 | loss 0.9967 | acc 0.3377
15:32:35 [train] batch 800/7649 | loss 0.9973 | acc 0.3375
15:32:38 [train] batch 1000/7649 | loss 0.9977 | acc 0.3373
15:32:42 [train] batch 1200/7649 | loss 0.9983 | acc 0.3361
15:32:45 [train] batch 1400/7649 | loss 0.9981 | acc 0.3363
15:32:48 [train] batch 1600/7649 | loss 0.9983 | acc 0.3360
15:32:52 [train] batch 1800/7649 | loss 0.9983 | acc 0.3362
15:32:55 [train] batch 2000/7649 | loss 0.9982 | acc 0.3362
15:32:58 [train] batch 2200/7649 | loss 0.9982 | acc 0.3363
15:33:02 [train] batch 2400/7649 | loss 0.9980 | acc 0.3366
15:33:05 [train] batch 2600/7649 | loss 0.9980 | acc 0.3366
15:33:08 [train] batch 2800/7649 | loss 0.9979 | acc 0.3368
15:33:11 [train] batch 3000/7649 | loss 0.9979 | acc 0.3366
15:33:15 [train] batch 3200/7649 | loss 0.9979 | acc 0.3368
15:33:18 [train] batch 3400/7649 | loss 0.9979 | acc 0.3367
15:33:21 [train] batch 3600/7649 | loss 0.9979 | acc 0.3367
15:33:25 [train] batch 3800/7649 | loss 0.9979 | acc 0.3366
15:33:28 [train] batch 4000/7649 | loss 0.9979 | acc 0.3367
15:33:32 [train] batch 4200/7649 | loss 0.9979 | acc 0.3368
15:33:35 [train] batch 4400/7649 | loss 0.9978 | acc 0.3369
15:33:38 [train] batch 4600/7649 | loss 0.9978 | acc 0.3369
15:33:41 [train] batch 4800/7649 | loss 0.9978 | acc 0.3369
15:33:45 [train] batch 5000/7649 | loss 0.9978 | acc 0.3369
15:33:48 [train] batch 5200/7649 | loss 0.9978 | acc 0.3370
15:33:51 [train] batch 5400/7649 | loss 0.9978 | acc 0.3370
15:33:55 [train] batch 5600/7649 | loss 0.9978 | acc 0.3371
15:33:58 [train] batch 5800/7649 | loss 0.9978 | acc 0.3371
15:34:01 [train] batch 6000/7649 | loss 0.9977 | acc 0.3372
15:34:04 [train] batch 6200/7649 | loss 0.9978 | acc 0.3372
15:34:08 [train] batch 6400/7649 | loss 0.9977 | acc 0.3372
15:34:11 [train] batch 6600/7649 | loss 0.9977 | acc 0.3372
15:34:14 [train] batch 6800/7649 | loss 0.9978 | acc 0.3372
15:34:17 [train] batch 7000/7649 | loss 0.9977 | acc 0.3372
15:34:21 [train] batch 7200/7649 | loss 0.9977 | acc 0.3372
15:34:24 [train] batch 7400/7649 | loss 0.9977 | acc 0.3371
15:34:27 [train] batch 7600/7649 | loss 0.9977 | acc 0.3371
15:34:28 [train] batch 7649/7649 | loss 0.9977 | acc 0.3372
15:34:35 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_12.png
15:34:35 Epoch 12 | train 0.9977/0.3372 | val 0.9828/0.3489 | lr 2.50e-06
15:34:38 [train] batch 200/7649 | loss 0.9966 | acc 0.3401
15:34:42 [train] batch 400/7649 | loss 0.9961 | acc 0.3414
15:34:45 [train] batch 600/7649 | loss 0.9973 | acc 0.3394
15:34:48 [train] batch 800/7649 | loss 0.9978 | acc 0.3383
15:34:52 [train] batch 1000/7649 | loss 0.9981 | acc 0.3374
15:34:55 [train] batch 1200/7649 | loss 0.9985 | acc 0.3371
15:34:58 [train] batch 1400/7649 | loss 0.9986 | acc 0.3365
15:35:01 [train] batch 1600/7649 | loss 0.9983 | acc 0.3368
15:35:05 [train] batch 1800/7649 | loss 0.9983 | acc 0.3369
15:35:08 [train] batch 2000/7649 | loss 0.9982 | acc 0.3371
15:35:11 [train] batch 2200/7649 | loss 0.9982 | acc 0.3371
15:35:14 [train] batch 2400/7649 | loss 0.9982 | acc 0.3372
15:35:18 [train] batch 2600/7649 | loss 0.9981 | acc 0.3372
15:35:21 [train] batch 2800/7649 | loss 0.9981 | acc 0.3372
15:35:24 [train] batch 3000/7649 | loss 0.9981 | acc 0.3371
15:35:28 [train] batch 3200/7649 | loss 0.9980 | acc 0.3372
15:35:31 [train] batch 3400/7649 | loss 0.9981 | acc 0.3371
15:35:34 [train] batch 3600/7649 | loss 0.9981 | acc 0.3370
15:35:38 [train] batch 3800/7649 | loss 0.9980 | acc 0.3372
15:35:41 [train] batch 4000/7649 | loss 0.9980 | acc 0.3373
15:35:44 [train] batch 4200/7649 | loss 0.9980 | acc 0.3373
15:35:48 [train] batch 4400/7649 | loss 0.9980 | acc 0.3374
15:35:51 [train] batch 4600/7649 | loss 0.9980 | acc 0.3374
15:35:54 [train] batch 4800/7649 | loss 0.9979 | acc 0.3374
15:35:57 [train] batch 5000/7649 | loss 0.9978 | acc 0.3373
15:36:01 [train] batch 5200/7649 | loss 0.9977 | acc 0.3374
15:36:04 [train] batch 5400/7649 | loss 0.9977 | acc 0.3373
15:36:07 [train] batch 5600/7649 | loss 0.9977 | acc 0.3374
15:36:11 [train] batch 5800/7649 | loss 0.9977 | acc 0.3374
15:36:14 [train] batch 6000/7649 | loss 0.9977 | acc 0.3375
15:36:17 [train] batch 6200/7649 | loss 0.9976 | acc 0.3376
15:36:20 [train] batch 6400/7649 | loss 0.9976 | acc 0.3376
15:36:24 [train] batch 6600/7649 | loss 0.9976 | acc 0.3377
15:36:27 [train] batch 6800/7649 | loss 0.9976 | acc 0.3376
15:36:30 [train] batch 7000/7649 | loss 0.9976 | acc 0.3376
15:36:34 [train] batch 7200/7649 | loss 0.9976 | acc 0.3376
15:36:37 [train] batch 7400/7649 | loss 0.9976 | acc 0.3376
15:36:40 [train] batch 7600/7649 | loss 0.9976 | acc 0.3376
15:36:41 [train] batch 7649/7649 | loss 0.9976 | acc 0.3377
15:36:48 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_13.png
15:36:48 Epoch 13 | train 0.9976/0.3377 | val 0.9825/0.3509 | lr 2.50e-06
15:36:51 [train] batch 200/7649 | loss 0.9980 | acc 0.3379
15:36:54 [train] batch 400/7649 | loss 0.9981 | acc 0.3374
15:36:58 [train] batch 600/7649 | loss 0.9977 | acc 0.3377
15:37:01 [train] batch 800/7649 | loss 0.9976 | acc 0.3380
15:37:04 [train] batch 1000/7649 | loss 0.9976 | acc 0.3382
15:37:08 [train] batch 1200/7649 | loss 0.9976 | acc 0.3381
15:37:11 [train] batch 1400/7649 | loss 0.9976 | acc 0.3381
15:37:14 [train] batch 1600/7649 | loss 0.9974 | acc 0.3382
15:37:17 [train] batch 1800/7649 | loss 0.9974 | acc 0.3383
15:37:21 [train] batch 2000/7649 | loss 0.9976 | acc 0.3379
15:37:24 [train] batch 2200/7649 | loss 0.9974 | acc 0.3381
15:37:27 [train] batch 2400/7649 | loss 0.9976 | acc 0.3378
15:37:31 [train] batch 2600/7649 | loss 0.9974 | acc 0.3380
15:37:34 [train] batch 2800/7649 | loss 0.9972 | acc 0.3383
15:37:37 [train] batch 3000/7649 | loss 0.9971 | acc 0.3383
15:37:40 [train] batch 3200/7649 | loss 0.9973 | acc 0.3381
15:37:44 [train] batch 3400/7649 | loss 0.9974 | acc 0.3380
15:37:47 [train] batch 3600/7649 | loss 0.9975 | acc 0.3379
15:37:50 [train] batch 3800/7649 | loss 0.9974 | acc 0.3380
15:37:54 [train] batch 4000/7649 | loss 0.9973 | acc 0.3381
15:37:57 [train] batch 4200/7649 | loss 0.9973 | acc 0.3382
15:38:00 [train] batch 4400/7649 | loss 0.9974 | acc 0.3383
15:38:04 [train] batch 4600/7649 | loss 0.9973 | acc 0.3382
15:38:07 [train] batch 4800/7649 | loss 0.9974 | acc 0.3380
15:38:10 [train] batch 5000/7649 | loss 0.9974 | acc 0.3381
15:38:13 [train] batch 5200/7649 | loss 0.9973 | acc 0.3381
15:38:17 [train] batch 5400/7649 | loss 0.9973 | acc 0.3382
15:38:20 [train] batch 5600/7649 | loss 0.9972 | acc 0.3383
15:38:23 [train] batch 5800/7649 | loss 0.9972 | acc 0.3383
15:38:27 [train] batch 6000/7649 | loss 0.9973 | acc 0.3383
15:38:30 [train] batch 6200/7649 | loss 0.9973 | acc 0.3382
15:38:33 [train] batch 6400/7649 | loss 0.9974 | acc 0.3381
15:38:36 [train] batch 6600/7649 | loss 0.9974 | acc 0.3382
15:38:40 [train] batch 6800/7649 | loss 0.9974 | acc 0.3382
15:38:43 [train] batch 7000/7649 | loss 0.9973 | acc 0.3383
15:38:46 [train] batch 7200/7649 | loss 0.9973 | acc 0.3382
15:38:50 [train] batch 7400/7649 | loss 0.9974 | acc 0.3382
15:38:53 [train] batch 7600/7649 | loss 0.9974 | acc 0.3381
15:38:54 [train] batch 7649/7649 | loss 0.9974 | acc 0.3381
15:39:00 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_14.png
15:39:01 Epoch 14 | train 0.9974/0.3381 | val 0.9825/0.3508 | lr 2.50e-06
15:39:04 [train] batch 200/7649 | loss 0.9988 | acc 0.3363
15:39:07 [train] batch 400/7649 | loss 0.9968 | acc 0.3383
15:39:11 [train] batch 600/7649 | loss 0.9979 | acc 0.3373
15:39:14 [train] batch 800/7649 | loss 0.9980 | acc 0.3374
15:39:17 [train] batch 1000/7649 | loss 0.9976 | acc 0.3376
15:39:20 [train] batch 1200/7649 | loss 0.9977 | acc 0.3379
15:39:24 [train] batch 1400/7649 | loss 0.9977 | acc 0.3380
15:39:27 [train] batch 1600/7649 | loss 0.9975 | acc 0.3383
15:39:30 [train] batch 1800/7649 | loss 0.9974 | acc 0.3384
15:39:34 [train] batch 2000/7649 | loss 0.9976 | acc 0.3382
15:39:37 [train] batch 2200/7649 | loss 0.9975 | acc 0.3383
15:39:40 [train] batch 2400/7649 | loss 0.9974 | acc 0.3384
15:39:43 [train] batch 2600/7649 | loss 0.9974 | acc 0.3383
15:39:47 [train] batch 2800/7649 | loss 0.9973 | acc 0.3384
15:39:50 [train] batch 3000/7649 | loss 0.9973 | acc 0.3384
15:39:53 [train] batch 3200/7649 | loss 0.9973 | acc 0.3383
15:39:57 [train] batch 3400/7649 | loss 0.9973 | acc 0.3383
15:40:00 [train] batch 3600/7649 | loss 0.9972 | acc 0.3383
15:40:03 [train] batch 3800/7649 | loss 0.9972 | acc 0.3382
15:40:07 [train] batch 4000/7649 | loss 0.9972 | acc 0.3382
15:40:10 [train] batch 4200/7649 | loss 0.9972 | acc 0.3381
15:40:13 [train] batch 4400/7649 | loss 0.9971 | acc 0.3382
15:40:16 [train] batch 4600/7649 | loss 0.9971 | acc 0.3382
15:40:20 [train] batch 4800/7649 | loss 0.9972 | acc 0.3383
15:40:23 [train] batch 5000/7649 | loss 0.9972 | acc 0.3383
15:40:26 [train] batch 5200/7649 | loss 0.9972 | acc 0.3383
15:40:30 [train] batch 5400/7649 | loss 0.9972 | acc 0.3382
15:40:33 [train] batch 5600/7649 | loss 0.9973 | acc 0.3382
15:40:36 [train] batch 5800/7649 | loss 0.9973 | acc 0.3381
15:40:39 [train] batch 6000/7649 | loss 0.9973 | acc 0.3382
15:40:43 [train] batch 6200/7649 | loss 0.9973 | acc 0.3382
15:40:46 [train] batch 6400/7649 | loss 0.9973 | acc 0.3383
15:40:49 [train] batch 6600/7649 | loss 0.9973 | acc 0.3382
15:40:53 [train] batch 6800/7649 | loss 0.9973 | acc 0.3383
15:40:56 [train] batch 7000/7649 | loss 0.9973 | acc 0.3384
15:40:59 [train] batch 7200/7649 | loss 0.9973 | acc 0.3383
15:41:03 [train] batch 7400/7649 | loss 0.9973 | acc 0.3382
15:41:06 [train] batch 7600/7649 | loss 0.9973 | acc 0.3382
15:41:07 [train] batch 7649/7649 | loss 0.9973 | acc 0.3382
15:41:13 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_15.png
15:41:13 Epoch 15 | train 0.9973/0.3382 | val 0.9826/0.3504 | lr 2.50e-06
15:41:17 [train] batch 200/7649 | loss 0.9973 | acc 0.3365
15:41:20 [train] batch 400/7649 | loss 0.9977 | acc 0.3354
15:41:23 [train] batch 600/7649 | loss 0.9975 | acc 0.3370
15:41:27 [train] batch 800/7649 | loss 0.9974 | acc 0.3376
15:41:30 [train] batch 1000/7649 | loss 0.9976 | acc 0.3381
15:41:33 [train] batch 1200/7649 | loss 0.9978 | acc 0.3378
15:41:37 [train] batch 1400/7649 | loss 0.9975 | acc 0.3381
15:41:40 [train] batch 1600/7649 | loss 0.9973 | acc 0.3383
15:41:43 [train] batch 1800/7649 | loss 0.9974 | acc 0.3381
15:41:46 [train] batch 2000/7649 | loss 0.9975 | acc 0.3378
15:41:50 [train] batch 2200/7649 | loss 0.9974 | acc 0.3380
15:41:53 [train] batch 2400/7649 | loss 0.9973 | acc 0.3382
15:41:56 [train] batch 2600/7649 | loss 0.9973 | acc 0.3381
15:42:00 [train] batch 2800/7649 | loss 0.9973 | acc 0.3381
15:42:03 [train] batch 3000/7649 | loss 0.9972 | acc 0.3382
15:42:06 [train] batch 3200/7649 | loss 0.9972 | acc 0.3385
15:42:10 [train] batch 3400/7649 | loss 0.9971 | acc 0.3385
15:42:13 [train] batch 3600/7649 | loss 0.9971 | acc 0.3386
15:42:16 [train] batch 3800/7649 | loss 0.9972 | acc 0.3384
15:42:19 [train] batch 4000/7649 | loss 0.9972 | acc 0.3385
15:42:23 [train] batch 4200/7649 | loss 0.9972 | acc 0.3385
15:42:26 [train] batch 4400/7649 | loss 0.9972 | acc 0.3384
15:42:29 [train] batch 4600/7649 | loss 0.9972 | acc 0.3384
15:42:33 [train] batch 4800/7649 | loss 0.9972 | acc 0.3383
15:42:36 [train] batch 5000/7649 | loss 0.9972 | acc 0.3384
15:42:39 [train] batch 5200/7649 | loss 0.9972 | acc 0.3384
15:42:42 [train] batch 5400/7649 | loss 0.9973 | acc 0.3383
15:42:46 [train] batch 5600/7649 | loss 0.9972 | acc 0.3384
15:42:49 [train] batch 5800/7649 | loss 0.9973 | acc 0.3383
15:42:52 [train] batch 6000/7649 | loss 0.9972 | acc 0.3383
15:42:56 [train] batch 6200/7649 | loss 0.9972 | acc 0.3384
15:42:59 [train] batch 6400/7649 | loss 0.9973 | acc 0.3384
15:43:02 [train] batch 6600/7649 | loss 0.9973 | acc 0.3384
15:43:05 [train] batch 6800/7649 | loss 0.9974 | acc 0.3383
15:43:09 [train] batch 7000/7649 | loss 0.9974 | acc 0.3382
15:43:12 [train] batch 7200/7649 | loss 0.9973 | acc 0.3383
15:43:15 [train] batch 7400/7649 | loss 0.9973 | acc 0.3383
15:43:19 [train] batch 7600/7649 | loss 0.9973 | acc 0.3383
15:43:20 [train] batch 7649/7649 | loss 0.9973 | acc 0.3383
15:43:26 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_16.png
15:43:26 Epoch 16 | train 0.9973/0.3383 | val 0.9827/0.3509 | lr 1.25e-06
15:43:30 [train] batch 200/7649 | loss 0.9977 | acc 0.3375
15:43:33 [train] batch 400/7649 | loss 0.9982 | acc 0.3376
15:43:36 [train] batch 600/7649 | loss 0.9979 | acc 0.3375
15:43:40 [train] batch 800/7649 | loss 0.9977 | acc 0.3380
15:43:43 [train] batch 1000/7649 | loss 0.9979 | acc 0.3375
15:43:46 [train] batch 1200/7649 | loss 0.9977 | acc 0.3373
15:43:49 [train] batch 1400/7649 | loss 0.9975 | acc 0.3378
15:43:53 [train] batch 1600/7649 | loss 0.9975 | acc 0.3377
15:43:56 [train] batch 1800/7649 | loss 0.9974 | acc 0.3380
15:43:59 [train] batch 2000/7649 | loss 0.9974 | acc 0.3380
15:44:03 [train] batch 2200/7649 | loss 0.9972 | acc 0.3383
15:44:06 [train] batch 2400/7649 | loss 0.9975 | acc 0.3381
15:44:09 [train] batch 2600/7649 | loss 0.9975 | acc 0.3382
15:44:13 [train] batch 2800/7649 | loss 0.9974 | acc 0.3382
15:44:16 [train] batch 3000/7649 | loss 0.9976 | acc 0.3381
15:44:19 [train] batch 3200/7649 | loss 0.9976 | acc 0.3381
15:44:23 [train] batch 3400/7649 | loss 0.9975 | acc 0.3381
15:44:26 [train] batch 3600/7649 | loss 0.9975 | acc 0.3382
15:44:29 [train] batch 3800/7649 | loss 0.9974 | acc 0.3383
15:44:32 [train] batch 4000/7649 | loss 0.9973 | acc 0.3384
15:44:36 [train] batch 4200/7649 | loss 0.9973 | acc 0.3385
15:44:39 [train] batch 4400/7649 | loss 0.9973 | acc 0.3386
15:44:42 [train] batch 4600/7649 | loss 0.9973 | acc 0.3386
15:44:46 [train] batch 4800/7649 | loss 0.9973 | acc 0.3387
15:44:49 [train] batch 5000/7649 | loss 0.9973 | acc 0.3387
15:44:52 [train] batch 5200/7649 | loss 0.9972 | acc 0.3387
15:44:55 [train] batch 5400/7649 | loss 0.9973 | acc 0.3386
15:44:59 [train] batch 5600/7649 | loss 0.9973 | acc 0.3386
15:45:02 [train] batch 5800/7649 | loss 0.9972 | acc 0.3387
15:45:05 [train] batch 6000/7649 | loss 0.9973 | acc 0.3386
15:45:09 [train] batch 6200/7649 | loss 0.9972 | acc 0.3385
15:45:12 [train] batch 6400/7649 | loss 0.9972 | acc 0.3386
15:45:15 [train] batch 6600/7649 | loss 0.9973 | acc 0.3387
15:45:19 [train] batch 6800/7649 | loss 0.9973 | acc 0.3386
15:45:22 [train] batch 7000/7649 | loss 0.9972 | acc 0.3386
15:45:25 [train] batch 7200/7649 | loss 0.9972 | acc 0.3386
15:45:28 [train] batch 7400/7649 | loss 0.9972 | acc 0.3386
15:45:32 [train] batch 7600/7649 | loss 0.9972 | acc 0.3386
15:45:33 [train] batch 7649/7649 | loss 0.9972 | acc 0.3387
15:45:39 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_17.png
15:45:39 Epoch 17 | train 0.9972/0.3387 | val 0.9826/0.3507 | lr 1.25e-06
15:45:43 [train] batch 200/7649 | loss 0.9967 | acc 0.3389
15:45:46 [train] batch 400/7649 | loss 0.9967 | acc 0.3389
15:45:49 [train] batch 600/7649 | loss 0.9961 | acc 0.3398
15:45:52 [train] batch 800/7649 | loss 0.9967 | acc 0.3387
15:45:56 [train] batch 1000/7649 | loss 0.9972 | acc 0.3385
15:45:59 [train] batch 1200/7649 | loss 0.9972 | acc 0.3385
15:46:02 [train] batch 1400/7649 | loss 0.9973 | acc 0.3384
15:46:06 [train] batch 1600/7649 | loss 0.9973 | acc 0.3381
15:46:09 [train] batch 1800/7649 | loss 0.9974 | acc 0.3379
15:46:12 [train] batch 2000/7649 | loss 0.9973 | acc 0.3380
15:46:16 [train] batch 2200/7649 | loss 0.9973 | acc 0.3382
15:46:19 [train] batch 2400/7649 | loss 0.9974 | acc 0.3380
15:46:22 [train] batch 2600/7649 | loss 0.9975 | acc 0.3380
15:46:26 [train] batch 2800/7649 | loss 0.9975 | acc 0.3380
15:46:29 [train] batch 3000/7649 | loss 0.9974 | acc 0.3381
15:46:32 [train] batch 3200/7649 | loss 0.9974 | acc 0.3380
15:46:35 [train] batch 3400/7649 | loss 0.9974 | acc 0.3380
15:46:39 [train] batch 3600/7649 | loss 0.9974 | acc 0.3382
15:46:42 [train] batch 3800/7649 | loss 0.9974 | acc 0.3382
15:46:45 [train] batch 4000/7649 | loss 0.9974 | acc 0.3381
15:46:49 [train] batch 4200/7649 | loss 0.9974 | acc 0.3383
15:46:52 [train] batch 4400/7649 | loss 0.9975 | acc 0.3383
15:46:55 [train] batch 4600/7649 | loss 0.9974 | acc 0.3385
15:46:58 [train] batch 4800/7649 | loss 0.9973 | acc 0.3385
15:47:02 [train] batch 5000/7649 | loss 0.9973 | acc 0.3385
15:47:05 [train] batch 5200/7649 | loss 0.9974 | acc 0.3385
15:47:08 [train] batch 5400/7649 | loss 0.9973 | acc 0.3386
15:47:12 [train] batch 5600/7649 | loss 0.9973 | acc 0.3384
15:47:15 [train] batch 5800/7649 | loss 0.9973 | acc 0.3384
15:47:18 [train] batch 6000/7649 | loss 0.9973 | acc 0.3384
15:47:21 [train] batch 6200/7649 | loss 0.9973 | acc 0.3382
15:47:25 [train] batch 6400/7649 | loss 0.9973 | acc 0.3383
15:47:28 [train] batch 6600/7649 | loss 0.9973 | acc 0.3383
15:47:31 [train] batch 6800/7649 | loss 0.9972 | acc 0.3383
15:47:35 [train] batch 7000/7649 | loss 0.9972 | acc 0.3383
15:47:38 [train] batch 7200/7649 | loss 0.9973 | acc 0.3383
15:47:41 [train] batch 7400/7649 | loss 0.9972 | acc 0.3383
15:47:45 [train] batch 7600/7649 | loss 0.9972 | acc 0.3384
15:47:45 [train] batch 7649/7649 | loss 0.9972 | acc 0.3384
15:47:52 ✔ saved validation confusion matrix → confusion_val/run_20250524_150757/epoch_18.png
15:47:52 Epoch 18 | train 0.9972/0.3384 | val 0.9825/0.3501 | lr 1.25e-06
15:47:52 Early-stop
15:47:53 [eval ] batch 200/2185 | loss 1.0029 | acc 0.3368
15:47:54 [eval ] batch 400/2185 | loss 0.9875 | acc 0.3488
15:47:55 [eval ] batch 600/2185 | loss 0.9845 | acc 0.3501
15:47:56 [eval ] batch 800/2185 | loss 0.9864 | acc 0.3484
15:47:57 [eval ] batch 1000/2185 | loss 0.9866 | acc 0.3480
15:47:59 [eval ] batch 1200/2185 | loss 0.9850 | acc 0.3489
15:48:00 [eval ] batch 1400/2185 | loss 0.9859 | acc 0.3476
15:48:01 [eval ] batch 1600/2185 | loss 0.9860 | acc 0.3475
15:48:02 [eval ] batch 1800/2185 | loss 0.9863 | acc 0.3469
15:48:03 [eval ] batch 2000/2185 | loss 0.9864 | acc 0.3462
15:48:04 [eval ] batch 2185/2185 | loss 0.9860 | acc 0.3464
15:48:04 TEST loss/acc 0.9860/0.3464
15:48:17 Confusion matrix saved ➜ confusion_matrix.png


1.5 : 0.5 loss
/data4/private/rmy/hw/confusion_val/run_20250524_150757