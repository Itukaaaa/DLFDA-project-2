22:52:12 Log file: logs/train_20250524_225212.log
22:52:44 ✔ Data split: 1958081/279725/559453 rows ➜ splits
22:52:46 train.csv: samples=1957961  class_dist=[ 242173 1465142  250766]
22:52:47 val.csv: samples=279605  class_dist=[ 29458 218014  32253]
22:52:47 test.csv: samples=559333  class_dist=[ 68225 420338  70890]
22:52:52 [train] batch 200/7649 | loss 1.0835 | acc 0.5997
22:52:56 [train] batch 400/7649 | loss 1.0752 | acc 0.5916
22:52:59 [train] batch 600/7649 | loss 1.0713 | acc 0.5857
22:53:02 [train] batch 800/7649 | loss 1.0684 | acc 0.5816
22:53:05 [train] batch 1000/7649 | loss 1.0668 | acc 0.5741
22:53:08 [train] batch 1200/7649 | loss 1.0653 | acc 0.5702
22:53:12 [train] batch 1400/7649 | loss 1.0643 | acc 0.5663
22:53:15 [train] batch 1600/7649 | loss 1.0628 | acc 0.5644
22:53:18 [train] batch 1800/7649 | loss 1.0619 | acc 0.5619
22:53:21 [train] batch 2000/7649 | loss 1.0611 | acc 0.5601
22:53:24 [train] batch 2200/7649 | loss 1.0604 | acc 0.5585
22:53:28 [train] batch 2400/7649 | loss 1.0597 | acc 0.5577
22:53:31 [train] batch 2600/7649 | loss 1.0591 | acc 0.5569
22:53:34 [train] batch 2800/7649 | loss 1.0587 | acc 0.5559
22:53:37 [train] batch 3000/7649 | loss 1.0582 | acc 0.5548
22:53:41 [train] batch 3200/7649 | loss 1.0578 | acc 0.5539
22:53:44 [train] batch 3400/7649 | loss 1.0575 | acc 0.5530
22:53:47 [train] batch 3600/7649 | loss 1.0573 | acc 0.5520
22:53:51 [train] batch 3800/7649 | loss 1.0569 | acc 0.5517
22:53:54 [train] batch 4000/7649 | loss 1.0566 | acc 0.5511
22:53:57 [train] batch 4200/7649 | loss 1.0563 | acc 0.5508
22:54:00 [train] batch 4400/7649 | loss 1.0559 | acc 0.5505
22:54:03 [train] batch 4600/7649 | loss 1.0558 | acc 0.5498
22:54:07 [train] batch 4800/7649 | loss 1.0555 | acc 0.5497
22:54:10 [train] batch 5000/7649 | loss 1.0552 | acc 0.5492
22:54:13 [train] batch 5200/7649 | loss 1.0551 | acc 0.5490
22:54:16 [train] batch 5400/7649 | loss 1.0548 | acc 0.5492
22:54:20 [train] batch 5600/7649 | loss 1.0546 | acc 0.5492
22:54:23 [train] batch 5800/7649 | loss 1.0544 | acc 0.5491
22:54:26 [train] batch 6000/7649 | loss 1.0543 | acc 0.5492
22:54:29 [train] batch 6200/7649 | loss 1.0542 | acc 0.5491
22:54:33 [train] batch 6400/7649 | loss 1.0540 | acc 0.5492
22:54:36 [train] batch 6600/7649 | loss 1.0538 | acc 0.5492
22:54:39 [train] batch 6800/7649 | loss 1.0537 | acc 0.5494
22:54:42 [train] batch 7000/7649 | loss 1.0536 | acc 0.5493
22:54:46 [train] batch 7200/7649 | loss 1.0535 | acc 0.5492
22:54:49 [train] batch 7400/7649 | loss 1.0533 | acc 0.5493
22:54:52 [train] batch 7600/7649 | loss 1.0533 | acc 0.5492
22:54:53 [train] batch 7649/7649 | loss 1.0533 | acc 0.5494
22:55:00 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_01.png
22:55:00 Epoch 01 | train 1.0533/0.5494 | val 1.0081/0.5659 | lr 1.00e-05
22:55:00 ✓ save best
22:55:03 [train] batch 200/7649 | loss 1.0518 | acc 0.5461
22:55:07 [train] batch 400/7649 | loss 1.0504 | acc 0.5505
22:55:10 [train] batch 600/7649 | loss 1.0508 | acc 0.5484
22:55:13 [train] batch 800/7649 | loss 1.0504 | acc 0.5476
22:55:16 [train] batch 1000/7649 | loss 1.0504 | acc 0.5482
22:55:20 [train] batch 1200/7649 | loss 1.0497 | acc 0.5505
22:55:23 [train] batch 1400/7649 | loss 1.0492 | acc 0.5520
22:55:26 [train] batch 1600/7649 | loss 1.0492 | acc 0.5531
22:55:29 [train] batch 1800/7649 | loss 1.0490 | acc 0.5538
22:55:33 [train] batch 2000/7649 | loss 1.0489 | acc 0.5537
22:55:36 [train] batch 2200/7649 | loss 1.0491 | acc 0.5537
22:55:39 [train] batch 2400/7649 | loss 1.0489 | acc 0.5548
22:55:42 [train] batch 2600/7649 | loss 1.0489 | acc 0.5556
22:55:46 [train] batch 2800/7649 | loss 1.0487 | acc 0.5566
22:55:49 [train] batch 3000/7649 | loss 1.0486 | acc 0.5568
22:55:52 [train] batch 3200/7649 | loss 1.0486 | acc 0.5566
22:55:56 [train] batch 3400/7649 | loss 1.0485 | acc 0.5566
22:55:59 [train] batch 3600/7649 | loss 1.0484 | acc 0.5567
22:56:02 [train] batch 3800/7649 | loss 1.0485 | acc 0.5563
22:56:05 [train] batch 4000/7649 | loss 1.0485 | acc 0.5562
22:56:09 [train] batch 4200/7649 | loss 1.0485 | acc 0.5561
22:56:12 [train] batch 4400/7649 | loss 1.0485 | acc 0.5560
22:56:15 [train] batch 4600/7649 | loss 1.0484 | acc 0.5563
22:56:19 [train] batch 4800/7649 | loss 1.0483 | acc 0.5565
22:56:22 [train] batch 5000/7649 | loss 1.0484 | acc 0.5565
22:56:25 [train] batch 5200/7649 | loss 1.0483 | acc 0.5565
22:56:28 [train] batch 5400/7649 | loss 1.0482 | acc 0.5567
22:56:32 [train] batch 5600/7649 | loss 1.0483 | acc 0.5569
22:56:35 [train] batch 5800/7649 | loss 1.0483 | acc 0.5574
22:56:38 [train] batch 6000/7649 | loss 1.0483 | acc 0.5574
22:56:41 [train] batch 6200/7649 | loss 1.0482 | acc 0.5576
22:56:45 [train] batch 6400/7649 | loss 1.0482 | acc 0.5574
22:56:48 [train] batch 6600/7649 | loss 1.0482 | acc 0.5573
22:56:51 [train] batch 6800/7649 | loss 1.0481 | acc 0.5574
22:56:55 [train] batch 7000/7649 | loss 1.0481 | acc 0.5576
22:56:58 [train] batch 7200/7649 | loss 1.0480 | acc 0.5580
22:57:01 [train] batch 7400/7649 | loss 1.0480 | acc 0.5582
22:57:04 [train] batch 7600/7649 | loss 1.0480 | acc 0.5583
22:57:05 [train] batch 7649/7649 | loss 1.0479 | acc 0.5584
22:57:12 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_02.png
22:57:12 Epoch 02 | train 1.0479/0.5584 | val 1.0085/0.5716 | lr 1.00e-05
22:57:12 ✓ save best
22:57:15 [train] batch 200/7649 | loss 1.0454 | acc 0.5675
22:57:19 [train] batch 400/7649 | loss 1.0464 | acc 0.5659
22:57:22 [train] batch 600/7649 | loss 1.0466 | acc 0.5664
22:57:25 [train] batch 800/7649 | loss 1.0468 | acc 0.5669
22:57:28 [train] batch 1000/7649 | loss 1.0469 | acc 0.5683
22:57:32 [train] batch 1200/7649 | loss 1.0469 | acc 0.5677
22:57:35 [train] batch 1400/7649 | loss 1.0470 | acc 0.5659
22:57:38 [train] batch 1600/7649 | loss 1.0469 | acc 0.5662
22:57:42 [train] batch 1800/7649 | loss 1.0466 | acc 0.5668
22:57:45 [train] batch 2000/7649 | loss 1.0468 | acc 0.5657
22:57:48 [train] batch 2200/7649 | loss 1.0466 | acc 0.5652
22:57:52 [train] batch 2400/7649 | loss 1.0466 | acc 0.5642
22:57:55 [train] batch 2600/7649 | loss 1.0468 | acc 0.5633
22:57:58 [train] batch 2800/7649 | loss 1.0467 | acc 0.5636
22:58:02 [train] batch 3000/7649 | loss 1.0466 | acc 0.5633
22:58:05 [train] batch 3200/7649 | loss 1.0465 | acc 0.5633
22:58:08 [train] batch 3400/7649 | loss 1.0467 | acc 0.5632
22:58:11 [train] batch 3600/7649 | loss 1.0467 | acc 0.5632
22:58:15 [train] batch 3800/7649 | loss 1.0469 | acc 0.5632
22:58:18 [train] batch 4000/7649 | loss 1.0467 | acc 0.5637
22:58:21 [train] batch 4200/7649 | loss 1.0467 | acc 0.5636
22:58:24 [train] batch 4400/7649 | loss 1.0468 | acc 0.5636
22:58:28 [train] batch 4600/7649 | loss 1.0468 | acc 0.5637
22:58:31 [train] batch 4800/7649 | loss 1.0468 | acc 0.5639
22:58:34 [train] batch 5000/7649 | loss 1.0469 | acc 0.5639
22:58:38 [train] batch 5200/7649 | loss 1.0469 | acc 0.5641
22:58:41 [train] batch 5400/7649 | loss 1.0469 | acc 0.5639
22:58:44 [train] batch 5600/7649 | loss 1.0470 | acc 0.5639
22:58:47 [train] batch 5800/7649 | loss 1.0471 | acc 0.5637
22:58:51 [train] batch 6000/7649 | loss 1.0470 | acc 0.5637
22:58:54 [train] batch 6200/7649 | loss 1.0470 | acc 0.5634
22:58:57 [train] batch 6400/7649 | loss 1.0471 | acc 0.5635
22:59:01 [train] batch 6600/7649 | loss 1.0471 | acc 0.5635
22:59:04 [train] batch 6800/7649 | loss 1.0470 | acc 0.5634
22:59:07 [train] batch 7000/7649 | loss 1.0470 | acc 0.5635
22:59:11 [train] batch 7200/7649 | loss 1.0471 | acc 0.5636
22:59:14 [train] batch 7400/7649 | loss 1.0470 | acc 0.5635
22:59:17 [train] batch 7600/7649 | loss 1.0470 | acc 0.5637
22:59:18 [train] batch 7649/7649 | loss 1.0470 | acc 0.5637
22:59:25 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_03.png
22:59:25 Epoch 03 | train 1.0470/0.5637 | val 1.0101/0.5698 | lr 1.00e-05
22:59:28 [train] batch 200/7649 | loss 1.0463 | acc 0.5613
22:59:31 [train] batch 400/7649 | loss 1.0474 | acc 0.5621
22:59:35 [train] batch 600/7649 | loss 1.0471 | acc 0.5615
22:59:38 [train] batch 800/7649 | loss 1.0472 | acc 0.5624
22:59:41 [train] batch 1000/7649 | loss 1.0470 | acc 0.5636
22:59:44 [train] batch 1200/7649 | loss 1.0470 | acc 0.5654
22:59:48 [train] batch 1400/7649 | loss 1.0473 | acc 0.5651
22:59:51 [train] batch 1600/7649 | loss 1.0471 | acc 0.5644
22:59:54 [train] batch 1800/7649 | loss 1.0471 | acc 0.5645
22:59:57 [train] batch 2000/7649 | loss 1.0474 | acc 0.5645
23:00:01 [train] batch 2200/7649 | loss 1.0475 | acc 0.5645
23:00:04 [train] batch 2400/7649 | loss 1.0474 | acc 0.5644
23:00:08 [train] batch 2600/7649 | loss 1.0475 | acc 0.5645
23:00:11 [train] batch 2800/7649 | loss 1.0475 | acc 0.5649
23:00:14 [train] batch 3000/7649 | loss 1.0475 | acc 0.5652
23:00:17 [train] batch 3200/7649 | loss 1.0474 | acc 0.5649
23:00:21 [train] batch 3400/7649 | loss 1.0474 | acc 0.5650
23:00:24 [train] batch 3600/7649 | loss 1.0474 | acc 0.5648
23:00:27 [train] batch 3800/7649 | loss 1.0473 | acc 0.5647
23:00:31 [train] batch 4000/7649 | loss 1.0473 | acc 0.5645
23:00:34 [train] batch 4200/7649 | loss 1.0472 | acc 0.5645
23:00:37 [train] batch 4400/7649 | loss 1.0471 | acc 0.5646
23:00:40 [train] batch 4600/7649 | loss 1.0470 | acc 0.5651
23:00:44 [train] batch 4800/7649 | loss 1.0470 | acc 0.5654
23:00:47 [train] batch 5000/7649 | loss 1.0470 | acc 0.5654
23:00:50 [train] batch 5200/7649 | loss 1.0470 | acc 0.5655
23:00:53 [train] batch 5400/7649 | loss 1.0468 | acc 0.5653
23:00:57 [train] batch 5600/7649 | loss 1.0467 | acc 0.5652
23:01:00 [train] batch 5800/7649 | loss 1.0468 | acc 0.5651
23:01:03 [train] batch 6000/7649 | loss 1.0467 | acc 0.5651
23:01:06 [train] batch 6200/7649 | loss 1.0467 | acc 0.5653
23:01:10 [train] batch 6400/7649 | loss 1.0467 | acc 0.5652
23:01:13 [train] batch 6600/7649 | loss 1.0467 | acc 0.5653
23:01:16 [train] batch 6800/7649 | loss 1.0466 | acc 0.5655
23:01:20 [train] batch 7000/7649 | loss 1.0467 | acc 0.5654
23:01:23 [train] batch 7200/7649 | loss 1.0466 | acc 0.5656
23:01:26 [train] batch 7400/7649 | loss 1.0466 | acc 0.5657
23:01:30 [train] batch 7600/7649 | loss 1.0466 | acc 0.5657
23:01:30 [train] batch 7649/7649 | loss 1.0465 | acc 0.5657
23:01:37 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_04.png
23:01:37 Epoch 04 | train 1.0465/0.5657 | val 1.0111/0.5640 | lr 1.00e-05
23:01:40 [train] batch 200/7649 | loss 1.0480 | acc 0.5588
23:01:44 [train] batch 400/7649 | loss 1.0464 | acc 0.5626
23:01:47 [train] batch 600/7649 | loss 1.0463 | acc 0.5646
23:01:50 [train] batch 800/7649 | loss 1.0455 | acc 0.5668
23:01:54 [train] batch 1000/7649 | loss 1.0459 | acc 0.5681
23:01:57 [train] batch 1200/7649 | loss 1.0457 | acc 0.5695
23:02:00 [train] batch 1400/7649 | loss 1.0457 | acc 0.5683
23:02:03 [train] batch 1600/7649 | loss 1.0459 | acc 0.5670
23:02:07 [train] batch 1800/7649 | loss 1.0459 | acc 0.5664
23:02:10 [train] batch 2000/7649 | loss 1.0461 | acc 0.5661
23:02:13 [train] batch 2200/7649 | loss 1.0462 | acc 0.5654
23:02:17 [train] batch 2400/7649 | loss 1.0462 | acc 0.5650
23:02:20 [train] batch 2600/7649 | loss 1.0462 | acc 0.5651
23:02:23 [train] batch 2800/7649 | loss 1.0463 | acc 0.5649
23:02:27 [train] batch 3000/7649 | loss 1.0462 | acc 0.5655
23:02:30 [train] batch 3200/7649 | loss 1.0463 | acc 0.5654
23:02:33 [train] batch 3400/7649 | loss 1.0463 | acc 0.5654
23:02:36 [train] batch 3600/7649 | loss 1.0462 | acc 0.5652
23:02:40 [train] batch 3800/7649 | loss 1.0461 | acc 0.5655
23:02:43 [train] batch 4000/7649 | loss 1.0459 | acc 0.5660
23:02:46 [train] batch 4200/7649 | loss 1.0460 | acc 0.5659
23:02:49 [train] batch 4400/7649 | loss 1.0459 | acc 0.5661
23:02:53 [train] batch 4600/7649 | loss 1.0458 | acc 0.5663
23:02:56 [train] batch 4800/7649 | loss 1.0458 | acc 0.5660
23:02:59 [train] batch 5000/7649 | loss 1.0459 | acc 0.5658
23:03:02 [train] batch 5200/7649 | loss 1.0460 | acc 0.5658
23:03:06 [train] batch 5400/7649 | loss 1.0460 | acc 0.5660
23:03:09 [train] batch 5600/7649 | loss 1.0461 | acc 0.5661
23:03:12 [train] batch 5800/7649 | loss 1.0461 | acc 0.5661
23:03:16 [train] batch 6000/7649 | loss 1.0461 | acc 0.5661
23:03:19 [train] batch 6200/7649 | loss 1.0461 | acc 0.5662
23:03:22 [train] batch 6400/7649 | loss 1.0461 | acc 0.5661
23:03:26 [train] batch 6600/7649 | loss 1.0461 | acc 0.5661
23:03:29 [train] batch 6800/7649 | loss 1.0462 | acc 0.5663
23:03:32 [train] batch 7000/7649 | loss 1.0461 | acc 0.5663
23:03:35 [train] batch 7200/7649 | loss 1.0462 | acc 0.5663
23:03:39 [train] batch 7400/7649 | loss 1.0461 | acc 0.5664
23:03:42 [train] batch 7600/7649 | loss 1.0461 | acc 0.5666
23:03:43 [train] batch 7649/7649 | loss 1.0461 | acc 0.5666
23:03:49 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_05.png
23:03:49 Epoch 05 | train 1.0461/0.5666 | val 1.0107/0.5758 | lr 5.00e-06
23:03:49 ✓ save best
23:03:53 [train] batch 200/7649 | loss 1.0472 | acc 0.5668
23:03:56 [train] batch 400/7649 | loss 1.0481 | acc 0.5598
23:03:59 [train] batch 600/7649 | loss 1.0467 | acc 0.5633
23:04:03 [train] batch 800/7649 | loss 1.0456 | acc 0.5643
23:04:06 [train] batch 1000/7649 | loss 1.0455 | acc 0.5640
23:04:09 [train] batch 1200/7649 | loss 1.0457 | acc 0.5634
23:04:13 [train] batch 1400/7649 | loss 1.0463 | acc 0.5633
23:04:16 [train] batch 1600/7649 | loss 1.0463 | acc 0.5640
23:04:19 [train] batch 1800/7649 | loss 1.0462 | acc 0.5649
23:04:23 [train] batch 2000/7649 | loss 1.0464 | acc 0.5651
23:04:26 [train] batch 2200/7649 | loss 1.0464 | acc 0.5652
23:04:29 [train] batch 2400/7649 | loss 1.0467 | acc 0.5649
23:04:32 [train] batch 2600/7649 | loss 1.0465 | acc 0.5650
23:04:36 [train] batch 2800/7649 | loss 1.0462 | acc 0.5660
23:04:39 [train] batch 3000/7649 | loss 1.0462 | acc 0.5663
23:04:42 [train] batch 3200/7649 | loss 1.0462 | acc 0.5662
23:04:46 [train] batch 3400/7649 | loss 1.0460 | acc 0.5665
23:04:49 [train] batch 3600/7649 | loss 1.0460 | acc 0.5665
23:04:52 [train] batch 3800/7649 | loss 1.0460 | acc 0.5664
23:04:55 [train] batch 4000/7649 | loss 1.0459 | acc 0.5664
23:04:59 [train] batch 4200/7649 | loss 1.0459 | acc 0.5661
23:05:02 [train] batch 4400/7649 | loss 1.0458 | acc 0.5659
23:05:05 [train] batch 4600/7649 | loss 1.0456 | acc 0.5661
23:05:08 [train] batch 4800/7649 | loss 1.0456 | acc 0.5662
23:05:12 [train] batch 5000/7649 | loss 1.0456 | acc 0.5663
23:05:15 [train] batch 5200/7649 | loss 1.0456 | acc 0.5664
23:05:18 [train] batch 5400/7649 | loss 1.0456 | acc 0.5663
23:05:22 [train] batch 5600/7649 | loss 1.0455 | acc 0.5665
23:05:25 [train] batch 5800/7649 | loss 1.0455 | acc 0.5664
23:05:28 [train] batch 6000/7649 | loss 1.0455 | acc 0.5664
23:05:32 [train] batch 6200/7649 | loss 1.0456 | acc 0.5662
23:05:35 [train] batch 6400/7649 | loss 1.0457 | acc 0.5659
23:05:38 [train] batch 6600/7649 | loss 1.0457 | acc 0.5659
23:05:41 [train] batch 6800/7649 | loss 1.0456 | acc 0.5661
23:05:45 [train] batch 7000/7649 | loss 1.0457 | acc 0.5661
23:05:48 [train] batch 7200/7649 | loss 1.0456 | acc 0.5663
23:05:51 [train] batch 7400/7649 | loss 1.0458 | acc 0.5661
23:05:54 [train] batch 7600/7649 | loss 1.0458 | acc 0.5661
23:05:55 [train] batch 7649/7649 | loss 1.0458 | acc 0.5663
23:06:02 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_06.png
23:06:02 Epoch 06 | train 1.0458/0.5663 | val 1.0095/0.5794 | lr 5.00e-06
23:06:02 ✓ save best
23:06:05 [train] batch 200/7649 | loss 1.0421 | acc 0.5744
23:06:09 [train] batch 400/7649 | loss 1.0442 | acc 0.5720
23:06:12 [train] batch 600/7649 | loss 1.0453 | acc 0.5669
23:06:15 [train] batch 800/7649 | loss 1.0451 | acc 0.5662
23:06:19 [train] batch 1000/7649 | loss 1.0449 | acc 0.5672
23:06:22 [train] batch 1200/7649 | loss 1.0449 | acc 0.5686
23:06:25 [train] batch 1400/7649 | loss 1.0447 | acc 0.5690
23:06:29 [train] batch 1600/7649 | loss 1.0451 | acc 0.5674
23:06:32 [train] batch 1800/7649 | loss 1.0454 | acc 0.5666
23:06:35 [train] batch 2000/7649 | loss 1.0455 | acc 0.5656
23:06:38 [train] batch 2200/7649 | loss 1.0455 | acc 0.5655
23:06:42 [train] batch 2400/7649 | loss 1.0455 | acc 0.5659
23:06:45 [train] batch 2600/7649 | loss 1.0456 | acc 0.5657
23:06:48 [train] batch 2800/7649 | loss 1.0456 | acc 0.5663
23:06:52 [train] batch 3000/7649 | loss 1.0458 | acc 0.5661
23:06:55 [train] batch 3200/7649 | loss 1.0458 | acc 0.5659
23:06:58 [train] batch 3400/7649 | loss 1.0459 | acc 0.5663
23:07:01 [train] batch 3600/7649 | loss 1.0459 | acc 0.5665
23:07:05 [train] batch 3800/7649 | loss 1.0460 | acc 0.5663
23:07:08 [train] batch 4000/7649 | loss 1.0460 | acc 0.5661
23:07:11 [train] batch 4200/7649 | loss 1.0460 | acc 0.5661
23:07:14 [train] batch 4400/7649 | loss 1.0459 | acc 0.5661
23:07:18 [train] batch 4600/7649 | loss 1.0458 | acc 0.5661
23:07:21 [train] batch 4800/7649 | loss 1.0457 | acc 0.5665
23:07:24 [train] batch 5000/7649 | loss 1.0458 | acc 0.5666
23:07:28 [train] batch 5200/7649 | loss 1.0459 | acc 0.5666
23:07:31 [train] batch 5400/7649 | loss 1.0458 | acc 0.5668
23:07:34 [train] batch 5600/7649 | loss 1.0458 | acc 0.5669
23:07:38 [train] batch 5800/7649 | loss 1.0458 | acc 0.5668
23:07:41 [train] batch 6000/7649 | loss 1.0457 | acc 0.5670
23:07:44 [train] batch 6200/7649 | loss 1.0457 | acc 0.5672
23:07:47 [train] batch 6400/7649 | loss 1.0457 | acc 0.5671
23:07:51 [train] batch 6600/7649 | loss 1.0457 | acc 0.5670
23:07:54 [train] batch 6800/7649 | loss 1.0457 | acc 0.5669
23:07:57 [train] batch 7000/7649 | loss 1.0457 | acc 0.5671
23:08:00 [train] batch 7200/7649 | loss 1.0457 | acc 0.5671
23:08:04 [train] batch 7400/7649 | loss 1.0457 | acc 0.5671
23:08:07 [train] batch 7600/7649 | loss 1.0457 | acc 0.5671
23:08:08 [train] batch 7649/7649 | loss 1.0457 | acc 0.5672
23:08:15 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_07.png
23:08:15 Epoch 07 | train 1.0457/0.5672 | val 1.0101/0.5744 | lr 5.00e-06
23:08:18 [train] batch 200/7649 | loss 1.0442 | acc 0.5754
23:08:21 [train] batch 400/7649 | loss 1.0448 | acc 0.5773
23:08:25 [train] batch 600/7649 | loss 1.0454 | acc 0.5735
23:08:28 [train] batch 800/7649 | loss 1.0449 | acc 0.5741
23:08:32 [train] batch 1000/7649 | loss 1.0451 | acc 0.5726
23:08:35 [train] batch 1200/7649 | loss 1.0451 | acc 0.5720
23:08:38 [train] batch 1400/7649 | loss 1.0456 | acc 0.5710
23:08:41 [train] batch 1600/7649 | loss 1.0452 | acc 0.5710
23:08:45 [train] batch 1800/7649 | loss 1.0452 | acc 0.5702
23:08:48 [train] batch 2000/7649 | loss 1.0453 | acc 0.5692
23:08:51 [train] batch 2200/7649 | loss 1.0453 | acc 0.5694
23:08:54 [train] batch 2400/7649 | loss 1.0454 | acc 0.5691
23:08:58 [train] batch 2600/7649 | loss 1.0454 | acc 0.5689
23:09:01 [train] batch 2800/7649 | loss 1.0454 | acc 0.5688
23:09:04 [train] batch 3000/7649 | loss 1.0456 | acc 0.5688
23:09:07 [train] batch 3200/7649 | loss 1.0457 | acc 0.5686
23:09:11 [train] batch 3400/7649 | loss 1.0458 | acc 0.5686
23:09:14 [train] batch 3600/7649 | loss 1.0458 | acc 0.5684
23:09:17 [train] batch 3800/7649 | loss 1.0457 | acc 0.5683
23:09:21 [train] batch 4000/7649 | loss 1.0457 | acc 0.5678
23:09:24 [train] batch 4200/7649 | loss 1.0457 | acc 0.5675
23:09:27 [train] batch 4400/7649 | loss 1.0457 | acc 0.5673
23:09:30 [train] batch 4600/7649 | loss 1.0456 | acc 0.5673
23:09:34 [train] batch 4800/7649 | loss 1.0456 | acc 0.5671
23:09:37 [train] batch 5000/7649 | loss 1.0456 | acc 0.5669
23:09:40 [train] batch 5200/7649 | loss 1.0456 | acc 0.5668
23:09:44 [train] batch 5400/7649 | loss 1.0456 | acc 0.5666
23:09:47 [train] batch 5600/7649 | loss 1.0456 | acc 0.5666
23:09:50 [train] batch 5800/7649 | loss 1.0455 | acc 0.5667
23:09:53 [train] batch 6000/7649 | loss 1.0455 | acc 0.5668
23:09:57 [train] batch 6200/7649 | loss 1.0454 | acc 0.5670
23:10:00 [train] batch 6400/7649 | loss 1.0455 | acc 0.5669
23:10:03 [train] batch 6600/7649 | loss 1.0455 | acc 0.5668
23:10:06 [train] batch 6800/7649 | loss 1.0455 | acc 0.5668
23:10:10 [train] batch 7000/7649 | loss 1.0454 | acc 0.5670
23:10:13 [train] batch 7200/7649 | loss 1.0454 | acc 0.5669
23:10:16 [train] batch 7400/7649 | loss 1.0455 | acc 0.5668
23:10:20 [train] batch 7600/7649 | loss 1.0455 | acc 0.5669
23:10:20 [train] batch 7649/7649 | loss 1.0455 | acc 0.5670
23:10:27 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_08.png
23:10:27 Epoch 08 | train 1.0455/0.5670 | val 1.0135/0.5605 | lr 5.00e-06
23:10:31 [train] batch 200/7649 | loss 1.0464 | acc 0.5641
23:10:34 [train] batch 400/7649 | loss 1.0466 | acc 0.5654
23:10:37 [train] batch 600/7649 | loss 1.0474 | acc 0.5652
23:10:41 [train] batch 800/7649 | loss 1.0464 | acc 0.5667
23:10:44 [train] batch 1000/7649 | loss 1.0463 | acc 0.5672
23:10:47 [train] batch 1200/7649 | loss 1.0464 | acc 0.5673
23:10:51 [train] batch 1400/7649 | loss 1.0461 | acc 0.5680
23:10:54 [train] batch 1600/7649 | loss 1.0460 | acc 0.5684
23:10:57 [train] batch 1800/7649 | loss 1.0460 | acc 0.5679
23:11:01 [train] batch 2000/7649 | loss 1.0458 | acc 0.5673
23:11:04 [train] batch 2200/7649 | loss 1.0460 | acc 0.5668
23:11:07 [train] batch 2400/7649 | loss 1.0460 | acc 0.5667
23:11:10 [train] batch 2600/7649 | loss 1.0461 | acc 0.5666
23:11:14 [train] batch 2800/7649 | loss 1.0461 | acc 0.5665
23:11:17 [train] batch 3000/7649 | loss 1.0460 | acc 0.5667
23:11:20 [train] batch 3200/7649 | loss 1.0461 | acc 0.5661
23:11:23 [train] batch 3400/7649 | loss 1.0461 | acc 0.5659
23:11:27 [train] batch 3600/7649 | loss 1.0460 | acc 0.5658
23:11:30 [train] batch 3800/7649 | loss 1.0460 | acc 0.5658
23:11:33 [train] batch 4000/7649 | loss 1.0459 | acc 0.5660
23:11:37 [train] batch 4200/7649 | loss 1.0459 | acc 0.5664
23:11:40 [train] batch 4400/7649 | loss 1.0459 | acc 0.5667
23:11:43 [train] batch 4600/7649 | loss 1.0458 | acc 0.5670
23:11:46 [train] batch 4800/7649 | loss 1.0458 | acc 0.5670
23:11:50 [train] batch 5000/7649 | loss 1.0458 | acc 0.5671
23:11:53 [train] batch 5200/7649 | loss 1.0458 | acc 0.5672
23:11:57 [train] batch 5400/7649 | loss 1.0458 | acc 0.5671
23:12:00 [train] batch 5600/7649 | loss 1.0458 | acc 0.5671
23:12:03 [train] batch 5800/7649 | loss 1.0457 | acc 0.5671
23:12:06 [train] batch 6000/7649 | loss 1.0457 | acc 0.5674
23:12:10 [train] batch 6200/7649 | loss 1.0457 | acc 0.5676
23:12:13 [train] batch 6400/7649 | loss 1.0457 | acc 0.5675
23:12:16 [train] batch 6600/7649 | loss 1.0457 | acc 0.5674
23:12:20 [train] batch 6800/7649 | loss 1.0457 | acc 0.5673
23:12:23 [train] batch 7000/7649 | loss 1.0456 | acc 0.5672
23:12:26 [train] batch 7200/7649 | loss 1.0456 | acc 0.5675
23:12:29 [train] batch 7400/7649 | loss 1.0456 | acc 0.5675
23:12:33 [train] batch 7600/7649 | loss 1.0455 | acc 0.5675
23:12:34 [train] batch 7649/7649 | loss 1.0455 | acc 0.5676
23:12:41 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_09.png
23:12:41 Epoch 09 | train 1.0455/0.5676 | val 1.0100/0.5642 | lr 2.50e-06
23:12:44 [train] batch 200/7649 | loss 1.0467 | acc 0.5640
23:12:47 [train] batch 400/7649 | loss 1.0457 | acc 0.5649
23:12:51 [train] batch 600/7649 | loss 1.0449 | acc 0.5663
23:12:54 [train] batch 800/7649 | loss 1.0452 | acc 0.5653
23:12:58 [train] batch 1000/7649 | loss 1.0452 | acc 0.5656
23:13:01 [train] batch 1200/7649 | loss 1.0455 | acc 0.5658
23:13:04 [train] batch 1400/7649 | loss 1.0452 | acc 0.5659
23:13:07 [train] batch 1600/7649 | loss 1.0451 | acc 0.5657
23:13:11 [train] batch 1800/7649 | loss 1.0454 | acc 0.5658
23:13:14 [train] batch 2000/7649 | loss 1.0454 | acc 0.5661
23:13:17 [train] batch 2200/7649 | loss 1.0455 | acc 0.5665
23:13:20 [train] batch 2400/7649 | loss 1.0456 | acc 0.5666
23:13:24 [train] batch 2600/7649 | loss 1.0456 | acc 0.5669
23:13:27 [train] batch 2800/7649 | loss 1.0456 | acc 0.5672
23:13:30 [train] batch 3000/7649 | loss 1.0455 | acc 0.5673
23:13:34 [train] batch 3200/7649 | loss 1.0456 | acc 0.5674
23:13:37 [train] batch 3400/7649 | loss 1.0456 | acc 0.5677
23:13:40 [train] batch 3600/7649 | loss 1.0456 | acc 0.5681
23:13:43 [train] batch 3800/7649 | loss 1.0456 | acc 0.5682
23:13:47 [train] batch 4000/7649 | loss 1.0454 | acc 0.5686
23:13:50 [train] batch 4200/7649 | loss 1.0455 | acc 0.5685
23:13:53 [train] batch 4400/7649 | loss 1.0456 | acc 0.5683
23:13:56 [train] batch 4600/7649 | loss 1.0456 | acc 0.5679
23:14:00 [train] batch 4800/7649 | loss 1.0457 | acc 0.5679
23:14:03 [train] batch 5000/7649 | loss 1.0455 | acc 0.5680
23:14:06 [train] batch 5200/7649 | loss 1.0455 | acc 0.5679
23:14:10 [train] batch 5400/7649 | loss 1.0454 | acc 0.5679
23:14:13 [train] batch 5600/7649 | loss 1.0454 | acc 0.5678
23:14:16 [train] batch 5800/7649 | loss 1.0454 | acc 0.5677
23:14:20 [train] batch 6000/7649 | loss 1.0454 | acc 0.5678
23:14:23 [train] batch 6200/7649 | loss 1.0454 | acc 0.5678
23:14:26 [train] batch 6400/7649 | loss 1.0454 | acc 0.5678
23:14:29 [train] batch 6600/7649 | loss 1.0454 | acc 0.5678
23:14:33 [train] batch 6800/7649 | loss 1.0455 | acc 0.5677
23:14:36 [train] batch 7000/7649 | loss 1.0454 | acc 0.5677
23:14:39 [train] batch 7200/7649 | loss 1.0454 | acc 0.5675
23:14:43 [train] batch 7400/7649 | loss 1.0454 | acc 0.5674
23:14:46 [train] batch 7600/7649 | loss 1.0454 | acc 0.5675
23:14:47 [train] batch 7649/7649 | loss 1.0454 | acc 0.5674
23:14:54 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_10.png
23:14:54 Epoch 10 | train 1.0454/0.5674 | val 1.0122/0.5603 | lr 2.50e-06
23:14:57 [train] batch 200/7649 | loss 1.0471 | acc 0.5620
23:15:01 [train] batch 400/7649 | loss 1.0456 | acc 0.5658
23:15:04 [train] batch 600/7649 | loss 1.0448 | acc 0.5684
23:15:07 [train] batch 800/7649 | loss 1.0445 | acc 0.5685
23:15:11 [train] batch 1000/7649 | loss 1.0448 | acc 0.5680
23:15:14 [train] batch 1200/7649 | loss 1.0444 | acc 0.5681
23:15:17 [train] batch 1400/7649 | loss 1.0443 | acc 0.5681
23:15:20 [train] batch 1600/7649 | loss 1.0446 | acc 0.5673
23:15:24 [train] batch 1800/7649 | loss 1.0447 | acc 0.5676
23:15:27 [train] batch 2000/7649 | loss 1.0447 | acc 0.5676
23:15:30 [train] batch 2200/7649 | loss 1.0446 | acc 0.5674
23:15:33 [train] batch 2400/7649 | loss 1.0446 | acc 0.5674
23:15:37 [train] batch 2600/7649 | loss 1.0448 | acc 0.5673
23:15:40 [train] batch 2800/7649 | loss 1.0448 | acc 0.5672
23:15:43 [train] batch 3000/7649 | loss 1.0449 | acc 0.5670
23:15:47 [train] batch 3200/7649 | loss 1.0450 | acc 0.5666
23:15:50 [train] batch 3400/7649 | loss 1.0449 | acc 0.5667
23:15:53 [train] batch 3600/7649 | loss 1.0448 | acc 0.5670
23:15:56 [train] batch 3800/7649 | loss 1.0448 | acc 0.5673
23:16:00 [train] batch 4000/7649 | loss 1.0450 | acc 0.5671
23:16:03 [train] batch 4200/7649 | loss 1.0450 | acc 0.5672
23:16:06 [train] batch 4400/7649 | loss 1.0450 | acc 0.5673
23:16:10 [train] batch 4600/7649 | loss 1.0451 | acc 0.5672
23:16:13 [train] batch 4800/7649 | loss 1.0452 | acc 0.5672
23:16:16 [train] batch 5000/7649 | loss 1.0453 | acc 0.5674
23:16:20 [train] batch 5200/7649 | loss 1.0453 | acc 0.5677
23:16:23 [train] batch 5400/7649 | loss 1.0452 | acc 0.5679
23:16:26 [train] batch 5600/7649 | loss 1.0452 | acc 0.5680
23:16:29 [train] batch 5800/7649 | loss 1.0452 | acc 0.5680
23:16:33 [train] batch 6000/7649 | loss 1.0452 | acc 0.5681
23:16:36 [train] batch 6200/7649 | loss 1.0453 | acc 0.5678
23:16:39 [train] batch 6400/7649 | loss 1.0453 | acc 0.5676
23:16:42 [train] batch 6600/7649 | loss 1.0453 | acc 0.5676
23:16:46 [train] batch 6800/7649 | loss 1.0454 | acc 0.5677
23:16:49 [train] batch 7000/7649 | loss 1.0454 | acc 0.5677
23:16:52 [train] batch 7200/7649 | loss 1.0453 | acc 0.5675
23:16:56 [train] batch 7400/7649 | loss 1.0453 | acc 0.5676
23:16:59 [train] batch 7600/7649 | loss 1.0453 | acc 0.5677
23:17:00 [train] batch 7649/7649 | loss 1.0453 | acc 0.5677
23:17:07 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_11.png
23:17:07 Epoch 11 | train 1.0453/0.5677 | val 1.0119/0.5675 | lr 2.50e-06
23:17:10 [train] batch 200/7649 | loss 1.0444 | acc 0.5751
23:17:14 [train] batch 400/7649 | loss 1.0458 | acc 0.5704
23:17:17 [train] batch 600/7649 | loss 1.0470 | acc 0.5668
23:17:20 [train] batch 800/7649 | loss 1.0464 | acc 0.5660
23:17:24 [train] batch 1000/7649 | loss 1.0462 | acc 0.5673
23:17:27 [train] batch 1200/7649 | loss 1.0464 | acc 0.5676
23:17:30 [train] batch 1400/7649 | loss 1.0465 | acc 0.5671
23:17:33 [train] batch 1600/7649 | loss 1.0463 | acc 0.5666
23:17:37 [train] batch 1800/7649 | loss 1.0462 | acc 0.5670
23:17:40 [train] batch 2000/7649 | loss 1.0459 | acc 0.5670
23:17:43 [train] batch 2200/7649 | loss 1.0461 | acc 0.5667
23:17:46 [train] batch 2400/7649 | loss 1.0458 | acc 0.5675
23:17:50 [train] batch 2600/7649 | loss 1.0457 | acc 0.5675
23:17:53 [train] batch 2800/7649 | loss 1.0457 | acc 0.5679
23:17:56 [train] batch 3000/7649 | loss 1.0456 | acc 0.5678
23:17:59 [train] batch 3200/7649 | loss 1.0455 | acc 0.5678
23:18:03 [train] batch 3400/7649 | loss 1.0456 | acc 0.5676
23:18:06 [train] batch 3600/7649 | loss 1.0454 | acc 0.5678
23:18:09 [train] batch 3800/7649 | loss 1.0455 | acc 0.5674
23:18:13 [train] batch 4000/7649 | loss 1.0455 | acc 0.5674
23:18:16 [train] batch 4200/7649 | loss 1.0455 | acc 0.5673
23:18:19 [train] batch 4400/7649 | loss 1.0454 | acc 0.5674
23:18:22 [train] batch 4600/7649 | loss 1.0455 | acc 0.5673
23:18:26 [train] batch 4800/7649 | loss 1.0455 | acc 0.5674
23:18:29 [train] batch 5000/7649 | loss 1.0454 | acc 0.5678
23:18:32 [train] batch 5200/7649 | loss 1.0454 | acc 0.5678
23:18:35 [train] batch 5400/7649 | loss 1.0453 | acc 0.5679
23:18:39 [train] batch 5600/7649 | loss 1.0453 | acc 0.5679
23:18:42 [train] batch 5800/7649 | loss 1.0452 | acc 0.5680
23:18:45 [train] batch 6000/7649 | loss 1.0452 | acc 0.5681
23:18:49 [train] batch 6200/7649 | loss 1.0452 | acc 0.5681
23:18:52 [train] batch 6400/7649 | loss 1.0452 | acc 0.5678
23:18:55 [train] batch 6600/7649 | loss 1.0453 | acc 0.5677
23:18:58 [train] batch 6800/7649 | loss 1.0453 | acc 0.5676
23:19:02 [train] batch 7000/7649 | loss 1.0452 | acc 0.5678
23:19:05 [train] batch 7200/7649 | loss 1.0452 | acc 0.5677
23:19:08 [train] batch 7400/7649 | loss 1.0452 | acc 0.5678
23:19:11 [train] batch 7600/7649 | loss 1.0451 | acc 0.5680
23:19:12 [train] batch 7649/7649 | loss 1.0451 | acc 0.5680
23:19:20 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_12.png
23:19:20 Epoch 12 | train 1.0451/0.5680 | val 1.0127/0.5619 | lr 2.50e-06
23:19:23 [train] batch 200/7649 | loss 1.0427 | acc 0.5706
23:19:26 [train] batch 400/7649 | loss 1.0435 | acc 0.5683
23:19:30 [train] batch 600/7649 | loss 1.0431 | acc 0.5699
23:19:33 [train] batch 800/7649 | loss 1.0433 | acc 0.5694
23:19:36 [train] batch 1000/7649 | loss 1.0438 | acc 0.5690
23:19:39 [train] batch 1200/7649 | loss 1.0435 | acc 0.5702
23:19:43 [train] batch 1400/7649 | loss 1.0437 | acc 0.5706
23:19:46 [train] batch 1600/7649 | loss 1.0441 | acc 0.5701
23:19:49 [train] batch 1800/7649 | loss 1.0442 | acc 0.5702
23:19:53 [train] batch 2000/7649 | loss 1.0443 | acc 0.5705
23:19:56 [train] batch 2200/7649 | loss 1.0444 | acc 0.5704
23:19:59 [train] batch 2400/7649 | loss 1.0447 | acc 0.5697
23:20:03 [train] batch 2600/7649 | loss 1.0446 | acc 0.5701
23:20:06 [train] batch 2800/7649 | loss 1.0447 | acc 0.5700
23:20:09 [train] batch 3000/7649 | loss 1.0447 | acc 0.5696
23:20:12 [train] batch 3200/7649 | loss 1.0447 | acc 0.5697
23:20:16 [train] batch 3400/7649 | loss 1.0449 | acc 0.5693
23:20:19 [train] batch 3600/7649 | loss 1.0447 | acc 0.5698
23:20:22 [train] batch 3800/7649 | loss 1.0450 | acc 0.5694
23:20:26 [train] batch 4000/7649 | loss 1.0450 | acc 0.5692
23:20:29 [train] batch 4200/7649 | loss 1.0449 | acc 0.5692
23:20:32 [train] batch 4400/7649 | loss 1.0450 | acc 0.5690
23:20:35 [train] batch 4600/7649 | loss 1.0451 | acc 0.5686
23:20:39 [train] batch 4800/7649 | loss 1.0451 | acc 0.5686
23:20:42 [train] batch 5000/7649 | loss 1.0451 | acc 0.5685
23:20:45 [train] batch 5200/7649 | loss 1.0450 | acc 0.5684
23:20:48 [train] batch 5400/7649 | loss 1.0450 | acc 0.5685
23:20:52 [train] batch 5600/7649 | loss 1.0449 | acc 0.5685
23:20:55 [train] batch 5800/7649 | loss 1.0450 | acc 0.5684
23:20:58 [train] batch 6000/7649 | loss 1.0450 | acc 0.5684
23:21:02 [train] batch 6200/7649 | loss 1.0450 | acc 0.5683
23:21:05 [train] batch 6400/7649 | loss 1.0450 | acc 0.5682
23:21:08 [train] batch 6600/7649 | loss 1.0450 | acc 0.5682
23:21:11 [train] batch 6800/7649 | loss 1.0450 | acc 0.5681
23:21:15 [train] batch 7000/7649 | loss 1.0450 | acc 0.5681
23:21:18 [train] batch 7200/7649 | loss 1.0450 | acc 0.5681
23:21:21 [train] batch 7400/7649 | loss 1.0450 | acc 0.5681
23:21:25 [train] batch 7600/7649 | loss 1.0450 | acc 0.5681
23:21:25 [train] batch 7649/7649 | loss 1.0450 | acc 0.5680
23:21:32 ✔ saved validation confusion matrix → confusion_val/run_20250524_225249/epoch_13.png
23:21:32 Epoch 13 | train 1.0450/0.5680 | val 1.0145/0.5539 | lr 1.25e-06
23:21:32 Early-stop
23:21:33 [eval ] batch 200/2185 | loss 1.0821 | acc 0.4402
23:21:34 [eval ] batch 400/2185 | loss 1.0317 | acc 0.5633
23:21:35 [eval ] batch 600/2185 | loss 1.0265 | acc 0.5710
23:21:36 [eval ] batch 800/2185 | loss 1.0365 | acc 0.5508
23:21:37 [eval ] batch 1000/2185 | loss 1.0369 | acc 0.5611
23:21:39 [eval ] batch 1200/2185 | loss 1.0302 | acc 0.5807
23:21:40 [eval ] batch 1400/2185 | loss 1.0352 | acc 0.5657
23:21:41 [eval ] batch 1600/2185 | loss 1.0369 | acc 0.5636
23:21:42 [eval ] batch 1800/2185 | loss 1.0379 | acc 0.5589
23:21:43 [eval ] batch 2000/2185 | loss 1.0365 | acc 0.5537
23:21:44 [eval ] batch 2185/2185 | loss 1.0368 | acc 0.5563
23:21:44 TEST loss/acc 1.0368/0.5563
23:21:56 Confusion matrix saved ➜ confusion_matrix.png
