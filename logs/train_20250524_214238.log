21:42:38 Log file: logs/train_20250524_214238.log
21:43:10 ✔ Data split: 1958081/279725/559453 rows ➜ splits
21:43:12 train.csv: samples=1957961  class_dist=[ 242173 1465142  250766]
21:43:13 val.csv: samples=279605  class_dist=[ 29458 218014  32253]
21:43:13 test.csv: samples=559333  class_dist=[ 68225 420338  70890]
21:43:18 [train] batch 200/7649 | loss 1.0962 | acc 0.3847
21:43:21 [train] batch 400/7649 | loss 1.0855 | acc 0.3968
21:43:25 [train] batch 600/7649 | loss 1.0813 | acc 0.4085
21:43:28 [train] batch 800/7649 | loss 1.0780 | acc 0.4156
21:43:31 [train] batch 1000/7649 | loss 1.0757 | acc 0.4162
21:43:34 [train] batch 1200/7649 | loss 1.0740 | acc 0.4171
21:43:37 [train] batch 1400/7649 | loss 1.0728 | acc 0.4170
21:43:41 [train] batch 1600/7649 | loss 1.0714 | acc 0.4177
21:43:44 [train] batch 1800/7649 | loss 1.0703 | acc 0.4169
21:43:47 [train] batch 2000/7649 | loss 1.0694 | acc 0.4166
21:43:50 [train] batch 2200/7649 | loss 1.0687 | acc 0.4160
21:43:54 [train] batch 2400/7649 | loss 1.0681 | acc 0.4155
21:43:57 [train] batch 2600/7649 | loss 1.0675 | acc 0.4151
21:44:00 [train] batch 2800/7649 | loss 1.0670 | acc 0.4145
21:44:03 [train] batch 3000/7649 | loss 1.0664 | acc 0.4135
21:44:07 [train] batch 3200/7649 | loss 1.0659 | acc 0.4126
21:44:10 [train] batch 3400/7649 | loss 1.0655 | acc 0.4118
21:44:13 [train] batch 3600/7649 | loss 1.0653 | acc 0.4108
21:44:16 [train] batch 3800/7649 | loss 1.0648 | acc 0.4103
21:44:20 [train] batch 4000/7649 | loss 1.0644 | acc 0.4097
21:44:23 [train] batch 4200/7649 | loss 1.0641 | acc 0.4092
21:44:26 [train] batch 4400/7649 | loss 1.0637 | acc 0.4088
21:44:29 [train] batch 4600/7649 | loss 1.0635 | acc 0.4080
21:44:33 [train] batch 4800/7649 | loss 1.0633 | acc 0.4074
21:44:36 [train] batch 5000/7649 | loss 1.0629 | acc 0.4069
21:44:39 [train] batch 5200/7649 | loss 1.0628 | acc 0.4063
21:44:42 [train] batch 5400/7649 | loss 1.0624 | acc 0.4060
21:44:46 [train] batch 5600/7649 | loss 1.0623 | acc 0.4057
21:44:49 [train] batch 5800/7649 | loss 1.0621 | acc 0.4052
21:44:52 [train] batch 6000/7649 | loss 1.0620 | acc 0.4049
21:44:55 [train] batch 6200/7649 | loss 1.0618 | acc 0.4045
21:44:59 [train] batch 6400/7649 | loss 1.0616 | acc 0.4042
21:45:02 [train] batch 6600/7649 | loss 1.0615 | acc 0.4040
21:45:05 [train] batch 6800/7649 | loss 1.0613 | acc 0.4039
21:45:08 [train] batch 7000/7649 | loss 1.0612 | acc 0.4036
21:45:12 [train] batch 7200/7649 | loss 1.0610 | acc 0.4032
21:45:15 [train] batch 7400/7649 | loss 1.0609 | acc 0.4031
21:45:18 [train] batch 7600/7649 | loss 1.0608 | acc 0.4027
21:45:19 [train] batch 7649/7649 | loss 1.0608 | acc 0.4027
21:45:25 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_01.png
21:45:25 Epoch 01 | train 1.0608/0.4027 | val 1.0418/0.3664 | lr 1.00e-05
21:45:25 ✓ save best
21:45:29 [train] batch 200/7649 | loss 1.0577 | acc 0.3903
21:45:32 [train] batch 400/7649 | loss 1.0570 | acc 0.3917
21:45:35 [train] batch 600/7649 | loss 1.0570 | acc 0.3901
21:45:39 [train] batch 800/7649 | loss 1.0565 | acc 0.3906
21:45:42 [train] batch 1000/7649 | loss 1.0565 | acc 0.3908
21:45:45 [train] batch 1200/7649 | loss 1.0562 | acc 0.3922
21:45:48 [train] batch 1400/7649 | loss 1.0559 | acc 0.3938
21:45:52 [train] batch 1600/7649 | loss 1.0560 | acc 0.3946
21:45:55 [train] batch 1800/7649 | loss 1.0558 | acc 0.3950
21:45:58 [train] batch 2000/7649 | loss 1.0558 | acc 0.3951
21:46:02 [train] batch 2200/7649 | loss 1.0560 | acc 0.3949
21:46:05 [train] batch 2400/7649 | loss 1.0560 | acc 0.3952
21:46:08 [train] batch 2600/7649 | loss 1.0561 | acc 0.3955
21:46:12 [train] batch 2800/7649 | loss 1.0560 | acc 0.3961
21:46:15 [train] batch 3000/7649 | loss 1.0559 | acc 0.3963
21:46:18 [train] batch 3200/7649 | loss 1.0559 | acc 0.3962
21:46:21 [train] batch 3400/7649 | loss 1.0557 | acc 0.3966
21:46:25 [train] batch 3600/7649 | loss 1.0557 | acc 0.3968
21:46:28 [train] batch 3800/7649 | loss 1.0557 | acc 0.3965
21:46:31 [train] batch 4000/7649 | loss 1.0557 | acc 0.3964
21:46:34 [train] batch 4200/7649 | loss 1.0557 | acc 0.3964
21:46:38 [train] batch 4400/7649 | loss 1.0557 | acc 0.3962
21:46:41 [train] batch 4600/7649 | loss 1.0556 | acc 0.3965
21:46:44 [train] batch 4800/7649 | loss 1.0555 | acc 0.3966
21:46:48 [train] batch 5000/7649 | loss 1.0556 | acc 0.3966
21:46:51 [train] batch 5200/7649 | loss 1.0555 | acc 0.3966
21:46:54 [train] batch 5400/7649 | loss 1.0555 | acc 0.3966
21:46:57 [train] batch 5600/7649 | loss 1.0556 | acc 0.3965
21:47:01 [train] batch 5800/7649 | loss 1.0555 | acc 0.3967
21:47:04 [train] batch 6000/7649 | loss 1.0555 | acc 0.3967
21:47:07 [train] batch 6200/7649 | loss 1.0555 | acc 0.3969
21:47:10 [train] batch 6400/7649 | loss 1.0555 | acc 0.3968
21:47:14 [train] batch 6600/7649 | loss 1.0554 | acc 0.3968
21:47:17 [train] batch 6800/7649 | loss 1.0554 | acc 0.3969
21:47:20 [train] batch 7000/7649 | loss 1.0554 | acc 0.3969
21:47:24 [train] batch 7200/7649 | loss 1.0553 | acc 0.3972
21:47:27 [train] batch 7400/7649 | loss 1.0553 | acc 0.3972
21:47:30 [train] batch 7600/7649 | loss 1.0553 | acc 0.3974
21:47:31 [train] batch 7649/7649 | loss 1.0553 | acc 0.3974
21:47:37 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_02.png
21:47:38 Epoch 02 | train 1.0553/0.3974 | val 1.0419/0.3670 | lr 1.00e-05
21:47:38 ✓ save best
21:47:41 [train] batch 200/7649 | loss 1.0531 | acc 0.4062
21:47:44 [train] batch 400/7649 | loss 1.0546 | acc 0.4036
21:47:48 [train] batch 600/7649 | loss 1.0548 | acc 0.4026
21:47:51 [train] batch 800/7649 | loss 1.0549 | acc 0.4035
21:47:54 [train] batch 1000/7649 | loss 1.0552 | acc 0.4036
21:47:57 [train] batch 1200/7649 | loss 1.0550 | acc 0.4033
21:48:01 [train] batch 1400/7649 | loss 1.0548 | acc 0.4018
21:48:04 [train] batch 1600/7649 | loss 1.0548 | acc 0.4021
21:48:07 [train] batch 1800/7649 | loss 1.0545 | acc 0.4025
21:48:10 [train] batch 2000/7649 | loss 1.0544 | acc 0.4015
21:48:14 [train] batch 2200/7649 | loss 1.0542 | acc 0.4017
21:48:17 [train] batch 2400/7649 | loss 1.0542 | acc 0.4010
21:48:21 [train] batch 2600/7649 | loss 1.0542 | acc 0.4003
21:48:24 [train] batch 2800/7649 | loss 1.0541 | acc 0.4002
21:48:27 [train] batch 3000/7649 | loss 1.0541 | acc 0.4001
21:48:30 [train] batch 3200/7649 | loss 1.0541 | acc 0.4000
21:48:34 [train] batch 3400/7649 | loss 1.0542 | acc 0.3997
21:48:37 [train] batch 3600/7649 | loss 1.0542 | acc 0.3996
21:48:40 [train] batch 3800/7649 | loss 1.0543 | acc 0.3994
21:48:43 [train] batch 4000/7649 | loss 1.0543 | acc 0.3998
21:48:47 [train] batch 4200/7649 | loss 1.0542 | acc 0.3996
21:48:50 [train] batch 4400/7649 | loss 1.0542 | acc 0.3996
21:48:53 [train] batch 4600/7649 | loss 1.0542 | acc 0.3998
21:48:56 [train] batch 4800/7649 | loss 1.0543 | acc 0.3997
21:49:00 [train] batch 5000/7649 | loss 1.0544 | acc 0.3997
21:49:03 [train] batch 5200/7649 | loss 1.0544 | acc 0.3999
21:49:06 [train] batch 5400/7649 | loss 1.0544 | acc 0.3998
21:49:10 [train] batch 5600/7649 | loss 1.0544 | acc 0.3998
21:49:13 [train] batch 5800/7649 | loss 1.0544 | acc 0.3996
21:49:16 [train] batch 6000/7649 | loss 1.0544 | acc 0.3995
21:49:19 [train] batch 6200/7649 | loss 1.0543 | acc 0.3994
21:49:23 [train] batch 6400/7649 | loss 1.0544 | acc 0.3993
21:49:26 [train] batch 6600/7649 | loss 1.0544 | acc 0.3994
21:49:29 [train] batch 6800/7649 | loss 1.0543 | acc 0.3995
21:49:33 [train] batch 7000/7649 | loss 1.0544 | acc 0.3996
21:49:36 [train] batch 7200/7649 | loss 1.0544 | acc 0.3996
21:49:39 [train] batch 7400/7649 | loss 1.0544 | acc 0.3996
21:49:42 [train] batch 7600/7649 | loss 1.0543 | acc 0.3997
21:49:43 [train] batch 7649/7649 | loss 1.0543 | acc 0.3997
21:49:50 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_03.png
21:49:50 Epoch 03 | train 1.0543/0.3997 | val 1.0433/0.3604 | lr 1.00e-05
21:49:53 [train] batch 200/7649 | loss 1.0540 | acc 0.4004
21:49:57 [train] batch 400/7649 | loss 1.0547 | acc 0.3968
21:50:00 [train] batch 600/7649 | loss 1.0543 | acc 0.3969
21:50:03 [train] batch 800/7649 | loss 1.0546 | acc 0.3965
21:50:06 [train] batch 1000/7649 | loss 1.0545 | acc 0.3974
21:50:10 [train] batch 1200/7649 | loss 1.0547 | acc 0.3982
21:50:13 [train] batch 1400/7649 | loss 1.0547 | acc 0.3979
21:50:16 [train] batch 1600/7649 | loss 1.0546 | acc 0.3976
21:50:19 [train] batch 1800/7649 | loss 1.0547 | acc 0.3976
21:50:23 [train] batch 2000/7649 | loss 1.0550 | acc 0.3972
21:50:26 [train] batch 2200/7649 | loss 1.0549 | acc 0.3969
21:50:29 [train] batch 2400/7649 | loss 1.0549 | acc 0.3972
21:50:33 [train] batch 2600/7649 | loss 1.0549 | acc 0.3975
21:50:36 [train] batch 2800/7649 | loss 1.0548 | acc 0.3980
21:50:39 [train] batch 3000/7649 | loss 1.0548 | acc 0.3984
21:50:43 [train] batch 3200/7649 | loss 1.0547 | acc 0.3984
21:50:46 [train] batch 3400/7649 | loss 1.0546 | acc 0.3988
21:50:49 [train] batch 3600/7649 | loss 1.0547 | acc 0.3986
21:50:52 [train] batch 3800/7649 | loss 1.0545 | acc 0.3987
21:50:56 [train] batch 4000/7649 | loss 1.0545 | acc 0.3986
21:50:59 [train] batch 4200/7649 | loss 1.0544 | acc 0.3986
21:51:02 [train] batch 4400/7649 | loss 1.0544 | acc 0.3990
21:51:05 [train] batch 4600/7649 | loss 1.0543 | acc 0.3996
21:51:09 [train] batch 4800/7649 | loss 1.0543 | acc 0.4000
21:51:12 [train] batch 5000/7649 | loss 1.0543 | acc 0.4000
21:51:15 [train] batch 5200/7649 | loss 1.0543 | acc 0.4002
21:51:18 [train] batch 5400/7649 | loss 1.0541 | acc 0.4003
21:51:22 [train] batch 5600/7649 | loss 1.0540 | acc 0.4004
21:51:25 [train] batch 5800/7649 | loss 1.0540 | acc 0.4003
21:51:28 [train] batch 6000/7649 | loss 1.0540 | acc 0.4005
21:51:31 [train] batch 6200/7649 | loss 1.0540 | acc 0.4006
21:51:35 [train] batch 6400/7649 | loss 1.0540 | acc 0.4004
21:51:38 [train] batch 6600/7649 | loss 1.0540 | acc 0.4005
21:51:41 [train] batch 6800/7649 | loss 1.0539 | acc 0.4007
21:51:45 [train] batch 7000/7649 | loss 1.0540 | acc 0.4006
21:51:48 [train] batch 7200/7649 | loss 1.0540 | acc 0.4008
21:51:51 [train] batch 7400/7649 | loss 1.0539 | acc 0.4010
21:51:54 [train] batch 7600/7649 | loss 1.0539 | acc 0.4011
21:51:55 [train] batch 7649/7649 | loss 1.0539 | acc 0.4011
21:52:02 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_04.png
21:52:02 Epoch 04 | train 1.0539/0.4011 | val 1.0440/0.3576 | lr 1.00e-05
21:52:05 [train] batch 200/7649 | loss 1.0550 | acc 0.3944
21:52:08 [train] batch 400/7649 | loss 1.0534 | acc 0.3981
21:52:12 [train] batch 600/7649 | loss 1.0538 | acc 0.3980
21:52:15 [train] batch 800/7649 | loss 1.0532 | acc 0.4005
21:52:18 [train] batch 1000/7649 | loss 1.0537 | acc 0.4008
21:52:21 [train] batch 1200/7649 | loss 1.0535 | acc 0.4018
21:52:25 [train] batch 1400/7649 | loss 1.0535 | acc 0.4016
21:52:28 [train] batch 1600/7649 | loss 1.0534 | acc 0.4009
21:52:31 [train] batch 1800/7649 | loss 1.0534 | acc 0.4003
21:52:35 [train] batch 2000/7649 | loss 1.0534 | acc 0.4000
21:52:38 [train] batch 2200/7649 | loss 1.0533 | acc 0.3999
21:52:41 [train] batch 2400/7649 | loss 1.0533 | acc 0.3998
21:52:45 [train] batch 2600/7649 | loss 1.0534 | acc 0.3997
21:52:48 [train] batch 2800/7649 | loss 1.0534 | acc 0.3996
21:52:51 [train] batch 3000/7649 | loss 1.0535 | acc 0.4001
21:52:54 [train] batch 3200/7649 | loss 1.0535 | acc 0.4000
21:52:58 [train] batch 3400/7649 | loss 1.0535 | acc 0.4001
21:53:01 [train] batch 3600/7649 | loss 1.0533 | acc 0.4004
21:53:04 [train] batch 3800/7649 | loss 1.0533 | acc 0.4007
21:53:07 [train] batch 4000/7649 | loss 1.0533 | acc 0.4011
21:53:11 [train] batch 4200/7649 | loss 1.0532 | acc 0.4009
21:53:14 [train] batch 4400/7649 | loss 1.0532 | acc 0.4013
21:53:17 [train] batch 4600/7649 | loss 1.0531 | acc 0.4015
21:53:21 [train] batch 4800/7649 | loss 1.0531 | acc 0.4014
21:53:24 [train] batch 5000/7649 | loss 1.0532 | acc 0.4011
21:53:27 [train] batch 5200/7649 | loss 1.0532 | acc 0.4009
21:53:30 [train] batch 5400/7649 | loss 1.0533 | acc 0.4010
21:53:34 [train] batch 5600/7649 | loss 1.0533 | acc 0.4010
21:53:37 [train] batch 5800/7649 | loss 1.0534 | acc 0.4009
21:53:40 [train] batch 6000/7649 | loss 1.0534 | acc 0.4010
21:53:44 [train] batch 6200/7649 | loss 1.0533 | acc 0.4011
21:53:47 [train] batch 6400/7649 | loss 1.0533 | acc 0.4010
21:53:50 [train] batch 6600/7649 | loss 1.0534 | acc 0.4010
21:53:53 [train] batch 6800/7649 | loss 1.0534 | acc 0.4012
21:53:57 [train] batch 7000/7649 | loss 1.0534 | acc 0.4014
21:54:00 [train] batch 7200/7649 | loss 1.0534 | acc 0.4013
21:54:03 [train] batch 7400/7649 | loss 1.0534 | acc 0.4014
21:54:07 [train] batch 7600/7649 | loss 1.0534 | acc 0.4015
21:54:07 [train] batch 7649/7649 | loss 1.0534 | acc 0.4015
21:54:14 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_05.png
21:54:14 Epoch 05 | train 1.0534/0.4015 | val 1.0443/0.3570 | lr 5.00e-06
21:54:17 [train] batch 200/7649 | loss 1.0541 | acc 0.4015
21:54:21 [train] batch 400/7649 | loss 1.0543 | acc 0.3948
21:54:24 [train] batch 600/7649 | loss 1.0532 | acc 0.3978
21:54:27 [train] batch 800/7649 | loss 1.0524 | acc 0.4003
21:54:30 [train] batch 1000/7649 | loss 1.0525 | acc 0.4001
21:54:34 [train] batch 1200/7649 | loss 1.0528 | acc 0.3997
21:54:37 [train] batch 1400/7649 | loss 1.0533 | acc 0.3993
21:54:40 [train] batch 1600/7649 | loss 1.0533 | acc 0.3994
21:54:44 [train] batch 1800/7649 | loss 1.0533 | acc 0.3999
21:54:47 [train] batch 2000/7649 | loss 1.0536 | acc 0.3996
21:54:50 [train] batch 2200/7649 | loss 1.0535 | acc 0.3998
21:54:54 [train] batch 2400/7649 | loss 1.0537 | acc 0.3994
21:54:57 [train] batch 2600/7649 | loss 1.0535 | acc 0.3997
21:55:00 [train] batch 2800/7649 | loss 1.0534 | acc 0.4010
21:55:03 [train] batch 3000/7649 | loss 1.0535 | acc 0.4013
21:55:07 [train] batch 3200/7649 | loss 1.0534 | acc 0.4010
21:55:10 [train] batch 3400/7649 | loss 1.0533 | acc 0.4015
21:55:13 [train] batch 3600/7649 | loss 1.0532 | acc 0.4017
21:55:16 [train] batch 3800/7649 | loss 1.0532 | acc 0.4014
21:55:20 [train] batch 4000/7649 | loss 1.0532 | acc 0.4015
21:55:23 [train] batch 4200/7649 | loss 1.0531 | acc 0.4014
21:55:26 [train] batch 4400/7649 | loss 1.0530 | acc 0.4015
21:55:30 [train] batch 4600/7649 | loss 1.0529 | acc 0.4018
21:55:33 [train] batch 4800/7649 | loss 1.0529 | acc 0.4019
21:55:36 [train] batch 5000/7649 | loss 1.0529 | acc 0.4020
21:55:39 [train] batch 5200/7649 | loss 1.0529 | acc 0.4020
21:55:43 [train] batch 5400/7649 | loss 1.0529 | acc 0.4019
21:55:46 [train] batch 5600/7649 | loss 1.0528 | acc 0.4021
21:55:49 [train] batch 5800/7649 | loss 1.0529 | acc 0.4021
21:55:52 [train] batch 6000/7649 | loss 1.0529 | acc 0.4020
21:55:56 [train] batch 6200/7649 | loss 1.0529 | acc 0.4018
21:55:59 [train] batch 6400/7649 | loss 1.0529 | acc 0.4015
21:56:02 [train] batch 6600/7649 | loss 1.0530 | acc 0.4014
21:56:05 [train] batch 6800/7649 | loss 1.0530 | acc 0.4016
21:56:09 [train] batch 7000/7649 | loss 1.0530 | acc 0.4015
21:56:12 [train] batch 7200/7649 | loss 1.0529 | acc 0.4017
21:56:15 [train] batch 7400/7649 | loss 1.0530 | acc 0.4015
21:56:18 [train] batch 7600/7649 | loss 1.0531 | acc 0.4014
21:56:19 [train] batch 7649/7649 | loss 1.0531 | acc 0.4015
21:56:26 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_06.png
21:56:26 Epoch 06 | train 1.0531/0.4015 | val 1.0429/0.3662 | lr 5.00e-06
21:56:29 [train] batch 200/7649 | loss 1.0506 | acc 0.4116
21:56:32 [train] batch 400/7649 | loss 1.0523 | acc 0.4096
21:56:36 [train] batch 600/7649 | loss 1.0526 | acc 0.4049
21:56:39 [train] batch 800/7649 | loss 1.0526 | acc 0.4032
21:56:42 [train] batch 1000/7649 | loss 1.0525 | acc 0.4043
21:56:46 [train] batch 1200/7649 | loss 1.0528 | acc 0.4047
21:56:49 [train] batch 1400/7649 | loss 1.0525 | acc 0.4050
21:56:52 [train] batch 1600/7649 | loss 1.0526 | acc 0.4040
21:56:56 [train] batch 1800/7649 | loss 1.0527 | acc 0.4033
21:56:59 [train] batch 2000/7649 | loss 1.0527 | acc 0.4025
21:57:02 [train] batch 2200/7649 | loss 1.0528 | acc 0.4024
21:57:05 [train] batch 2400/7649 | loss 1.0528 | acc 0.4024
21:57:09 [train] batch 2600/7649 | loss 1.0528 | acc 0.4022
21:57:12 [train] batch 2800/7649 | loss 1.0530 | acc 0.4025
21:57:15 [train] batch 3000/7649 | loss 1.0529 | acc 0.4021
21:57:18 [train] batch 3200/7649 | loss 1.0530 | acc 0.4015
21:57:22 [train] batch 3400/7649 | loss 1.0531 | acc 0.4015
21:57:25 [train] batch 3600/7649 | loss 1.0532 | acc 0.4017
21:57:28 [train] batch 3800/7649 | loss 1.0532 | acc 0.4014
21:57:31 [train] batch 4000/7649 | loss 1.0532 | acc 0.4011
21:57:35 [train] batch 4200/7649 | loss 1.0531 | acc 0.4013
21:57:38 [train] batch 4400/7649 | loss 1.0531 | acc 0.4013
21:57:41 [train] batch 4600/7649 | loss 1.0529 | acc 0.4016
21:57:44 [train] batch 4800/7649 | loss 1.0529 | acc 0.4019
21:57:48 [train] batch 5000/7649 | loss 1.0530 | acc 0.4019
21:57:51 [train] batch 5200/7649 | loss 1.0531 | acc 0.4019
21:57:54 [train] batch 5400/7649 | loss 1.0530 | acc 0.4022
21:57:58 [train] batch 5600/7649 | loss 1.0530 | acc 0.4023
21:58:01 [train] batch 5800/7649 | loss 1.0530 | acc 0.4021
21:58:04 [train] batch 6000/7649 | loss 1.0530 | acc 0.4024
21:58:08 [train] batch 6200/7649 | loss 1.0530 | acc 0.4026
21:58:11 [train] batch 6400/7649 | loss 1.0530 | acc 0.4027
21:58:14 [train] batch 6600/7649 | loss 1.0530 | acc 0.4025
21:58:17 [train] batch 6800/7649 | loss 1.0530 | acc 0.4024
21:58:21 [train] batch 7000/7649 | loss 1.0530 | acc 0.4025
21:58:24 [train] batch 7200/7649 | loss 1.0530 | acc 0.4024
21:58:27 [train] batch 7400/7649 | loss 1.0530 | acc 0.4025
21:58:30 [train] batch 7600/7649 | loss 1.0530 | acc 0.4024
21:58:31 [train] batch 7649/7649 | loss 1.0530 | acc 0.4025
21:58:38 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_07.png
21:58:38 Epoch 07 | train 1.0530/0.4025 | val 1.0437/0.3612 | lr 5.00e-06
21:58:42 [train] batch 200/7649 | loss 1.0527 | acc 0.4101
21:58:45 [train] batch 400/7649 | loss 1.0536 | acc 0.4092
21:58:48 [train] batch 600/7649 | loss 1.0533 | acc 0.4077
21:58:52 [train] batch 800/7649 | loss 1.0532 | acc 0.4084
21:58:55 [train] batch 1000/7649 | loss 1.0532 | acc 0.4075
21:58:58 [train] batch 1200/7649 | loss 1.0531 | acc 0.4068
21:59:01 [train] batch 1400/7649 | loss 1.0534 | acc 0.4060
21:59:05 [train] batch 1600/7649 | loss 1.0530 | acc 0.4067
21:59:08 [train] batch 1800/7649 | loss 1.0529 | acc 0.4064
21:59:11 [train] batch 2000/7649 | loss 1.0529 | acc 0.4058
21:59:14 [train] batch 2200/7649 | loss 1.0530 | acc 0.4053
21:59:18 [train] batch 2400/7649 | loss 1.0530 | acc 0.4050
21:59:21 [train] batch 2600/7649 | loss 1.0530 | acc 0.4050
21:59:24 [train] batch 2800/7649 | loss 1.0530 | acc 0.4048
21:59:28 [train] batch 3000/7649 | loss 1.0532 | acc 0.4044
21:59:31 [train] batch 3200/7649 | loss 1.0533 | acc 0.4039
21:59:34 [train] batch 3400/7649 | loss 1.0534 | acc 0.4037
21:59:37 [train] batch 3600/7649 | loss 1.0533 | acc 0.4034
21:59:41 [train] batch 3800/7649 | loss 1.0532 | acc 0.4033
21:59:44 [train] batch 4000/7649 | loss 1.0531 | acc 0.4032
21:59:47 [train] batch 4200/7649 | loss 1.0531 | acc 0.4030
21:59:50 [train] batch 4400/7649 | loss 1.0530 | acc 0.4030
21:59:54 [train] batch 4600/7649 | loss 1.0529 | acc 0.4030
21:59:57 [train] batch 4800/7649 | loss 1.0529 | acc 0.4030
22:00:00 [train] batch 5000/7649 | loss 1.0529 | acc 0.4029
22:00:04 [train] batch 5200/7649 | loss 1.0529 | acc 0.4027
22:00:07 [train] batch 5400/7649 | loss 1.0529 | acc 0.4026
22:00:10 [train] batch 5600/7649 | loss 1.0528 | acc 0.4027
22:00:14 [train] batch 5800/7649 | loss 1.0528 | acc 0.4028
22:00:17 [train] batch 6000/7649 | loss 1.0528 | acc 0.4028
22:00:20 [train] batch 6200/7649 | loss 1.0528 | acc 0.4029
22:00:23 [train] batch 6400/7649 | loss 1.0528 | acc 0.4029
22:00:27 [train] batch 6600/7649 | loss 1.0528 | acc 0.4028
22:00:30 [train] batch 6800/7649 | loss 1.0528 | acc 0.4026
22:00:33 [train] batch 7000/7649 | loss 1.0528 | acc 0.4029
22:00:36 [train] batch 7200/7649 | loss 1.0527 | acc 0.4029
22:00:40 [train] batch 7400/7649 | loss 1.0528 | acc 0.4029
22:00:43 [train] batch 7600/7649 | loss 1.0528 | acc 0.4029
22:00:44 [train] batch 7649/7649 | loss 1.0528 | acc 0.4029
22:00:51 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_08.png
22:00:51 Epoch 08 | train 1.0528/0.4029 | val 1.0468/0.3473 | lr 5.00e-06
22:00:54 [train] batch 200/7649 | loss 1.0531 | acc 0.4012
22:00:58 [train] batch 400/7649 | loss 1.0537 | acc 0.4032
22:01:01 [train] batch 600/7649 | loss 1.0548 | acc 0.4013
22:01:04 [train] batch 800/7649 | loss 1.0539 | acc 0.4032
22:01:08 [train] batch 1000/7649 | loss 1.0539 | acc 0.4038
22:01:11 [train] batch 1200/7649 | loss 1.0539 | acc 0.4039
22:01:14 [train] batch 1400/7649 | loss 1.0537 | acc 0.4037
22:01:17 [train] batch 1600/7649 | loss 1.0537 | acc 0.4042
22:01:21 [train] batch 1800/7649 | loss 1.0535 | acc 0.4041
22:01:24 [train] batch 2000/7649 | loss 1.0533 | acc 0.4041
22:01:27 [train] batch 2200/7649 | loss 1.0534 | acc 0.4034
22:01:30 [train] batch 2400/7649 | loss 1.0534 | acc 0.4031
22:01:34 [train] batch 2600/7649 | loss 1.0534 | acc 0.4028
22:01:37 [train] batch 2800/7649 | loss 1.0534 | acc 0.4023
22:01:40 [train] batch 3000/7649 | loss 1.0531 | acc 0.4027
22:01:43 [train] batch 3200/7649 | loss 1.0532 | acc 0.4021
22:01:47 [train] batch 3400/7649 | loss 1.0532 | acc 0.4017
22:01:50 [train] batch 3600/7649 | loss 1.0530 | acc 0.4016
22:01:53 [train] batch 3800/7649 | loss 1.0531 | acc 0.4014
22:01:56 [train] batch 4000/7649 | loss 1.0531 | acc 0.4016
22:02:00 [train] batch 4200/7649 | loss 1.0531 | acc 0.4017
22:02:03 [train] batch 4400/7649 | loss 1.0530 | acc 0.4019
22:02:06 [train] batch 4600/7649 | loss 1.0530 | acc 0.4020
22:02:10 [train] batch 4800/7649 | loss 1.0530 | acc 0.4020
22:02:13 [train] batch 5000/7649 | loss 1.0531 | acc 0.4021
22:02:16 [train] batch 5200/7649 | loss 1.0530 | acc 0.4021
22:02:20 [train] batch 5400/7649 | loss 1.0530 | acc 0.4021
22:02:23 [train] batch 5600/7649 | loss 1.0530 | acc 0.4022
22:02:26 [train] batch 5800/7649 | loss 1.0530 | acc 0.4023
22:02:29 [train] batch 6000/7649 | loss 1.0530 | acc 0.4025
22:02:33 [train] batch 6200/7649 | loss 1.0531 | acc 0.4025
22:02:36 [train] batch 6400/7649 | loss 1.0530 | acc 0.4025
22:02:39 [train] batch 6600/7649 | loss 1.0530 | acc 0.4025
22:02:42 [train] batch 6800/7649 | loss 1.0529 | acc 0.4026
22:02:46 [train] batch 7000/7649 | loss 1.0529 | acc 0.4026
22:02:49 [train] batch 7200/7649 | loss 1.0529 | acc 0.4028
22:02:52 [train] batch 7400/7649 | loss 1.0529 | acc 0.4029
22:02:55 [train] batch 7600/7649 | loss 1.0528 | acc 0.4030
22:02:56 [train] batch 7649/7649 | loss 1.0528 | acc 0.4031
22:03:03 ✔ saved validation confusion matrix → confusion_val/run_20250524_214315/epoch_09.png
22:03:03 Epoch 09 | train 1.0528/0.4031 | val 1.0429/0.3584 | lr 2.50e-06
22:03:03 Early-stop
22:03:05 [eval ] batch 200/2185 | loss 1.0856 | acc 0.2129
22:03:06 [eval ] batch 400/2185 | loss 1.0536 | acc 0.3539
22:03:07 [eval ] batch 600/2185 | loss 1.0494 | acc 0.3716
22:03:08 [eval ] batch 800/2185 | loss 1.0548 | acc 0.3518
22:03:09 [eval ] batch 1000/2185 | loss 1.0563 | acc 0.3524
22:03:10 [eval ] batch 1200/2185 | loss 1.0528 | acc 0.3774
22:03:11 [eval ] batch 1400/2185 | loss 1.0550 | acc 0.3662
22:03:12 [eval ] batch 1600/2185 | loss 1.0560 | acc 0.3648
22:03:13 [eval ] batch 1800/2185 | loss 1.0564 | acc 0.3639
22:03:14 [eval ] batch 2000/2185 | loss 1.0541 | acc 0.3661
22:03:15 [eval ] batch 2185/2185 | loss 1.0542 | acc 0.3668
22:03:15 TEST loss/acc 1.0542/0.3668
22:03:28 Confusion matrix saved ➜ confusion_matrix.png

改完标签后1.2:1
/data4/private/rmy/hw/confusion_val/run_20250524_214315