23:37:47 Log file: logs/train_20250523_233747.log
23:38:19 ✔ Data split: 1958081/279725/559453 rows ➜ splits
23:38:22 train.csv: samples=1957961  class_dist=[609313 731512 617256]
23:38:22 val.csv: samples=279605  class_dist=[90467 94550 94708]
23:38:23 test.csv: samples=559333  class_dist=[183495 190446 185512]
23:38:28 [train] batch 200/7649 | loss 1.1037 | acc 0.3543
23:38:31 [train] batch 400/7649 | loss 1.1028 | acc 0.3547
23:38:35 [train] batch 600/7649 | loss 1.1023 | acc 0.3556
23:38:38 [train] batch 800/7649 | loss 1.1016 | acc 0.3565
23:38:41 [train] batch 1000/7649 | loss 1.1011 | acc 0.3569
23:38:44 [train] batch 1200/7649 | loss 1.1006 | acc 0.3582
23:38:48 [train] batch 1400/7649 | loss 1.1002 | acc 0.3586
23:38:51 [train] batch 1600/7649 | loss 1.0999 | acc 0.3586
23:38:54 [train] batch 1800/7649 | loss 1.0996 | acc 0.3588
23:38:58 [train] batch 2000/7649 | loss 1.0993 | acc 0.3591
23:39:01 [train] batch 2200/7649 | loss 1.0991 | acc 0.3594
23:39:04 [train] batch 2400/7649 | loss 1.0989 | acc 0.3597
23:39:07 [train] batch 2600/7649 | loss 1.0987 | acc 0.3601
23:39:11 [train] batch 2800/7649 | loss 1.0985 | acc 0.3604
23:39:14 [train] batch 3000/7649 | loss 1.0984 | acc 0.3604
23:39:17 [train] batch 3200/7649 | loss 1.0982 | acc 0.3606
23:39:21 [train] batch 3400/7649 | loss 1.0980 | acc 0.3607
23:39:24 [train] batch 3600/7649 | loss 1.0978 | acc 0.3610
23:39:27 [train] batch 3800/7649 | loss 1.0977 | acc 0.3613
23:39:30 [train] batch 4000/7649 | loss 1.0975 | acc 0.3619
23:39:34 [train] batch 4200/7649 | loss 1.0973 | acc 0.3621
23:39:37 [train] batch 4400/7649 | loss 1.0972 | acc 0.3624
23:39:40 [train] batch 4600/7649 | loss 1.0971 | acc 0.3624
23:39:43 [train] batch 4800/7649 | loss 1.0970 | acc 0.3626
23:39:46 [train] batch 5000/7649 | loss 1.0969 | acc 0.3627
23:39:50 [train] batch 5200/7649 | loss 1.0968 | acc 0.3626
23:39:53 [train] batch 5400/7649 | loss 1.0967 | acc 0.3629
23:39:56 [train] batch 5600/7649 | loss 1.0966 | acc 0.3632
23:40:00 [train] batch 5800/7649 | loss 1.0965 | acc 0.3634
23:40:03 [train] batch 6000/7649 | loss 1.0965 | acc 0.3635
23:40:06 [train] batch 6200/7649 | loss 1.0964 | acc 0.3637
23:40:09 [train] batch 6400/7649 | loss 1.0963 | acc 0.3638
23:40:13 [train] batch 6600/7649 | loss 1.0962 | acc 0.3639
23:40:16 [train] batch 6800/7649 | loss 1.0961 | acc 0.3641
23:40:19 [train] batch 7000/7649 | loss 1.0960 | acc 0.3644
23:40:22 [train] batch 7200/7649 | loss 1.0960 | acc 0.3646
23:40:26 [train] batch 7400/7649 | loss 1.0959 | acc 0.3648
23:40:29 [train] batch 7600/7649 | loss 1.0958 | acc 0.3650
23:40:30 [train] batch 7649/7649 | loss 1.0958 | acc 0.3651
23:40:36 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_01.png
23:40:36 Epoch 01 | train 1.0958/0.3651 | val 1.0947/0.3644 | lr 1.00e-05
23:40:36 ✓ save best
23:40:40 [train] batch 200/7649 | loss 1.0935 | acc 0.3702
23:40:43 [train] batch 400/7649 | loss 1.0935 | acc 0.3693
23:40:46 [train] batch 600/7649 | loss 1.0934 | acc 0.3683
23:40:50 [train] batch 800/7649 | loss 1.0935 | acc 0.3681
23:40:53 [train] batch 1000/7649 | loss 1.0933 | acc 0.3683
23:40:56 [train] batch 1200/7649 | loss 1.0932 | acc 0.3690
23:41:00 [train] batch 1400/7649 | loss 1.0933 | acc 0.3695
23:41:03 [train] batch 1600/7649 | loss 1.0932 | acc 0.3700
23:41:06 [train] batch 1800/7649 | loss 1.0932 | acc 0.3704
23:41:10 [train] batch 2000/7649 | loss 1.0932 | acc 0.3705
23:41:13 [train] batch 2200/7649 | loss 1.0933 | acc 0.3704
23:41:16 [train] batch 2400/7649 | loss 1.0932 | acc 0.3709
23:41:20 [train] batch 2600/7649 | loss 1.0931 | acc 0.3710
23:41:23 [train] batch 2800/7649 | loss 1.0931 | acc 0.3710
23:41:27 [train] batch 3000/7649 | loss 1.0931 | acc 0.3708
23:41:30 [train] batch 3200/7649 | loss 1.0931 | acc 0.3709
23:41:33 [train] batch 3400/7649 | loss 1.0931 | acc 0.3708
23:41:37 [train] batch 3600/7649 | loss 1.0931 | acc 0.3709
23:41:40 [train] batch 3800/7649 | loss 1.0931 | acc 0.3710
23:41:43 [train] batch 4000/7649 | loss 1.0930 | acc 0.3710
23:41:47 [train] batch 4200/7649 | loss 1.0930 | acc 0.3710
23:41:50 [train] batch 4400/7649 | loss 1.0930 | acc 0.3710
23:41:53 [train] batch 4600/7649 | loss 1.0930 | acc 0.3710
23:41:57 [train] batch 4800/7649 | loss 1.0930 | acc 0.3712
23:42:00 [train] batch 5000/7649 | loss 1.0929 | acc 0.3714
23:42:03 [train] batch 5200/7649 | loss 1.0929 | acc 0.3715
23:42:07 [train] batch 5400/7649 | loss 1.0929 | acc 0.3715
23:42:10 [train] batch 5600/7649 | loss 1.0929 | acc 0.3716
23:42:13 [train] batch 5800/7649 | loss 1.0928 | acc 0.3717
23:42:17 [train] batch 6000/7649 | loss 1.0928 | acc 0.3717
23:42:20 [train] batch 6200/7649 | loss 1.0928 | acc 0.3718
23:42:24 [train] batch 6400/7649 | loss 1.0927 | acc 0.3720
23:42:27 [train] batch 6600/7649 | loss 1.0927 | acc 0.3720
23:42:30 [train] batch 6800/7649 | loss 1.0927 | acc 0.3721
23:42:34 [train] batch 7000/7649 | loss 1.0926 | acc 0.3722
23:42:37 [train] batch 7200/7649 | loss 1.0926 | acc 0.3723
23:42:41 [train] batch 7400/7649 | loss 1.0926 | acc 0.3723
23:42:44 [train] batch 7600/7649 | loss 1.0926 | acc 0.3723
23:42:45 [train] batch 7649/7649 | loss 1.0926 | acc 0.3723
23:42:51 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_02.png
23:42:51 Epoch 02 | train 1.0926/0.3723 | val 1.0945/0.3650 | lr 1.00e-05
23:42:51 ✓ save best
23:42:55 [train] batch 200/7649 | loss 1.0928 | acc 0.3718
23:42:58 [train] batch 400/7649 | loss 1.0923 | acc 0.3760
23:43:02 [train] batch 600/7649 | loss 1.0923 | acc 0.3758
23:43:05 [train] batch 800/7649 | loss 1.0922 | acc 0.3759
23:43:08 [train] batch 1000/7649 | loss 1.0922 | acc 0.3759
23:43:12 [train] batch 1200/7649 | loss 1.0922 | acc 0.3760
23:43:15 [train] batch 1400/7649 | loss 1.0922 | acc 0.3757
23:43:18 [train] batch 1600/7649 | loss 1.0921 | acc 0.3756
23:43:21 [train] batch 1800/7649 | loss 1.0921 | acc 0.3758
23:43:25 [train] batch 2000/7649 | loss 1.0921 | acc 0.3755
23:43:28 [train] batch 2200/7649 | loss 1.0921 | acc 0.3757
23:43:32 [train] batch 2400/7649 | loss 1.0921 | acc 0.3755
23:43:35 [train] batch 2600/7649 | loss 1.0921 | acc 0.3755
23:43:38 [train] batch 2800/7649 | loss 1.0921 | acc 0.3751
23:43:41 [train] batch 3000/7649 | loss 1.0921 | acc 0.3751
23:43:45 [train] batch 3200/7649 | loss 1.0921 | acc 0.3752
23:43:48 [train] batch 3400/7649 | loss 1.0920 | acc 0.3754
23:43:51 [train] batch 3600/7649 | loss 1.0920 | acc 0.3754
23:43:54 [train] batch 3800/7649 | loss 1.0920 | acc 0.3753
23:43:58 [train] batch 4000/7649 | loss 1.0920 | acc 0.3756
23:44:01 [train] batch 4200/7649 | loss 1.0919 | acc 0.3755
23:44:04 [train] batch 4400/7649 | loss 1.0919 | acc 0.3756
23:44:07 [train] batch 4600/7649 | loss 1.0919 | acc 0.3754
23:44:11 [train] batch 4800/7649 | loss 1.0919 | acc 0.3752
23:44:14 [train] batch 5000/7649 | loss 1.0919 | acc 0.3753
23:44:17 [train] batch 5200/7649 | loss 1.0919 | acc 0.3754
23:44:20 [train] batch 5400/7649 | loss 1.0919 | acc 0.3754
23:44:24 [train] batch 5600/7649 | loss 1.0919 | acc 0.3753
23:44:27 [train] batch 5800/7649 | loss 1.0919 | acc 0.3750
23:44:30 [train] batch 6000/7649 | loss 1.0919 | acc 0.3749
23:44:34 [train] batch 6200/7649 | loss 1.0919 | acc 0.3749
23:44:37 [train] batch 6400/7649 | loss 1.0919 | acc 0.3750
23:44:40 [train] batch 6600/7649 | loss 1.0919 | acc 0.3751
23:44:44 [train] batch 6800/7649 | loss 1.0919 | acc 0.3750
23:44:47 [train] batch 7000/7649 | loss 1.0918 | acc 0.3750
23:44:50 [train] batch 7200/7649 | loss 1.0918 | acc 0.3749
23:44:54 [train] batch 7400/7649 | loss 1.0918 | acc 0.3749
23:44:57 [train] batch 7600/7649 | loss 1.0918 | acc 0.3750
23:44:58 [train] batch 7649/7649 | loss 1.0918 | acc 0.3750
23:45:04 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_03.png
23:45:04 Epoch 03 | train 1.0918/0.3750 | val 1.0937/0.3662 | lr 1.00e-05
23:45:04 ✓ save best
23:45:08 [train] batch 200/7649 | loss 1.0919 | acc 0.3770
23:45:11 [train] batch 400/7649 | loss 1.0921 | acc 0.3761
23:45:14 [train] batch 600/7649 | loss 1.0919 | acc 0.3749
23:45:18 [train] batch 800/7649 | loss 1.0917 | acc 0.3755
23:45:21 [train] batch 1000/7649 | loss 1.0916 | acc 0.3759
23:45:24 [train] batch 1200/7649 | loss 1.0915 | acc 0.3760
23:45:28 [train] batch 1400/7649 | loss 1.0916 | acc 0.3753
23:45:31 [train] batch 1600/7649 | loss 1.0915 | acc 0.3762
23:45:34 [train] batch 1800/7649 | loss 1.0914 | acc 0.3765
23:45:38 [train] batch 2000/7649 | loss 1.0914 | acc 0.3769
23:45:41 [train] batch 2200/7649 | loss 1.0914 | acc 0.3767
23:45:45 [train] batch 2400/7649 | loss 1.0914 | acc 0.3765
23:45:48 [train] batch 2600/7649 | loss 1.0915 | acc 0.3762
23:45:51 [train] batch 2800/7649 | loss 1.0915 | acc 0.3762
23:45:55 [train] batch 3000/7649 | loss 1.0915 | acc 0.3757
23:45:58 [train] batch 3200/7649 | loss 1.0915 | acc 0.3754
23:46:01 [train] batch 3400/7649 | loss 1.0916 | acc 0.3751
23:46:05 [train] batch 3600/7649 | loss 1.0916 | acc 0.3751
23:46:08 [train] batch 3800/7649 | loss 1.0916 | acc 0.3751
23:46:11 [train] batch 4000/7649 | loss 1.0915 | acc 0.3750
23:46:15 [train] batch 4200/7649 | loss 1.0915 | acc 0.3751
23:46:18 [train] batch 4400/7649 | loss 1.0915 | acc 0.3752
23:46:21 [train] batch 4600/7649 | loss 1.0915 | acc 0.3753
23:46:25 [train] batch 4800/7649 | loss 1.0915 | acc 0.3753
23:46:28 [train] batch 5000/7649 | loss 1.0915 | acc 0.3751
23:46:31 [train] batch 5200/7649 | loss 1.0915 | acc 0.3751
23:46:35 [train] batch 5400/7649 | loss 1.0915 | acc 0.3750
23:46:38 [train] batch 5600/7649 | loss 1.0915 | acc 0.3750
23:46:41 [train] batch 5800/7649 | loss 1.0915 | acc 0.3752
23:46:45 [train] batch 6000/7649 | loss 1.0915 | acc 0.3752
23:46:48 [train] batch 6200/7649 | loss 1.0915 | acc 0.3754
23:46:52 [train] batch 6400/7649 | loss 1.0914 | acc 0.3755
23:46:55 [train] batch 6600/7649 | loss 1.0914 | acc 0.3756
23:46:58 [train] batch 6800/7649 | loss 1.0914 | acc 0.3756
23:47:02 [train] batch 7000/7649 | loss 1.0914 | acc 0.3756
23:47:05 [train] batch 7200/7649 | loss 1.0914 | acc 0.3755
23:47:09 [train] batch 7400/7649 | loss 1.0914 | acc 0.3756
23:47:12 [train] batch 7600/7649 | loss 1.0914 | acc 0.3756
23:47:13 [train] batch 7649/7649 | loss 1.0914 | acc 0.3756
23:47:19 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_04.png
23:47:19 Epoch 04 | train 1.0914/0.3756 | val 1.0939/0.3667 | lr 1.00e-05
23:47:19 ✓ save best
23:47:23 [train] batch 200/7649 | loss 1.0904 | acc 0.3783
23:47:26 [train] batch 400/7649 | loss 1.0909 | acc 0.3774
23:47:29 [train] batch 600/7649 | loss 1.0909 | acc 0.3778
23:47:33 [train] batch 800/7649 | loss 1.0908 | acc 0.3789
23:47:36 [train] batch 1000/7649 | loss 1.0909 | acc 0.3784
23:47:39 [train] batch 1200/7649 | loss 1.0909 | acc 0.3781
23:47:43 [train] batch 1400/7649 | loss 1.0910 | acc 0.3784
23:47:46 [train] batch 1600/7649 | loss 1.0910 | acc 0.3782
23:47:50 [train] batch 1800/7649 | loss 1.0910 | acc 0.3777
23:47:53 [train] batch 2000/7649 | loss 1.0911 | acc 0.3773
23:47:56 [train] batch 2200/7649 | loss 1.0911 | acc 0.3771
23:47:59 [train] batch 2400/7649 | loss 1.0911 | acc 0.3768
23:48:03 [train] batch 2600/7649 | loss 1.0911 | acc 0.3771
23:48:06 [train] batch 2800/7649 | loss 1.0911 | acc 0.3768
23:48:09 [train] batch 3000/7649 | loss 1.0911 | acc 0.3768
23:48:12 [train] batch 3200/7649 | loss 1.0911 | acc 0.3767
23:48:16 [train] batch 3400/7649 | loss 1.0911 | acc 0.3767
23:48:19 [train] batch 3600/7649 | loss 1.0911 | acc 0.3767
23:48:22 [train] batch 3800/7649 | loss 1.0911 | acc 0.3769
23:48:25 [train] batch 4000/7649 | loss 1.0911 | acc 0.3769
23:48:29 [train] batch 4200/7649 | loss 1.0911 | acc 0.3769
23:48:32 [train] batch 4400/7649 | loss 1.0910 | acc 0.3770
23:48:35 [train] batch 4600/7649 | loss 1.0910 | acc 0.3770
23:48:39 [train] batch 4800/7649 | loss 1.0910 | acc 0.3771
23:48:42 [train] batch 5000/7649 | loss 1.0910 | acc 0.3769
23:48:45 [train] batch 5200/7649 | loss 1.0910 | acc 0.3768
23:48:48 [train] batch 5400/7649 | loss 1.0910 | acc 0.3767
23:48:52 [train] batch 5600/7649 | loss 1.0910 | acc 0.3769
23:48:55 [train] batch 5800/7649 | loss 1.0910 | acc 0.3769
23:48:58 [train] batch 6000/7649 | loss 1.0910 | acc 0.3768
23:49:02 [train] batch 6200/7649 | loss 1.0910 | acc 0.3768
23:49:05 [train] batch 6400/7649 | loss 1.0910 | acc 0.3767
23:49:08 [train] batch 6600/7649 | loss 1.0910 | acc 0.3767
23:49:12 [train] batch 6800/7649 | loss 1.0910 | acc 0.3765
23:49:15 [train] batch 7000/7649 | loss 1.0910 | acc 0.3765
23:49:18 [train] batch 7200/7649 | loss 1.0910 | acc 0.3765
23:49:21 [train] batch 7400/7649 | loss 1.0910 | acc 0.3765
23:49:25 [train] batch 7600/7649 | loss 1.0910 | acc 0.3766
23:49:26 [train] batch 7649/7649 | loss 1.0910 | acc 0.3766
23:49:32 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_05.png
23:49:32 Epoch 05 | train 1.0910/0.3766 | val 1.0944/0.3667 | lr 1.00e-05
23:49:35 [train] batch 200/7649 | loss 1.0911 | acc 0.3784
23:49:39 [train] batch 400/7649 | loss 1.0909 | acc 0.3768
23:49:42 [train] batch 600/7649 | loss 1.0908 | acc 0.3769
23:49:45 [train] batch 800/7649 | loss 1.0911 | acc 0.3760
23:49:49 [train] batch 1000/7649 | loss 1.0910 | acc 0.3765
23:49:52 [train] batch 1200/7649 | loss 1.0910 | acc 0.3770
23:49:55 [train] batch 1400/7649 | loss 1.0911 | acc 0.3769
23:49:59 [train] batch 1600/7649 | loss 1.0909 | acc 0.3770
23:50:02 [train] batch 1800/7649 | loss 1.0909 | acc 0.3772
23:50:06 [train] batch 2000/7649 | loss 1.0910 | acc 0.3775
23:50:09 [train] batch 2200/7649 | loss 1.0909 | acc 0.3778
23:50:12 [train] batch 2400/7649 | loss 1.0910 | acc 0.3771
23:50:16 [train] batch 2600/7649 | loss 1.0910 | acc 0.3772
23:50:19 [train] batch 2800/7649 | loss 1.0909 | acc 0.3775
23:50:22 [train] batch 3000/7649 | loss 1.0909 | acc 0.3776
23:50:26 [train] batch 3200/7649 | loss 1.0908 | acc 0.3777
23:50:29 [train] batch 3400/7649 | loss 1.0908 | acc 0.3778
23:50:32 [train] batch 3600/7649 | loss 1.0908 | acc 0.3775
23:50:36 [train] batch 3800/7649 | loss 1.0908 | acc 0.3777
23:50:39 [train] batch 4000/7649 | loss 1.0908 | acc 0.3778
23:50:42 [train] batch 4200/7649 | loss 1.0908 | acc 0.3776
23:50:46 [train] batch 4400/7649 | loss 1.0908 | acc 0.3775
23:50:49 [train] batch 4600/7649 | loss 1.0908 | acc 0.3774
23:50:52 [train] batch 4800/7649 | loss 1.0908 | acc 0.3775
23:50:56 [train] batch 5000/7649 | loss 1.0908 | acc 0.3776
23:50:59 [train] batch 5200/7649 | loss 1.0908 | acc 0.3776
23:51:02 [train] batch 5400/7649 | loss 1.0907 | acc 0.3776
23:51:06 [train] batch 5600/7649 | loss 1.0907 | acc 0.3775
23:51:09 [train] batch 5800/7649 | loss 1.0907 | acc 0.3775
23:51:13 [train] batch 6000/7649 | loss 1.0907 | acc 0.3774
23:51:16 [train] batch 6200/7649 | loss 1.0907 | acc 0.3775
23:51:19 [train] batch 6400/7649 | loss 1.0908 | acc 0.3773
23:51:23 [train] batch 6600/7649 | loss 1.0908 | acc 0.3774
23:51:26 [train] batch 6800/7649 | loss 1.0908 | acc 0.3774
23:51:30 [train] batch 7000/7649 | loss 1.0908 | acc 0.3774
23:51:33 [train] batch 7200/7649 | loss 1.0908 | acc 0.3774
23:51:36 [train] batch 7400/7649 | loss 1.0908 | acc 0.3774
23:51:40 [train] batch 7600/7649 | loss 1.0908 | acc 0.3775
23:51:40 [train] batch 7649/7649 | loss 1.0908 | acc 0.3775
23:51:47 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_06.png
23:51:47 Epoch 06 | train 1.0908/0.3775 | val 1.0945/0.3660 | lr 1.00e-05
23:51:50 [train] batch 200/7649 | loss 1.0910 | acc 0.3753
23:51:54 [train] batch 400/7649 | loss 1.0901 | acc 0.3771
23:51:57 [train] batch 600/7649 | loss 1.0902 | acc 0.3768
23:52:00 [train] batch 800/7649 | loss 1.0904 | acc 0.3766
23:52:04 [train] batch 1000/7649 | loss 1.0906 | acc 0.3773
23:52:07 [train] batch 1200/7649 | loss 1.0905 | acc 0.3784
23:52:10 [train] batch 1400/7649 | loss 1.0907 | acc 0.3782
23:52:14 [train] batch 1600/7649 | loss 1.0907 | acc 0.3781
23:52:17 [train] batch 1800/7649 | loss 1.0906 | acc 0.3782
23:52:20 [train] batch 2000/7649 | loss 1.0906 | acc 0.3780
23:52:24 [train] batch 2200/7649 | loss 1.0906 | acc 0.3778
23:52:27 [train] batch 2400/7649 | loss 1.0906 | acc 0.3779
23:52:30 [train] batch 2600/7649 | loss 1.0906 | acc 0.3778
23:52:33 [train] batch 2800/7649 | loss 1.0906 | acc 0.3781
23:52:37 [train] batch 3000/7649 | loss 1.0906 | acc 0.3780
23:52:40 [train] batch 3200/7649 | loss 1.0906 | acc 0.3780
23:52:43 [train] batch 3400/7649 | loss 1.0906 | acc 0.3781
23:52:46 [train] batch 3600/7649 | loss 1.0906 | acc 0.3781
23:52:50 [train] batch 3800/7649 | loss 1.0905 | acc 0.3781
23:52:53 [train] batch 4000/7649 | loss 1.0906 | acc 0.3782
23:52:56 [train] batch 4200/7649 | loss 1.0906 | acc 0.3781
23:53:00 [train] batch 4400/7649 | loss 1.0906 | acc 0.3781
23:53:03 [train] batch 4600/7649 | loss 1.0906 | acc 0.3783
23:53:06 [train] batch 4800/7649 | loss 1.0906 | acc 0.3783
23:53:10 [train] batch 5000/7649 | loss 1.0906 | acc 0.3783
23:53:13 [train] batch 5200/7649 | loss 1.0906 | acc 0.3784
23:53:16 [train] batch 5400/7649 | loss 1.0906 | acc 0.3784
23:53:20 [train] batch 5600/7649 | loss 1.0905 | acc 0.3784
23:53:23 [train] batch 5800/7649 | loss 1.0905 | acc 0.3784
23:53:26 [train] batch 6000/7649 | loss 1.0905 | acc 0.3785
23:53:30 [train] batch 6200/7649 | loss 1.0905 | acc 0.3785
23:53:33 [train] batch 6400/7649 | loss 1.0905 | acc 0.3785
23:53:36 [train] batch 6600/7649 | loss 1.0905 | acc 0.3784
23:53:40 [train] batch 6800/7649 | loss 1.0905 | acc 0.3783
23:53:43 [train] batch 7000/7649 | loss 1.0905 | acc 0.3783
23:53:46 [train] batch 7200/7649 | loss 1.0905 | acc 0.3782
23:53:50 [train] batch 7400/7649 | loss 1.0905 | acc 0.3781
23:53:53 [train] batch 7600/7649 | loss 1.0905 | acc 0.3782
23:53:54 [train] batch 7649/7649 | loss 1.0905 | acc 0.3782
23:54:01 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_07.png
23:54:01 Epoch 07 | train 1.0905/0.3782 | val 1.0943/0.3666 | lr 5.00e-06
23:54:04 [train] batch 200/7649 | loss 1.0899 | acc 0.3834
23:54:08 [train] batch 400/7649 | loss 1.0900 | acc 0.3821
23:54:11 [train] batch 600/7649 | loss 1.0901 | acc 0.3821
23:54:15 [train] batch 800/7649 | loss 1.0903 | acc 0.3813
23:54:18 [train] batch 1000/7649 | loss 1.0903 | acc 0.3815
23:54:21 [train] batch 1200/7649 | loss 1.0903 | acc 0.3816
23:54:25 [train] batch 1400/7649 | loss 1.0904 | acc 0.3811
23:54:28 [train] batch 1600/7649 | loss 1.0904 | acc 0.3807
23:54:31 [train] batch 1800/7649 | loss 1.0904 | acc 0.3805
23:54:35 [train] batch 2000/7649 | loss 1.0904 | acc 0.3802
23:54:38 [train] batch 2200/7649 | loss 1.0904 | acc 0.3804
23:54:41 [train] batch 2400/7649 | loss 1.0904 | acc 0.3803
23:54:45 [train] batch 2600/7649 | loss 1.0905 | acc 0.3802
23:54:48 [train] batch 2800/7649 | loss 1.0904 | acc 0.3804
23:54:51 [train] batch 3000/7649 | loss 1.0903 | acc 0.3805
23:54:55 [train] batch 3200/7649 | loss 1.0903 | acc 0.3806
23:54:58 [train] batch 3400/7649 | loss 1.0902 | acc 0.3805
23:55:02 [train] batch 3600/7649 | loss 1.0902 | acc 0.3802
23:55:05 [train] batch 3800/7649 | loss 1.0903 | acc 0.3800
23:55:08 [train] batch 4000/7649 | loss 1.0903 | acc 0.3797
23:55:12 [train] batch 4200/7649 | loss 1.0904 | acc 0.3796
23:55:15 [train] batch 4400/7649 | loss 1.0903 | acc 0.3796
23:55:18 [train] batch 4600/7649 | loss 1.0903 | acc 0.3795
23:55:22 [train] batch 4800/7649 | loss 1.0903 | acc 0.3793
23:55:25 [train] batch 5000/7649 | loss 1.0903 | acc 0.3792
23:55:28 [train] batch 5200/7649 | loss 1.0904 | acc 0.3791
23:55:32 [train] batch 5400/7649 | loss 1.0904 | acc 0.3791
23:55:35 [train] batch 5600/7649 | loss 1.0903 | acc 0.3791
23:55:38 [train] batch 5800/7649 | loss 1.0904 | acc 0.3790
23:55:42 [train] batch 6000/7649 | loss 1.0904 | acc 0.3791
23:55:45 [train] batch 6200/7649 | loss 1.0903 | acc 0.3791
23:55:48 [train] batch 6400/7649 | loss 1.0903 | acc 0.3792
23:55:52 [train] batch 6600/7649 | loss 1.0903 | acc 0.3792
23:55:55 [train] batch 6800/7649 | loss 1.0903 | acc 0.3792
23:55:58 [train] batch 7000/7649 | loss 1.0903 | acc 0.3792
23:56:02 [train] batch 7200/7649 | loss 1.0903 | acc 0.3792
23:56:05 [train] batch 7400/7649 | loss 1.0903 | acc 0.3792
23:56:08 [train] batch 7600/7649 | loss 1.0902 | acc 0.3793
23:56:09 [train] batch 7649/7649 | loss 1.0902 | acc 0.3793
23:56:16 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_08.png
23:56:16 Epoch 08 | train 1.0902/0.3793 | val 1.0940/0.3676 | lr 5.00e-06
23:56:16 ✓ save best
23:56:19 [train] batch 200/7649 | loss 1.0905 | acc 0.3800
23:56:23 [train] batch 400/7649 | loss 1.0911 | acc 0.3789
23:56:26 [train] batch 600/7649 | loss 1.0907 | acc 0.3794
23:56:30 [train] batch 800/7649 | loss 1.0906 | acc 0.3790
23:56:33 [train] batch 1000/7649 | loss 1.0907 | acc 0.3785
23:56:36 [train] batch 1200/7649 | loss 1.0905 | acc 0.3789
23:56:39 [train] batch 1400/7649 | loss 1.0903 | acc 0.3788
23:56:43 [train] batch 1600/7649 | loss 1.0904 | acc 0.3785
23:56:46 [train] batch 1800/7649 | loss 1.0905 | acc 0.3783
23:56:49 [train] batch 2000/7649 | loss 1.0904 | acc 0.3785
23:56:52 [train] batch 2200/7649 | loss 1.0905 | acc 0.3781
23:56:56 [train] batch 2400/7649 | loss 1.0904 | acc 0.3782
23:56:59 [train] batch 2600/7649 | loss 1.0904 | acc 0.3785
23:57:02 [train] batch 2800/7649 | loss 1.0904 | acc 0.3787
23:57:05 [train] batch 3000/7649 | loss 1.0903 | acc 0.3790
23:57:09 [train] batch 3200/7649 | loss 1.0903 | acc 0.3789
23:57:12 [train] batch 3400/7649 | loss 1.0903 | acc 0.3787
23:57:15 [train] batch 3600/7649 | loss 1.0903 | acc 0.3787
23:57:19 [train] batch 3800/7649 | loss 1.0903 | acc 0.3786
23:57:22 [train] batch 4000/7649 | loss 1.0904 | acc 0.3785
23:57:25 [train] batch 4200/7649 | loss 1.0904 | acc 0.3786
23:57:29 [train] batch 4400/7649 | loss 1.0904 | acc 0.3784
23:57:32 [train] batch 4600/7649 | loss 1.0904 | acc 0.3786
23:57:36 [train] batch 4800/7649 | loss 1.0904 | acc 0.3786
23:57:39 [train] batch 5000/7649 | loss 1.0903 | acc 0.3788
23:57:42 [train] batch 5200/7649 | loss 1.0903 | acc 0.3787
23:57:46 [train] batch 5400/7649 | loss 1.0903 | acc 0.3787
23:57:49 [train] batch 5600/7649 | loss 1.0903 | acc 0.3789
23:57:52 [train] batch 5800/7649 | loss 1.0903 | acc 0.3789
23:57:56 [train] batch 6000/7649 | loss 1.0903 | acc 0.3789
23:57:59 [train] batch 6200/7649 | loss 1.0903 | acc 0.3789
23:58:02 [train] batch 6400/7649 | loss 1.0902 | acc 0.3789
23:58:06 [train] batch 6600/7649 | loss 1.0902 | acc 0.3789
23:58:09 [train] batch 6800/7649 | loss 1.0902 | acc 0.3790
23:58:12 [train] batch 7000/7649 | loss 1.0902 | acc 0.3790
23:58:16 [train] batch 7200/7649 | loss 1.0902 | acc 0.3789
23:58:19 [train] batch 7400/7649 | loss 1.0902 | acc 0.3789
23:58:22 [train] batch 7600/7649 | loss 1.0902 | acc 0.3790
23:58:23 [train] batch 7649/7649 | loss 1.0902 | acc 0.3791
23:58:30 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_09.png
23:58:30 Epoch 09 | train 1.0902/0.3791 | val 1.0944/0.3668 | lr 5.00e-06
23:58:34 [train] batch 200/7649 | loss 1.0899 | acc 0.3819
23:58:38 [train] batch 400/7649 | loss 1.0899 | acc 0.3817
23:58:41 [train] batch 600/7649 | loss 1.0903 | acc 0.3812
23:58:44 [train] batch 800/7649 | loss 1.0904 | acc 0.3806
23:58:48 [train] batch 1000/7649 | loss 1.0902 | acc 0.3806
23:58:51 [train] batch 1200/7649 | loss 1.0902 | acc 0.3812
23:58:54 [train] batch 1400/7649 | loss 1.0902 | acc 0.3808
23:58:58 [train] batch 1600/7649 | loss 1.0902 | acc 0.3806
23:59:01 [train] batch 1800/7649 | loss 1.0903 | acc 0.3802
23:59:04 [train] batch 2000/7649 | loss 1.0902 | acc 0.3801
23:59:08 [train] batch 2200/7649 | loss 1.0902 | acc 0.3799
23:59:11 [train] batch 2400/7649 | loss 1.0902 | acc 0.3801
23:59:15 [train] batch 2600/7649 | loss 1.0902 | acc 0.3799
23:59:18 [train] batch 2800/7649 | loss 1.0901 | acc 0.3801
23:59:21 [train] batch 3000/7649 | loss 1.0902 | acc 0.3798
23:59:25 [train] batch 3200/7649 | loss 1.0901 | acc 0.3799
23:59:28 [train] batch 3400/7649 | loss 1.0901 | acc 0.3798
23:59:31 [train] batch 3600/7649 | loss 1.0901 | acc 0.3799
23:59:35 [train] batch 3800/7649 | loss 1.0901 | acc 0.3798
23:59:38 [train] batch 4000/7649 | loss 1.0900 | acc 0.3800
23:59:41 [train] batch 4200/7649 | loss 1.0900 | acc 0.3799
23:59:45 [train] batch 4400/7649 | loss 1.0900 | acc 0.3800
23:59:48 [train] batch 4600/7649 | loss 1.0901 | acc 0.3799
23:59:52 [train] batch 4800/7649 | loss 1.0901 | acc 0.3799
23:59:55 [train] batch 5000/7649 | loss 1.0900 | acc 0.3800
23:59:58 [train] batch 5200/7649 | loss 1.0900 | acc 0.3799
00:00:02 [train] batch 5400/7649 | loss 1.0901 | acc 0.3798
00:00:05 [train] batch 5600/7649 | loss 1.0901 | acc 0.3798
00:00:08 [train] batch 5800/7649 | loss 1.0901 | acc 0.3799
00:00:12 [train] batch 6000/7649 | loss 1.0901 | acc 0.3799
00:00:15 [train] batch 6200/7649 | loss 1.0901 | acc 0.3799
00:00:18 [train] batch 6400/7649 | loss 1.0900 | acc 0.3799
00:00:21 [train] batch 6600/7649 | loss 1.0900 | acc 0.3799
00:00:25 [train] batch 6800/7649 | loss 1.0901 | acc 0.3799
00:00:28 [train] batch 7000/7649 | loss 1.0900 | acc 0.3799
00:00:31 [train] batch 7200/7649 | loss 1.0900 | acc 0.3799
00:00:35 [train] batch 7400/7649 | loss 1.0900 | acc 0.3798
00:00:38 [train] batch 7600/7649 | loss 1.0900 | acc 0.3799
00:00:39 [train] batch 7649/7649 | loss 1.0900 | acc 0.3800
00:00:45 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_10.png
00:00:46 Epoch 10 | train 1.0900/0.3800 | val 1.0939/0.3677 | lr 5.00e-06
00:00:46 ✓ save best
00:00:49 [train] batch 200/7649 | loss 1.0902 | acc 0.3775
00:00:52 [train] batch 400/7649 | loss 1.0901 | acc 0.3784
00:00:56 [train] batch 600/7649 | loss 1.0902 | acc 0.3778
00:00:59 [train] batch 800/7649 | loss 1.0902 | acc 0.3782
00:01:02 [train] batch 1000/7649 | loss 1.0900 | acc 0.3787
00:01:06 [train] batch 1200/7649 | loss 1.0900 | acc 0.3790
00:01:09 [train] batch 1400/7649 | loss 1.0899 | acc 0.3795
00:01:12 [train] batch 1600/7649 | loss 1.0899 | acc 0.3795
00:01:15 [train] batch 1800/7649 | loss 1.0899 | acc 0.3800
00:01:19 [train] batch 2000/7649 | loss 1.0899 | acc 0.3797
00:01:22 [train] batch 2200/7649 | loss 1.0900 | acc 0.3793
00:01:25 [train] batch 2400/7649 | loss 1.0899 | acc 0.3795
00:01:28 [train] batch 2600/7649 | loss 1.0900 | acc 0.3793
00:01:32 [train] batch 2800/7649 | loss 1.0900 | acc 0.3792
00:01:35 [train] batch 3000/7649 | loss 1.0900 | acc 0.3790
00:01:38 [train] batch 3200/7649 | loss 1.0899 | acc 0.3791
00:01:41 [train] batch 3400/7649 | loss 1.0899 | acc 0.3791
00:01:45 [train] batch 3600/7649 | loss 1.0899 | acc 0.3794
00:01:48 [train] batch 3800/7649 | loss 1.0899 | acc 0.3796
00:01:51 [train] batch 4000/7649 | loss 1.0899 | acc 0.3796
00:01:55 [train] batch 4200/7649 | loss 1.0899 | acc 0.3797
00:01:58 [train] batch 4400/7649 | loss 1.0898 | acc 0.3796
00:02:01 [train] batch 4600/7649 | loss 1.0898 | acc 0.3797
00:02:05 [train] batch 4800/7649 | loss 1.0898 | acc 0.3797
00:02:08 [train] batch 5000/7649 | loss 1.0898 | acc 0.3797
00:02:11 [train] batch 5200/7649 | loss 1.0898 | acc 0.3797
00:02:15 [train] batch 5400/7649 | loss 1.0898 | acc 0.3798
00:02:18 [train] batch 5600/7649 | loss 1.0898 | acc 0.3798
00:02:21 [train] batch 5800/7649 | loss 1.0898 | acc 0.3798
00:02:25 [train] batch 6000/7649 | loss 1.0898 | acc 0.3797
00:02:28 [train] batch 6200/7649 | loss 1.0898 | acc 0.3797
00:02:31 [train] batch 6400/7649 | loss 1.0898 | acc 0.3798
00:02:35 [train] batch 6600/7649 | loss 1.0898 | acc 0.3799
00:02:38 [train] batch 6800/7649 | loss 1.0898 | acc 0.3799
00:02:41 [train] batch 7000/7649 | loss 1.0898 | acc 0.3799
00:02:45 [train] batch 7200/7649 | loss 1.0898 | acc 0.3800
00:02:48 [train] batch 7400/7649 | loss 1.0898 | acc 0.3800
00:02:51 [train] batch 7600/7649 | loss 1.0898 | acc 0.3799
00:02:52 [train] batch 7649/7649 | loss 1.0898 | acc 0.3799
00:02:59 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_11.png
00:02:59 Epoch 11 | train 1.0898/0.3799 | val 1.0941/0.3674 | lr 2.50e-06
00:03:03 [train] batch 200/7649 | loss 1.0892 | acc 0.3822
00:03:06 [train] batch 400/7649 | loss 1.0896 | acc 0.3789
00:03:10 [train] batch 600/7649 | loss 1.0893 | acc 0.3798
00:03:13 [train] batch 800/7649 | loss 1.0897 | acc 0.3797
00:03:16 [train] batch 1000/7649 | loss 1.0894 | acc 0.3807
00:03:20 [train] batch 1200/7649 | loss 1.0899 | acc 0.3801
00:03:23 [train] batch 1400/7649 | loss 1.0897 | acc 0.3802
00:03:26 [train] batch 1600/7649 | loss 1.0899 | acc 0.3801
00:03:30 [train] batch 1800/7649 | loss 1.0899 | acc 0.3801
00:03:33 [train] batch 2000/7649 | loss 1.0899 | acc 0.3800
00:03:36 [train] batch 2200/7649 | loss 1.0899 | acc 0.3800
00:03:40 [train] batch 2400/7649 | loss 1.0899 | acc 0.3802
00:03:43 [train] batch 2600/7649 | loss 1.0899 | acc 0.3802
00:03:46 [train] batch 2800/7649 | loss 1.0899 | acc 0.3801
00:03:50 [train] batch 3000/7649 | loss 1.0899 | acc 0.3798
00:03:53 [train] batch 3200/7649 | loss 1.0899 | acc 0.3799
00:03:56 [train] batch 3400/7649 | loss 1.0899 | acc 0.3799
00:04:00 [train] batch 3600/7649 | loss 1.0898 | acc 0.3798
00:04:03 [train] batch 3800/7649 | loss 1.0898 | acc 0.3797
00:04:06 [train] batch 4000/7649 | loss 1.0898 | acc 0.3797
00:04:10 [train] batch 4200/7649 | loss 1.0898 | acc 0.3799
00:04:13 [train] batch 4400/7649 | loss 1.0897 | acc 0.3799
00:04:17 [train] batch 4600/7649 | loss 1.0897 | acc 0.3800
00:04:20 [train] batch 4800/7649 | loss 1.0897 | acc 0.3800
00:04:23 [train] batch 5000/7649 | loss 1.0897 | acc 0.3799
00:04:26 [train] batch 5200/7649 | loss 1.0898 | acc 0.3799
00:04:30 [train] batch 5400/7649 | loss 1.0897 | acc 0.3799
00:04:33 [train] batch 5600/7649 | loss 1.0897 | acc 0.3801
00:04:36 [train] batch 5800/7649 | loss 1.0897 | acc 0.3801
00:04:40 [train] batch 6000/7649 | loss 1.0897 | acc 0.3802
00:04:43 [train] batch 6200/7649 | loss 1.0897 | acc 0.3800
00:04:46 [train] batch 6400/7649 | loss 1.0897 | acc 0.3799
00:04:49 [train] batch 6600/7649 | loss 1.0897 | acc 0.3799
00:04:53 [train] batch 6800/7649 | loss 1.0897 | acc 0.3800
00:04:56 [train] batch 7000/7649 | loss 1.0897 | acc 0.3801
00:04:59 [train] batch 7200/7649 | loss 1.0897 | acc 0.3801
00:05:02 [train] batch 7400/7649 | loss 1.0897 | acc 0.3800
00:05:06 [train] batch 7600/7649 | loss 1.0897 | acc 0.3802
00:05:07 [train] batch 7649/7649 | loss 1.0897 | acc 0.3802
00:05:14 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_12.png
00:05:14 Epoch 12 | train 1.0897/0.3802 | val 1.0941/0.3679 | lr 2.50e-06
00:05:14 ✓ save best
00:05:17 [train] batch 200/7649 | loss 1.0895 | acc 0.3809
00:05:21 [train] batch 400/7649 | loss 1.0890 | acc 0.3829
00:05:24 [train] batch 600/7649 | loss 1.0895 | acc 0.3822
00:05:27 [train] batch 800/7649 | loss 1.0897 | acc 0.3813
00:05:30 [train] batch 1000/7649 | loss 1.0899 | acc 0.3810
00:05:34 [train] batch 1200/7649 | loss 1.0898 | acc 0.3810
00:05:37 [train] batch 1400/7649 | loss 1.0898 | acc 0.3808
00:05:40 [train] batch 1600/7649 | loss 1.0897 | acc 0.3809
00:05:43 [train] batch 1800/7649 | loss 1.0896 | acc 0.3812
00:05:47 [train] batch 2000/7649 | loss 1.0896 | acc 0.3810
00:05:50 [train] batch 2200/7649 | loss 1.0897 | acc 0.3810
00:05:53 [train] batch 2400/7649 | loss 1.0897 | acc 0.3811
00:05:56 [train] batch 2600/7649 | loss 1.0896 | acc 0.3809
00:06:00 [train] batch 2800/7649 | loss 1.0896 | acc 0.3811
00:06:03 [train] batch 3000/7649 | loss 1.0896 | acc 0.3810
00:06:06 [train] batch 3200/7649 | loss 1.0895 | acc 0.3813
00:06:09 [train] batch 3400/7649 | loss 1.0896 | acc 0.3814
00:06:13 [train] batch 3600/7649 | loss 1.0896 | acc 0.3813
00:06:16 [train] batch 3800/7649 | loss 1.0896 | acc 0.3814
00:06:19 [train] batch 4000/7649 | loss 1.0897 | acc 0.3814
00:06:23 [train] batch 4200/7649 | loss 1.0897 | acc 0.3813
00:06:26 [train] batch 4400/7649 | loss 1.0897 | acc 0.3813
00:06:29 [train] batch 4600/7649 | loss 1.0897 | acc 0.3813
00:06:32 [train] batch 4800/7649 | loss 1.0896 | acc 0.3814
00:06:36 [train] batch 5000/7649 | loss 1.0896 | acc 0.3814
00:06:39 [train] batch 5200/7649 | loss 1.0897 | acc 0.3812
00:06:42 [train] batch 5400/7649 | loss 1.0897 | acc 0.3809
00:06:45 [train] batch 5600/7649 | loss 1.0897 | acc 0.3809
00:06:49 [train] batch 5800/7649 | loss 1.0896 | acc 0.3809
00:06:52 [train] batch 6000/7649 | loss 1.0896 | acc 0.3809
00:06:55 [train] batch 6200/7649 | loss 1.0896 | acc 0.3808
00:06:58 [train] batch 6400/7649 | loss 1.0896 | acc 0.3808
00:07:02 [train] batch 6600/7649 | loss 1.0896 | acc 0.3808
00:07:05 [train] batch 6800/7649 | loss 1.0896 | acc 0.3809
00:07:08 [train] batch 7000/7649 | loss 1.0896 | acc 0.3809
00:07:11 [train] batch 7200/7649 | loss 1.0896 | acc 0.3808
00:07:15 [train] batch 7400/7649 | loss 1.0896 | acc 0.3808
00:07:18 [train] batch 7600/7649 | loss 1.0896 | acc 0.3808
00:07:19 [train] batch 7649/7649 | loss 1.0896 | acc 0.3809
00:07:25 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_13.png
00:07:25 Epoch 13 | train 1.0896/0.3809 | val 1.0939/0.3676 | lr 2.50e-06
00:07:28 [train] batch 200/7649 | loss 1.0897 | acc 0.3795
00:07:32 [train] batch 400/7649 | loss 1.0894 | acc 0.3811
00:07:35 [train] batch 600/7649 | loss 1.0895 | acc 0.3804
00:07:38 [train] batch 800/7649 | loss 1.0894 | acc 0.3809
00:07:42 [train] batch 1000/7649 | loss 1.0895 | acc 0.3815
00:07:45 [train] batch 1200/7649 | loss 1.0894 | acc 0.3818
00:07:48 [train] batch 1400/7649 | loss 1.0894 | acc 0.3816
00:07:52 [train] batch 1600/7649 | loss 1.0895 | acc 0.3812
00:07:55 [train] batch 1800/7649 | loss 1.0896 | acc 0.3809
00:07:58 [train] batch 2000/7649 | loss 1.0897 | acc 0.3806
00:08:01 [train] batch 2200/7649 | loss 1.0896 | acc 0.3806
00:08:05 [train] batch 2400/7649 | loss 1.0897 | acc 0.3803
00:08:08 [train] batch 2600/7649 | loss 1.0896 | acc 0.3804
00:08:11 [train] batch 2800/7649 | loss 1.0896 | acc 0.3803
00:08:15 [train] batch 3000/7649 | loss 1.0897 | acc 0.3802
00:08:18 [train] batch 3200/7649 | loss 1.0897 | acc 0.3800
00:08:21 [train] batch 3400/7649 | loss 1.0897 | acc 0.3801
00:08:25 [train] batch 3600/7649 | loss 1.0897 | acc 0.3802
00:08:28 [train] batch 3800/7649 | loss 1.0896 | acc 0.3803
00:08:32 [train] batch 4000/7649 | loss 1.0896 | acc 0.3802
00:08:35 [train] batch 4200/7649 | loss 1.0896 | acc 0.3804
00:08:39 [train] batch 4400/7649 | loss 1.0896 | acc 0.3804
00:08:42 [train] batch 4600/7649 | loss 1.0895 | acc 0.3805
00:08:45 [train] batch 4800/7649 | loss 1.0896 | acc 0.3802
00:08:49 [train] batch 5000/7649 | loss 1.0896 | acc 0.3802
00:08:52 [train] batch 5200/7649 | loss 1.0896 | acc 0.3803
00:08:55 [train] batch 5400/7649 | loss 1.0895 | acc 0.3805
00:08:59 [train] batch 5600/7649 | loss 1.0894 | acc 0.3806
00:09:02 [train] batch 5800/7649 | loss 1.0894 | acc 0.3807
00:09:05 [train] batch 6000/7649 | loss 1.0894 | acc 0.3807
00:09:09 [train] batch 6200/7649 | loss 1.0894 | acc 0.3807
00:09:12 [train] batch 6400/7649 | loss 1.0894 | acc 0.3809
00:09:15 [train] batch 6600/7649 | loss 1.0894 | acc 0.3810
00:09:19 [train] batch 6800/7649 | loss 1.0894 | acc 0.3810
00:09:22 [train] batch 7000/7649 | loss 1.0894 | acc 0.3810
00:09:25 [train] batch 7200/7649 | loss 1.0894 | acc 0.3809
00:09:29 [train] batch 7400/7649 | loss 1.0894 | acc 0.3809
00:09:32 [train] batch 7600/7649 | loss 1.0895 | acc 0.3808
00:09:33 [train] batch 7649/7649 | loss 1.0895 | acc 0.3808
00:09:40 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_14.png
00:09:40 Epoch 14 | train 1.0895/0.3808 | val 1.0940/0.3675 | lr 2.50e-06
00:09:43 [train] batch 200/7649 | loss 1.0895 | acc 0.3792
00:09:47 [train] batch 400/7649 | loss 1.0894 | acc 0.3793
00:09:50 [train] batch 600/7649 | loss 1.0897 | acc 0.3789
00:09:53 [train] batch 800/7649 | loss 1.0898 | acc 0.3791
00:09:57 [train] batch 1000/7649 | loss 1.0896 | acc 0.3794
00:10:00 [train] batch 1200/7649 | loss 1.0894 | acc 0.3800
00:10:03 [train] batch 1400/7649 | loss 1.0895 | acc 0.3803
00:10:07 [train] batch 1600/7649 | loss 1.0895 | acc 0.3802
00:10:10 [train] batch 1800/7649 | loss 1.0894 | acc 0.3804
00:10:13 [train] batch 2000/7649 | loss 1.0895 | acc 0.3805
00:10:17 [train] batch 2200/7649 | loss 1.0894 | acc 0.3807
00:10:20 [train] batch 2400/7649 | loss 1.0894 | acc 0.3806
00:10:23 [train] batch 2600/7649 | loss 1.0895 | acc 0.3805
00:10:27 [train] batch 2800/7649 | loss 1.0895 | acc 0.3806
00:10:30 [train] batch 3000/7649 | loss 1.0894 | acc 0.3806
00:10:33 [train] batch 3200/7649 | loss 1.0894 | acc 0.3808
00:10:37 [train] batch 3400/7649 | loss 1.0893 | acc 0.3809
00:10:40 [train] batch 3600/7649 | loss 1.0894 | acc 0.3810
00:10:44 [train] batch 3800/7649 | loss 1.0893 | acc 0.3811
00:10:47 [train] batch 4000/7649 | loss 1.0893 | acc 0.3811
00:10:50 [train] batch 4200/7649 | loss 1.0894 | acc 0.3810
00:10:53 [train] batch 4400/7649 | loss 1.0894 | acc 0.3810
00:10:57 [train] batch 4600/7649 | loss 1.0894 | acc 0.3810
00:11:00 [train] batch 4800/7649 | loss 1.0894 | acc 0.3809
00:11:03 [train] batch 5000/7649 | loss 1.0894 | acc 0.3809
00:11:06 [train] batch 5200/7649 | loss 1.0894 | acc 0.3809
00:11:10 [train] batch 5400/7649 | loss 1.0894 | acc 0.3808
00:11:13 [train] batch 5600/7649 | loss 1.0894 | acc 0.3808
00:11:16 [train] batch 5800/7649 | loss 1.0894 | acc 0.3808
00:11:20 [train] batch 6000/7649 | loss 1.0894 | acc 0.3809
00:11:23 [train] batch 6200/7649 | loss 1.0894 | acc 0.3808
00:11:26 [train] batch 6400/7649 | loss 1.0893 | acc 0.3810
00:11:29 [train] batch 6600/7649 | loss 1.0894 | acc 0.3809
00:11:33 [train] batch 6800/7649 | loss 1.0894 | acc 0.3810
00:11:36 [train] batch 7000/7649 | loss 1.0893 | acc 0.3810
00:11:39 [train] batch 7200/7649 | loss 1.0894 | acc 0.3809
00:11:42 [train] batch 7400/7649 | loss 1.0894 | acc 0.3809
00:11:46 [train] batch 7600/7649 | loss 1.0894 | acc 0.3809
00:11:47 [train] batch 7649/7649 | loss 1.0894 | acc 0.3809
00:11:53 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_15.png
00:11:53 Epoch 15 | train 1.0894/0.3809 | val 1.0940/0.3674 | lr 1.25e-06
00:11:57 [train] batch 200/7649 | loss 1.0895 | acc 0.3810
00:12:00 [train] batch 400/7649 | loss 1.0898 | acc 0.3794
00:12:03 [train] batch 600/7649 | loss 1.0898 | acc 0.3796
00:12:07 [train] batch 800/7649 | loss 1.0898 | acc 0.3795
00:12:10 [train] batch 1000/7649 | loss 1.0899 | acc 0.3795
00:12:13 [train] batch 1200/7649 | loss 1.0897 | acc 0.3802
00:12:16 [train] batch 1400/7649 | loss 1.0897 | acc 0.3805
00:12:20 [train] batch 1600/7649 | loss 1.0897 | acc 0.3804
00:12:23 [train] batch 1800/7649 | loss 1.0898 | acc 0.3802
00:12:26 [train] batch 2000/7649 | loss 1.0899 | acc 0.3800
00:12:30 [train] batch 2200/7649 | loss 1.0898 | acc 0.3800
00:12:33 [train] batch 2400/7649 | loss 1.0897 | acc 0.3805
00:12:36 [train] batch 2600/7649 | loss 1.0897 | acc 0.3806
00:12:40 [train] batch 2800/7649 | loss 1.0896 | acc 0.3806
00:12:43 [train] batch 3000/7649 | loss 1.0895 | acc 0.3807
00:12:47 [train] batch 3200/7649 | loss 1.0895 | acc 0.3807
00:12:50 [train] batch 3400/7649 | loss 1.0894 | acc 0.3810
00:12:53 [train] batch 3600/7649 | loss 1.0894 | acc 0.3809
00:12:57 [train] batch 3800/7649 | loss 1.0894 | acc 0.3808
00:13:00 [train] batch 4000/7649 | loss 1.0894 | acc 0.3809
00:13:03 [train] batch 4200/7649 | loss 1.0894 | acc 0.3807
00:13:07 [train] batch 4400/7649 | loss 1.0894 | acc 0.3807
00:13:10 [train] batch 4600/7649 | loss 1.0894 | acc 0.3808
00:13:14 [train] batch 4800/7649 | loss 1.0894 | acc 0.3807
00:13:17 [train] batch 5000/7649 | loss 1.0894 | acc 0.3809
00:13:20 [train] batch 5200/7649 | loss 1.0894 | acc 0.3808
00:13:24 [train] batch 5400/7649 | loss 1.0894 | acc 0.3808
00:13:27 [train] batch 5600/7649 | loss 1.0894 | acc 0.3808
00:13:30 [train] batch 5800/7649 | loss 1.0894 | acc 0.3809
00:13:34 [train] batch 6000/7649 | loss 1.0894 | acc 0.3809
00:13:37 [train] batch 6200/7649 | loss 1.0894 | acc 0.3809
00:13:40 [train] batch 6400/7649 | loss 1.0894 | acc 0.3808
00:13:44 [train] batch 6600/7649 | loss 1.0894 | acc 0.3809
00:13:47 [train] batch 6800/7649 | loss 1.0894 | acc 0.3809
00:13:51 [train] batch 7000/7649 | loss 1.0894 | acc 0.3810
00:13:54 [train] batch 7200/7649 | loss 1.0893 | acc 0.3811
00:13:57 [train] batch 7400/7649 | loss 1.0893 | acc 0.3812
00:14:01 [train] batch 7600/7649 | loss 1.0893 | acc 0.3812
00:14:02 [train] batch 7649/7649 | loss 1.0893 | acc 0.3812
00:14:09 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_16.png
00:14:09 Epoch 16 | train 1.0893/0.3812 | val 1.0942/0.3673 | lr 1.25e-06
00:14:12 [train] batch 200/7649 | loss 1.0881 | acc 0.3846
00:14:16 [train] batch 400/7649 | loss 1.0891 | acc 0.3817
00:14:19 [train] batch 600/7649 | loss 1.0893 | acc 0.3795
00:14:22 [train] batch 800/7649 | loss 1.0894 | acc 0.3803
00:14:26 [train] batch 1000/7649 | loss 1.0893 | acc 0.3808
00:14:29 [train] batch 1200/7649 | loss 1.0894 | acc 0.3804
00:14:32 [train] batch 1400/7649 | loss 1.0893 | acc 0.3810
00:14:36 [train] batch 1600/7649 | loss 1.0894 | acc 0.3809
00:14:39 [train] batch 1800/7649 | loss 1.0893 | acc 0.3810
00:14:42 [train] batch 2000/7649 | loss 1.0894 | acc 0.3808
00:14:45 [train] batch 2200/7649 | loss 1.0893 | acc 0.3811
00:14:49 [train] batch 2400/7649 | loss 1.0893 | acc 0.3810
00:14:52 [train] batch 2600/7649 | loss 1.0894 | acc 0.3809
00:14:56 [train] batch 2800/7649 | loss 1.0895 | acc 0.3807
00:14:59 [train] batch 3000/7649 | loss 1.0896 | acc 0.3806
00:15:02 [train] batch 3200/7649 | loss 1.0896 | acc 0.3805
00:15:05 [train] batch 3400/7649 | loss 1.0896 | acc 0.3807
00:15:09 [train] batch 3600/7649 | loss 1.0896 | acc 0.3808
00:15:12 [train] batch 3800/7649 | loss 1.0895 | acc 0.3810
00:15:15 [train] batch 4000/7649 | loss 1.0895 | acc 0.3808
00:15:18 [train] batch 4200/7649 | loss 1.0895 | acc 0.3810
00:15:22 [train] batch 4400/7649 | loss 1.0895 | acc 0.3812
00:15:25 [train] batch 4600/7649 | loss 1.0895 | acc 0.3812
00:15:28 [train] batch 4800/7649 | loss 1.0895 | acc 0.3812
00:15:31 [train] batch 5000/7649 | loss 1.0895 | acc 0.3812
00:15:35 [train] batch 5200/7649 | loss 1.0894 | acc 0.3814
00:15:38 [train] batch 5400/7649 | loss 1.0894 | acc 0.3815
00:15:41 [train] batch 5600/7649 | loss 1.0893 | acc 0.3815
00:15:45 [train] batch 5800/7649 | loss 1.0893 | acc 0.3817
00:15:48 [train] batch 6000/7649 | loss 1.0893 | acc 0.3816
00:15:51 [train] batch 6200/7649 | loss 1.0893 | acc 0.3815
00:15:54 [train] batch 6400/7649 | loss 1.0893 | acc 0.3815
00:15:58 [train] batch 6600/7649 | loss 1.0893 | acc 0.3814
00:16:01 [train] batch 6800/7649 | loss 1.0893 | acc 0.3814
00:16:04 [train] batch 7000/7649 | loss 1.0893 | acc 0.3815
00:16:08 [train] batch 7200/7649 | loss 1.0893 | acc 0.3816
00:16:11 [train] batch 7400/7649 | loss 1.0893 | acc 0.3815
00:16:14 [train] batch 7600/7649 | loss 1.0893 | acc 0.3816
00:16:15 [train] batch 7649/7649 | loss 1.0893 | acc 0.3816
00:16:21 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_17.png
00:16:21 Epoch 17 | train 1.0893/0.3816 | val 1.0941/0.3680 | lr 1.25e-06
00:16:21 ✓ save best
00:16:25 [train] batch 200/7649 | loss 1.0891 | acc 0.3839
00:16:28 [train] batch 400/7649 | loss 1.0892 | acc 0.3823
00:16:32 [train] batch 600/7649 | loss 1.0889 | acc 0.3832
00:16:35 [train] batch 800/7649 | loss 1.0890 | acc 0.3828
00:16:38 [train] batch 1000/7649 | loss 1.0891 | acc 0.3827
00:16:41 [train] batch 1200/7649 | loss 1.0891 | acc 0.3826
00:16:45 [train] batch 1400/7649 | loss 1.0891 | acc 0.3822
00:16:48 [train] batch 1600/7649 | loss 1.0891 | acc 0.3819
00:16:51 [train] batch 1800/7649 | loss 1.0892 | acc 0.3817
00:16:55 [train] batch 2000/7649 | loss 1.0892 | acc 0.3816
00:16:58 [train] batch 2200/7649 | loss 1.0892 | acc 0.3818
00:17:02 [train] batch 2400/7649 | loss 1.0891 | acc 0.3821
00:17:05 [train] batch 2600/7649 | loss 1.0891 | acc 0.3821
00:17:08 [train] batch 2800/7649 | loss 1.0891 | acc 0.3821
00:17:12 [train] batch 3000/7649 | loss 1.0892 | acc 0.3820
00:17:15 [train] batch 3200/7649 | loss 1.0892 | acc 0.3820
00:17:18 [train] batch 3400/7649 | loss 1.0892 | acc 0.3821
00:17:22 [train] batch 3600/7649 | loss 1.0892 | acc 0.3820
00:17:25 [train] batch 3800/7649 | loss 1.0891 | acc 0.3820
00:17:28 [train] batch 4000/7649 | loss 1.0891 | acc 0.3819
00:17:32 [train] batch 4200/7649 | loss 1.0892 | acc 0.3820
00:17:35 [train] batch 4400/7649 | loss 1.0892 | acc 0.3820
00:17:38 [train] batch 4600/7649 | loss 1.0892 | acc 0.3818
00:17:42 [train] batch 4800/7649 | loss 1.0892 | acc 0.3818
00:17:45 [train] batch 5000/7649 | loss 1.0892 | acc 0.3818
00:17:48 [train] batch 5200/7649 | loss 1.0892 | acc 0.3819
00:17:52 [train] batch 5400/7649 | loss 1.0892 | acc 0.3819
00:17:55 [train] batch 5600/7649 | loss 1.0892 | acc 0.3819
00:17:58 [train] batch 5800/7649 | loss 1.0892 | acc 0.3817
00:18:02 [train] batch 6000/7649 | loss 1.0893 | acc 0.3817
00:18:05 [train] batch 6200/7649 | loss 1.0893 | acc 0.3817
00:18:08 [train] batch 6400/7649 | loss 1.0893 | acc 0.3817
00:18:12 [train] batch 6600/7649 | loss 1.0893 | acc 0.3817
00:18:15 [train] batch 6800/7649 | loss 1.0893 | acc 0.3816
00:18:19 [train] batch 7000/7649 | loss 1.0893 | acc 0.3814
00:18:22 [train] batch 7200/7649 | loss 1.0893 | acc 0.3814
00:18:25 [train] batch 7400/7649 | loss 1.0893 | acc 0.3815
00:18:29 [train] batch 7600/7649 | loss 1.0893 | acc 0.3815
00:18:30 [train] batch 7649/7649 | loss 1.0893 | acc 0.3815
00:18:36 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_18.png
00:18:36 Epoch 18 | train 1.0893/0.3815 | val 1.0938/0.3676 | lr 1.25e-06
00:18:40 [train] batch 200/7649 | loss 1.0901 | acc 0.3815
00:18:43 [train] batch 400/7649 | loss 1.0896 | acc 0.3815
00:18:47 [train] batch 600/7649 | loss 1.0895 | acc 0.3818
00:18:50 [train] batch 800/7649 | loss 1.0893 | acc 0.3813
00:18:53 [train] batch 1000/7649 | loss 1.0894 | acc 0.3811
00:18:56 [train] batch 1200/7649 | loss 1.0892 | acc 0.3817
00:19:00 [train] batch 1400/7649 | loss 1.0893 | acc 0.3819
00:19:03 [train] batch 1600/7649 | loss 1.0891 | acc 0.3823
00:19:06 [train] batch 1800/7649 | loss 1.0891 | acc 0.3819
00:19:10 [train] batch 2000/7649 | loss 1.0891 | acc 0.3820
00:19:13 [train] batch 2200/7649 | loss 1.0892 | acc 0.3820
00:19:17 [train] batch 2400/7649 | loss 1.0892 | acc 0.3820
00:19:20 [train] batch 2600/7649 | loss 1.0892 | acc 0.3820
00:19:23 [train] batch 2800/7649 | loss 1.0891 | acc 0.3822
00:19:26 [train] batch 3000/7649 | loss 1.0892 | acc 0.3820
00:19:30 [train] batch 3200/7649 | loss 1.0892 | acc 0.3820
00:19:33 [train] batch 3400/7649 | loss 1.0892 | acc 0.3820
00:19:36 [train] batch 3600/7649 | loss 1.0892 | acc 0.3820
00:19:40 [train] batch 3800/7649 | loss 1.0892 | acc 0.3819
00:19:43 [train] batch 4000/7649 | loss 1.0893 | acc 0.3816
00:19:46 [train] batch 4200/7649 | loss 1.0893 | acc 0.3816
00:19:49 [train] batch 4400/7649 | loss 1.0892 | acc 0.3817
00:19:53 [train] batch 4600/7649 | loss 1.0892 | acc 0.3816
00:19:56 [train] batch 4800/7649 | loss 1.0892 | acc 0.3816
00:19:59 [train] batch 5000/7649 | loss 1.0892 | acc 0.3816
00:20:02 [train] batch 5200/7649 | loss 1.0892 | acc 0.3816
00:20:06 [train] batch 5400/7649 | loss 1.0892 | acc 0.3816
00:20:09 [train] batch 5600/7649 | loss 1.0892 | acc 0.3816
00:20:12 [train] batch 5800/7649 | loss 1.0892 | acc 0.3816
00:20:15 [train] batch 6000/7649 | loss 1.0892 | acc 0.3816
00:20:19 [train] batch 6200/7649 | loss 1.0892 | acc 0.3816
00:20:22 [train] batch 6400/7649 | loss 1.0892 | acc 0.3816
00:20:25 [train] batch 6600/7649 | loss 1.0892 | acc 0.3816
00:20:29 [train] batch 6800/7649 | loss 1.0892 | acc 0.3817
00:20:32 [train] batch 7000/7649 | loss 1.0891 | acc 0.3817
00:20:35 [train] batch 7200/7649 | loss 1.0892 | acc 0.3817
00:20:39 [train] batch 7400/7649 | loss 1.0892 | acc 0.3816
00:20:42 [train] batch 7600/7649 | loss 1.0892 | acc 0.3814
00:20:43 [train] batch 7649/7649 | loss 1.0892 | acc 0.3814
00:20:49 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_19.png
00:20:49 Epoch 19 | train 1.0892/0.3814 | val 1.0939/0.3675 | lr 6.25e-07
00:20:53 [train] batch 200/7649 | loss 1.0911 | acc 0.3742
00:20:56 [train] batch 400/7649 | loss 1.0902 | acc 0.3771
00:20:59 [train] batch 600/7649 | loss 1.0897 | acc 0.3796
00:21:03 [train] batch 800/7649 | loss 1.0894 | acc 0.3801
00:21:06 [train] batch 1000/7649 | loss 1.0892 | acc 0.3809
00:21:09 [train] batch 1200/7649 | loss 1.0892 | acc 0.3808
00:21:13 [train] batch 1400/7649 | loss 1.0891 | acc 0.3815
00:21:16 [train] batch 1600/7649 | loss 1.0892 | acc 0.3814
00:21:20 [train] batch 1800/7649 | loss 1.0891 | acc 0.3816
00:21:23 [train] batch 2000/7649 | loss 1.0890 | acc 0.3815
00:21:27 [train] batch 2200/7649 | loss 1.0891 | acc 0.3816
00:21:30 [train] batch 2400/7649 | loss 1.0891 | acc 0.3813
00:21:33 [train] batch 2600/7649 | loss 1.0891 | acc 0.3813
00:21:37 [train] batch 2800/7649 | loss 1.0892 | acc 0.3812
00:21:40 [train] batch 3000/7649 | loss 1.0891 | acc 0.3815
00:21:43 [train] batch 3200/7649 | loss 1.0890 | acc 0.3816
00:21:47 [train] batch 3400/7649 | loss 1.0890 | acc 0.3815
00:21:50 [train] batch 3600/7649 | loss 1.0890 | acc 0.3815
00:21:53 [train] batch 3800/7649 | loss 1.0890 | acc 0.3814
00:21:57 [train] batch 4000/7649 | loss 1.0890 | acc 0.3816
00:22:00 [train] batch 4200/7649 | loss 1.0891 | acc 0.3815
00:22:03 [train] batch 4400/7649 | loss 1.0891 | acc 0.3814
00:22:07 [train] batch 4600/7649 | loss 1.0891 | acc 0.3814
00:22:10 [train] batch 4800/7649 | loss 1.0891 | acc 0.3815
00:22:13 [train] batch 5000/7649 | loss 1.0891 | acc 0.3815
00:22:17 [train] batch 5200/7649 | loss 1.0891 | acc 0.3816
00:22:20 [train] batch 5400/7649 | loss 1.0892 | acc 0.3814
00:22:23 [train] batch 5600/7649 | loss 1.0892 | acc 0.3814
00:22:27 [train] batch 5800/7649 | loss 1.0892 | acc 0.3813
00:22:30 [train] batch 6000/7649 | loss 1.0892 | acc 0.3815
00:22:34 [train] batch 6200/7649 | loss 1.0892 | acc 0.3815
00:22:37 [train] batch 6400/7649 | loss 1.0891 | acc 0.3816
00:22:40 [train] batch 6600/7649 | loss 1.0891 | acc 0.3816
00:22:44 [train] batch 6800/7649 | loss 1.0891 | acc 0.3816
00:22:47 [train] batch 7000/7649 | loss 1.0892 | acc 0.3816
00:22:50 [train] batch 7200/7649 | loss 1.0892 | acc 0.3816
00:22:54 [train] batch 7400/7649 | loss 1.0892 | acc 0.3816
00:22:57 [train] batch 7600/7649 | loss 1.0891 | acc 0.3817
00:22:58 [train] batch 7649/7649 | loss 1.0891 | acc 0.3817
00:23:04 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_20.png
00:23:04 Epoch 20 | train 1.0891/0.3817 | val 1.0938/0.3678 | lr 6.25e-07
00:23:08 [train] batch 200/7649 | loss 1.0903 | acc 0.3800
00:23:11 [train] batch 400/7649 | loss 1.0898 | acc 0.3797
00:23:15 [train] batch 600/7649 | loss 1.0893 | acc 0.3811
00:23:18 [train] batch 800/7649 | loss 1.0893 | acc 0.3810
00:23:21 [train] batch 1000/7649 | loss 1.0893 | acc 0.3807
00:23:25 [train] batch 1200/7649 | loss 1.0894 | acc 0.3800
00:23:28 [train] batch 1400/7649 | loss 1.0893 | acc 0.3805
00:23:32 [train] batch 1600/7649 | loss 1.0892 | acc 0.3807
00:23:35 [train] batch 1800/7649 | loss 1.0892 | acc 0.3808
00:23:38 [train] batch 2000/7649 | loss 1.0892 | acc 0.3808
00:23:41 [train] batch 2200/7649 | loss 1.0892 | acc 0.3809
00:23:45 [train] batch 2400/7649 | loss 1.0891 | acc 0.3809
00:23:48 [train] batch 2600/7649 | loss 1.0891 | acc 0.3810
00:23:51 [train] batch 2800/7649 | loss 1.0891 | acc 0.3813
00:23:55 [train] batch 3000/7649 | loss 1.0891 | acc 0.3813
00:23:58 [train] batch 3200/7649 | loss 1.0891 | acc 0.3815
00:24:01 [train] batch 3400/7649 | loss 1.0891 | acc 0.3815
00:24:04 [train] batch 3600/7649 | loss 1.0891 | acc 0.3814
00:24:08 [train] batch 3800/7649 | loss 1.0891 | acc 0.3813
00:24:11 [train] batch 4000/7649 | loss 1.0892 | acc 0.3813
00:24:14 [train] batch 4200/7649 | loss 1.0892 | acc 0.3813
00:24:17 [train] batch 4400/7649 | loss 1.0892 | acc 0.3811
00:24:21 [train] batch 4600/7649 | loss 1.0892 | acc 0.3811
00:24:24 [train] batch 4800/7649 | loss 1.0892 | acc 0.3811
00:24:27 [train] batch 5000/7649 | loss 1.0892 | acc 0.3810
00:24:30 [train] batch 5200/7649 | loss 1.0892 | acc 0.3810
00:24:34 [train] batch 5400/7649 | loss 1.0892 | acc 0.3810
00:24:37 [train] batch 5600/7649 | loss 1.0892 | acc 0.3810
00:24:40 [train] batch 5800/7649 | loss 1.0892 | acc 0.3810
00:24:44 [train] batch 6000/7649 | loss 1.0892 | acc 0.3811
00:24:47 [train] batch 6200/7649 | loss 1.0892 | acc 0.3810
00:24:50 [train] batch 6400/7649 | loss 1.0892 | acc 0.3811
00:24:53 [train] batch 6600/7649 | loss 1.0892 | acc 0.3812
00:24:57 [train] batch 6800/7649 | loss 1.0892 | acc 0.3812
00:25:00 [train] batch 7000/7649 | loss 1.0892 | acc 0.3813
00:25:03 [train] batch 7200/7649 | loss 1.0892 | acc 0.3814
00:25:07 [train] batch 7400/7649 | loss 1.0892 | acc 0.3814
00:25:10 [train] batch 7600/7649 | loss 1.0892 | acc 0.3815
00:25:11 [train] batch 7649/7649 | loss 1.0892 | acc 0.3815
00:25:17 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_21.png
00:25:17 Epoch 21 | train 1.0892/0.3815 | val 1.0939/0.3680 | lr 6.25e-07
00:25:17 ✓ save best
00:25:21 [train] batch 200/7649 | loss 1.0905 | acc 0.3798
00:25:24 [train] batch 400/7649 | loss 1.0899 | acc 0.3815
00:25:27 [train] batch 600/7649 | loss 1.0895 | acc 0.3817
00:25:31 [train] batch 800/7649 | loss 1.0894 | acc 0.3819
00:25:34 [train] batch 1000/7649 | loss 1.0895 | acc 0.3811
00:25:38 [train] batch 1200/7649 | loss 1.0895 | acc 0.3811
00:25:41 [train] batch 1400/7649 | loss 1.0896 | acc 0.3807
00:25:45 [train] batch 1600/7649 | loss 1.0896 | acc 0.3807
00:25:48 [train] batch 1800/7649 | loss 1.0895 | acc 0.3805
00:25:51 [train] batch 2000/7649 | loss 1.0895 | acc 0.3809
00:25:55 [train] batch 2200/7649 | loss 1.0894 | acc 0.3810
00:25:58 [train] batch 2400/7649 | loss 1.0894 | acc 0.3809
00:26:02 [train] batch 2600/7649 | loss 1.0894 | acc 0.3809
00:26:05 [train] batch 2800/7649 | loss 1.0894 | acc 0.3810
00:26:08 [train] batch 3000/7649 | loss 1.0893 | acc 0.3810
00:26:12 [train] batch 3200/7649 | loss 1.0893 | acc 0.3810
00:26:15 [train] batch 3400/7649 | loss 1.0893 | acc 0.3810
00:26:18 [train] batch 3600/7649 | loss 1.0893 | acc 0.3810
00:26:22 [train] batch 3800/7649 | loss 1.0894 | acc 0.3808
00:26:25 [train] batch 4000/7649 | loss 1.0894 | acc 0.3809
00:26:29 [train] batch 4200/7649 | loss 1.0893 | acc 0.3809
00:26:32 [train] batch 4400/7649 | loss 1.0893 | acc 0.3811
00:26:35 [train] batch 4600/7649 | loss 1.0893 | acc 0.3813
00:26:39 [train] batch 4800/7649 | loss 1.0893 | acc 0.3812
00:26:42 [train] batch 5000/7649 | loss 1.0893 | acc 0.3813
00:26:45 [train] batch 5200/7649 | loss 1.0893 | acc 0.3813
00:26:49 [train] batch 5400/7649 | loss 1.0893 | acc 0.3814
00:26:52 [train] batch 5600/7649 | loss 1.0893 | acc 0.3814
00:26:56 [train] batch 5800/7649 | loss 1.0892 | acc 0.3816
00:26:59 [train] batch 6000/7649 | loss 1.0892 | acc 0.3816
00:27:02 [train] batch 6200/7649 | loss 1.0892 | acc 0.3816
00:27:06 [train] batch 6400/7649 | loss 1.0892 | acc 0.3817
00:27:09 [train] batch 6600/7649 | loss 1.0891 | acc 0.3818
00:27:12 [train] batch 6800/7649 | loss 1.0892 | acc 0.3817
00:27:16 [train] batch 7000/7649 | loss 1.0891 | acc 0.3817
00:27:19 [train] batch 7200/7649 | loss 1.0892 | acc 0.3818
00:27:22 [train] batch 7400/7649 | loss 1.0892 | acc 0.3817
00:27:26 [train] batch 7600/7649 | loss 1.0892 | acc 0.3816
00:27:27 [train] batch 7649/7649 | loss 1.0892 | acc 0.3816
00:27:33 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_22.png
00:27:33 Epoch 22 | train 1.0892/0.3816 | val 1.0941/0.3680 | lr 6.25e-07
00:27:33 ✓ save best
00:27:37 [train] batch 200/7649 | loss 1.0896 | acc 0.3805
00:27:40 [train] batch 400/7649 | loss 1.0890 | acc 0.3807
00:27:44 [train] batch 600/7649 | loss 1.0892 | acc 0.3801
00:27:47 [train] batch 800/7649 | loss 1.0889 | acc 0.3804
00:27:51 [train] batch 1000/7649 | loss 1.0890 | acc 0.3805
00:27:54 [train] batch 1200/7649 | loss 1.0891 | acc 0.3805
00:27:57 [train] batch 1400/7649 | loss 1.0892 | acc 0.3803
00:28:00 [train] batch 1600/7649 | loss 1.0892 | acc 0.3803
00:28:04 [train] batch 1800/7649 | loss 1.0893 | acc 0.3800
00:28:07 [train] batch 2000/7649 | loss 1.0893 | acc 0.3802
00:28:10 [train] batch 2200/7649 | loss 1.0894 | acc 0.3801
00:28:13 [train] batch 2400/7649 | loss 1.0894 | acc 0.3800
00:28:17 [train] batch 2600/7649 | loss 1.0893 | acc 0.3800
00:28:20 [train] batch 2800/7649 | loss 1.0894 | acc 0.3799
00:28:23 [train] batch 3000/7649 | loss 1.0893 | acc 0.3802
00:28:26 [train] batch 3200/7649 | loss 1.0893 | acc 0.3803
00:28:30 [train] batch 3400/7649 | loss 1.0893 | acc 0.3804
00:28:33 [train] batch 3600/7649 | loss 1.0893 | acc 0.3805
00:28:36 [train] batch 3800/7649 | loss 1.0893 | acc 0.3807
00:28:40 [train] batch 4000/7649 | loss 1.0892 | acc 0.3808
00:28:43 [train] batch 4200/7649 | loss 1.0892 | acc 0.3808
00:28:46 [train] batch 4400/7649 | loss 1.0892 | acc 0.3811
00:28:49 [train] batch 4600/7649 | loss 1.0892 | acc 0.3811
00:28:53 [train] batch 4800/7649 | loss 1.0892 | acc 0.3810
00:28:56 [train] batch 5000/7649 | loss 1.0892 | acc 0.3810
00:28:59 [train] batch 5200/7649 | loss 1.0892 | acc 0.3811
00:29:03 [train] batch 5400/7649 | loss 1.0892 | acc 0.3811
00:29:06 [train] batch 5600/7649 | loss 1.0892 | acc 0.3812
00:29:09 [train] batch 5800/7649 | loss 1.0892 | acc 0.3812
00:29:12 [train] batch 6000/7649 | loss 1.0891 | acc 0.3812
00:29:16 [train] batch 6200/7649 | loss 1.0891 | acc 0.3813
00:29:19 [train] batch 6400/7649 | loss 1.0891 | acc 0.3813
00:29:22 [train] batch 6600/7649 | loss 1.0891 | acc 0.3814
00:29:26 [train] batch 6800/7649 | loss 1.0892 | acc 0.3813
00:29:29 [train] batch 7000/7649 | loss 1.0891 | acc 0.3814
00:29:32 [train] batch 7200/7649 | loss 1.0891 | acc 0.3814
00:29:36 [train] batch 7400/7649 | loss 1.0891 | acc 0.3814
00:29:39 [train] batch 7600/7649 | loss 1.0891 | acc 0.3815
00:29:40 [train] batch 7649/7649 | loss 1.0891 | acc 0.3814
00:29:47 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_23.png
00:29:47 Epoch 23 | train 1.0891/0.3814 | val 1.0940/0.3676 | lr 3.13e-07
00:29:50 [train] batch 200/7649 | loss 1.0890 | acc 0.3832
00:29:54 [train] batch 400/7649 | loss 1.0892 | acc 0.3840
00:29:58 [train] batch 600/7649 | loss 1.0889 | acc 0.3835
00:30:01 [train] batch 800/7649 | loss 1.0891 | acc 0.3827
00:30:04 [train] batch 1000/7649 | loss 1.0891 | acc 0.3826
00:30:08 [train] batch 1200/7649 | loss 1.0892 | acc 0.3829
00:30:11 [train] batch 1400/7649 | loss 1.0891 | acc 0.3830
00:30:14 [train] batch 1600/7649 | loss 1.0891 | acc 0.3828
00:30:18 [train] batch 1800/7649 | loss 1.0891 | acc 0.3825
00:30:21 [train] batch 2000/7649 | loss 1.0891 | acc 0.3825
00:30:24 [train] batch 2200/7649 | loss 1.0892 | acc 0.3824
00:30:28 [train] batch 2400/7649 | loss 1.0892 | acc 0.3822
00:30:31 [train] batch 2600/7649 | loss 1.0892 | acc 0.3820
00:30:34 [train] batch 2800/7649 | loss 1.0892 | acc 0.3819
00:30:38 [train] batch 3000/7649 | loss 1.0892 | acc 0.3819
00:30:41 [train] batch 3200/7649 | loss 1.0891 | acc 0.3818
00:30:44 [train] batch 3400/7649 | loss 1.0891 | acc 0.3816
00:30:48 [train] batch 3600/7649 | loss 1.0891 | acc 0.3818
00:30:51 [train] batch 3800/7649 | loss 1.0891 | acc 0.3819
00:30:54 [train] batch 4000/7649 | loss 1.0891 | acc 0.3817
00:30:58 [train] batch 4200/7649 | loss 1.0891 | acc 0.3818
00:31:01 [train] batch 4400/7649 | loss 1.0891 | acc 0.3819
00:31:05 [train] batch 4600/7649 | loss 1.0891 | acc 0.3819
00:31:08 [train] batch 4800/7649 | loss 1.0890 | acc 0.3820
00:31:11 [train] batch 5000/7649 | loss 1.0890 | acc 0.3821
00:31:15 [train] batch 5200/7649 | loss 1.0891 | acc 0.3819
00:31:18 [train] batch 5400/7649 | loss 1.0890 | acc 0.3821
00:31:21 [train] batch 5600/7649 | loss 1.0890 | acc 0.3822
00:31:25 [train] batch 5800/7649 | loss 1.0890 | acc 0.3821
00:31:28 [train] batch 6000/7649 | loss 1.0890 | acc 0.3821
00:31:31 [train] batch 6200/7649 | loss 1.0890 | acc 0.3822
00:31:35 [train] batch 6400/7649 | loss 1.0890 | acc 0.3822
00:31:38 [train] batch 6600/7649 | loss 1.0890 | acc 0.3822
00:31:41 [train] batch 6800/7649 | loss 1.0891 | acc 0.3822
00:31:45 [train] batch 7000/7649 | loss 1.0891 | acc 0.3821
00:31:48 [train] batch 7200/7649 | loss 1.0891 | acc 0.3821
00:31:51 [train] batch 7400/7649 | loss 1.0891 | acc 0.3821
00:31:55 [train] batch 7600/7649 | loss 1.0891 | acc 0.3821
00:31:56 [train] batch 7649/7649 | loss 1.0891 | acc 0.3821
00:32:03 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_24.png
00:32:03 Epoch 24 | train 1.0891/0.3821 | val 1.0940/0.3676 | lr 3.13e-07
00:32:07 [train] batch 200/7649 | loss 1.0888 | acc 0.3800
00:32:10 [train] batch 400/7649 | loss 1.0885 | acc 0.3832
00:32:13 [train] batch 600/7649 | loss 1.0888 | acc 0.3820
00:32:16 [train] batch 800/7649 | loss 1.0892 | acc 0.3800
00:32:20 [train] batch 1000/7649 | loss 1.0893 | acc 0.3802
00:32:23 [train] batch 1200/7649 | loss 1.0893 | acc 0.3805
00:32:26 [train] batch 1400/7649 | loss 1.0893 | acc 0.3807
00:32:29 [train] batch 1600/7649 | loss 1.0893 | acc 0.3807
00:32:33 [train] batch 1800/7649 | loss 1.0893 | acc 0.3806
00:32:36 [train] batch 2000/7649 | loss 1.0893 | acc 0.3804
00:32:39 [train] batch 2200/7649 | loss 1.0893 | acc 0.3805
00:32:43 [train] batch 2400/7649 | loss 1.0893 | acc 0.3805
00:32:46 [train] batch 2600/7649 | loss 1.0892 | acc 0.3806
00:32:49 [train] batch 2800/7649 | loss 1.0892 | acc 0.3807
00:32:52 [train] batch 3000/7649 | loss 1.0891 | acc 0.3808
00:32:56 [train] batch 3200/7649 | loss 1.0890 | acc 0.3811
00:32:59 [train] batch 3400/7649 | loss 1.0891 | acc 0.3812
00:33:02 [train] batch 3600/7649 | loss 1.0890 | acc 0.3810
00:33:05 [train] batch 3800/7649 | loss 1.0891 | acc 0.3811
00:33:09 [train] batch 4000/7649 | loss 1.0891 | acc 0.3811
00:33:12 [train] batch 4200/7649 | loss 1.0891 | acc 0.3812
00:33:16 [train] batch 4400/7649 | loss 1.0891 | acc 0.3813
00:33:19 [train] batch 4600/7649 | loss 1.0891 | acc 0.3813
00:33:22 [train] batch 4800/7649 | loss 1.0891 | acc 0.3812
00:33:26 [train] batch 5000/7649 | loss 1.0891 | acc 0.3813
00:33:29 [train] batch 5200/7649 | loss 1.0891 | acc 0.3813
00:33:32 [train] batch 5400/7649 | loss 1.0891 | acc 0.3814
00:33:36 [train] batch 5600/7649 | loss 1.0891 | acc 0.3814
00:33:39 [train] batch 5800/7649 | loss 1.0891 | acc 0.3815
00:33:42 [train] batch 6000/7649 | loss 1.0891 | acc 0.3815
00:33:46 [train] batch 6200/7649 | loss 1.0891 | acc 0.3816
00:33:49 [train] batch 6400/7649 | loss 1.0891 | acc 0.3815
00:33:52 [train] batch 6600/7649 | loss 1.0891 | acc 0.3816
00:33:56 [train] batch 6800/7649 | loss 1.0891 | acc 0.3816
00:33:59 [train] batch 7000/7649 | loss 1.0891 | acc 0.3815
00:34:02 [train] batch 7200/7649 | loss 1.0891 | acc 0.3816
00:34:06 [train] batch 7400/7649 | loss 1.0891 | acc 0.3816
00:34:09 [train] batch 7600/7649 | loss 1.0891 | acc 0.3817
00:34:10 [train] batch 7649/7649 | loss 1.0891 | acc 0.3817
00:34:17 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_25.png
00:34:17 Epoch 25 | train 1.0891/0.3817 | val 1.0940/0.3678 | lr 3.13e-07
00:34:21 [train] batch 200/7649 | loss 1.0886 | acc 0.3850
00:34:24 [train] batch 400/7649 | loss 1.0891 | acc 0.3838
00:34:27 [train] batch 600/7649 | loss 1.0894 | acc 0.3817
00:34:31 [train] batch 800/7649 | loss 1.0894 | acc 0.3821
00:34:34 [train] batch 1000/7649 | loss 1.0893 | acc 0.3817
00:34:37 [train] batch 1200/7649 | loss 1.0893 | acc 0.3814
00:34:41 [train] batch 1400/7649 | loss 1.0893 | acc 0.3817
00:34:44 [train] batch 1600/7649 | loss 1.0894 | acc 0.3816
00:34:47 [train] batch 1800/7649 | loss 1.0894 | acc 0.3817
00:34:51 [train] batch 2000/7649 | loss 1.0893 | acc 0.3819
00:34:54 [train] batch 2200/7649 | loss 1.0894 | acc 0.3817
00:34:57 [train] batch 2400/7649 | loss 1.0894 | acc 0.3817
00:35:01 [train] batch 2600/7649 | loss 1.0894 | acc 0.3817
00:35:04 [train] batch 2800/7649 | loss 1.0894 | acc 0.3816
00:35:07 [train] batch 3000/7649 | loss 1.0894 | acc 0.3814
00:35:11 [train] batch 3200/7649 | loss 1.0893 | acc 0.3814
00:35:14 [train] batch 3400/7649 | loss 1.0893 | acc 0.3814
00:35:17 [train] batch 3600/7649 | loss 1.0893 | acc 0.3815
00:35:21 [train] batch 3800/7649 | loss 1.0893 | acc 0.3815
00:35:24 [train] batch 4000/7649 | loss 1.0892 | acc 0.3818
00:35:27 [train] batch 4200/7649 | loss 1.0892 | acc 0.3816
00:35:31 [train] batch 4400/7649 | loss 1.0892 | acc 0.3816
00:35:34 [train] batch 4600/7649 | loss 1.0892 | acc 0.3817
00:35:38 [train] batch 4800/7649 | loss 1.0892 | acc 0.3817
00:35:41 [train] batch 5000/7649 | loss 1.0892 | acc 0.3817
00:35:44 [train] batch 5200/7649 | loss 1.0892 | acc 0.3817
00:35:47 [train] batch 5400/7649 | loss 1.0892 | acc 0.3816
00:35:51 [train] batch 5600/7649 | loss 1.0892 | acc 0.3817
00:35:54 [train] batch 5800/7649 | loss 1.0892 | acc 0.3816
00:35:57 [train] batch 6000/7649 | loss 1.0891 | acc 0.3817
00:36:01 [train] batch 6200/7649 | loss 1.0891 | acc 0.3818
00:36:04 [train] batch 6400/7649 | loss 1.0891 | acc 0.3817
00:36:07 [train] batch 6600/7649 | loss 1.0891 | acc 0.3817
00:36:10 [train] batch 6800/7649 | loss 1.0891 | acc 0.3818
00:36:14 [train] batch 7000/7649 | loss 1.0891 | acc 0.3818
00:36:17 [train] batch 7200/7649 | loss 1.0891 | acc 0.3818
00:36:20 [train] batch 7400/7649 | loss 1.0891 | acc 0.3819
00:36:24 [train] batch 7600/7649 | loss 1.0891 | acc 0.3819
00:36:24 [train] batch 7649/7649 | loss 1.0891 | acc 0.3819
00:36:31 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_26.png
00:36:31 Epoch 26 | train 1.0891/0.3819 | val 1.0939/0.3678 | lr 3.13e-07
00:36:34 [train] batch 200/7649 | loss 1.0886 | acc 0.3818
00:36:38 [train] batch 400/7649 | loss 1.0882 | acc 0.3835
00:36:41 [train] batch 600/7649 | loss 1.0886 | acc 0.3827
00:36:44 [train] batch 800/7649 | loss 1.0889 | acc 0.3819
00:36:47 [train] batch 1000/7649 | loss 1.0889 | acc 0.3812
00:36:51 [train] batch 1200/7649 | loss 1.0891 | acc 0.3811
00:36:54 [train] batch 1400/7649 | loss 1.0891 | acc 0.3813
00:36:57 [train] batch 1600/7649 | loss 1.0892 | acc 0.3816
00:37:00 [train] batch 1800/7649 | loss 1.0892 | acc 0.3813
00:37:04 [train] batch 2000/7649 | loss 1.0893 | acc 0.3814
00:37:07 [train] batch 2200/7649 | loss 1.0893 | acc 0.3816
00:37:10 [train] batch 2400/7649 | loss 1.0893 | acc 0.3815
00:37:13 [train] batch 2600/7649 | loss 1.0893 | acc 0.3815
00:37:17 [train] batch 2800/7649 | loss 1.0892 | acc 0.3817
00:37:20 [train] batch 3000/7649 | loss 1.0892 | acc 0.3818
00:37:23 [train] batch 3200/7649 | loss 1.0892 | acc 0.3818
00:37:27 [train] batch 3400/7649 | loss 1.0892 | acc 0.3819
00:37:30 [train] batch 3600/7649 | loss 1.0892 | acc 0.3820
00:37:33 [train] batch 3800/7649 | loss 1.0892 | acc 0.3818
00:37:37 [train] batch 4000/7649 | loss 1.0892 | acc 0.3819
00:37:40 [train] batch 4200/7649 | loss 1.0891 | acc 0.3821
00:37:43 [train] batch 4400/7649 | loss 1.0892 | acc 0.3820
00:37:47 [train] batch 4600/7649 | loss 1.0891 | acc 0.3819
00:37:50 [train] batch 4800/7649 | loss 1.0892 | acc 0.3819
00:37:53 [train] batch 5000/7649 | loss 1.0891 | acc 0.3819
00:37:57 [train] batch 5200/7649 | loss 1.0891 | acc 0.3820
00:38:00 [train] batch 5400/7649 | loss 1.0891 | acc 0.3822
00:38:03 [train] batch 5600/7649 | loss 1.0891 | acc 0.3822
00:38:07 [train] batch 5800/7649 | loss 1.0891 | acc 0.3822
00:38:10 [train] batch 6000/7649 | loss 1.0891 | acc 0.3822
00:38:13 [train] batch 6200/7649 | loss 1.0891 | acc 0.3822
00:38:17 [train] batch 6400/7649 | loss 1.0891 | acc 0.3822
00:38:20 [train] batch 6600/7649 | loss 1.0891 | acc 0.3823
00:38:23 [train] batch 6800/7649 | loss 1.0891 | acc 0.3823
00:38:27 [train] batch 7000/7649 | loss 1.0890 | acc 0.3824
00:38:30 [train] batch 7200/7649 | loss 1.0891 | acc 0.3824
00:38:33 [train] batch 7400/7649 | loss 1.0891 | acc 0.3824
00:38:37 [train] batch 7600/7649 | loss 1.0891 | acc 0.3824
00:38:38 [train] batch 7649/7649 | loss 1.0891 | acc 0.3823
00:38:44 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_27.png
00:38:44 Epoch 27 | train 1.0891/0.3823 | val 1.0939/0.3678 | lr 1.56e-07
00:38:48 [train] batch 200/7649 | loss 1.0882 | acc 0.3838
00:38:51 [train] batch 400/7649 | loss 1.0884 | acc 0.3835
00:38:54 [train] batch 600/7649 | loss 1.0891 | acc 0.3815
00:38:58 [train] batch 800/7649 | loss 1.0891 | acc 0.3822
00:39:01 [train] batch 1000/7649 | loss 1.0889 | acc 0.3821
00:39:05 [train] batch 1200/7649 | loss 1.0891 | acc 0.3816
00:39:08 [train] batch 1400/7649 | loss 1.0890 | acc 0.3819
00:39:11 [train] batch 1600/7649 | loss 1.0890 | acc 0.3819
00:39:15 [train] batch 1800/7649 | loss 1.0889 | acc 0.3819
00:39:18 [train] batch 2000/7649 | loss 1.0889 | acc 0.3820
00:39:21 [train] batch 2200/7649 | loss 1.0889 | acc 0.3820
00:39:25 [train] batch 2400/7649 | loss 1.0890 | acc 0.3820
00:39:28 [train] batch 2600/7649 | loss 1.0890 | acc 0.3820
00:39:32 [train] batch 2800/7649 | loss 1.0889 | acc 0.3822
00:39:35 [train] batch 3000/7649 | loss 1.0889 | acc 0.3823
00:39:38 [train] batch 3200/7649 | loss 1.0889 | acc 0.3822
00:39:42 [train] batch 3400/7649 | loss 1.0889 | acc 0.3824
00:39:45 [train] batch 3600/7649 | loss 1.0890 | acc 0.3823
00:39:49 [train] batch 3800/7649 | loss 1.0890 | acc 0.3823
00:39:52 [train] batch 4000/7649 | loss 1.0890 | acc 0.3823
00:39:55 [train] batch 4200/7649 | loss 1.0890 | acc 0.3822
00:39:59 [train] batch 4400/7649 | loss 1.0890 | acc 0.3821
00:40:02 [train] batch 4600/7649 | loss 1.0890 | acc 0.3822
00:40:05 [train] batch 4800/7649 | loss 1.0890 | acc 0.3821
00:40:09 [train] batch 5000/7649 | loss 1.0890 | acc 0.3821
00:40:12 [train] batch 5200/7649 | loss 1.0890 | acc 0.3820
00:40:15 [train] batch 5400/7649 | loss 1.0890 | acc 0.3820
00:40:19 [train] batch 5600/7649 | loss 1.0890 | acc 0.3820
00:40:22 [train] batch 5800/7649 | loss 1.0890 | acc 0.3819
00:40:25 [train] batch 6000/7649 | loss 1.0890 | acc 0.3820
00:40:29 [train] batch 6200/7649 | loss 1.0891 | acc 0.3819
00:40:32 [train] batch 6400/7649 | loss 1.0891 | acc 0.3819
00:40:35 [train] batch 6600/7649 | loss 1.0891 | acc 0.3820
00:40:38 [train] batch 6800/7649 | loss 1.0891 | acc 0.3819
00:40:42 [train] batch 7000/7649 | loss 1.0891 | acc 0.3818
00:40:45 [train] batch 7200/7649 | loss 1.0891 | acc 0.3819
00:40:48 [train] batch 7400/7649 | loss 1.0891 | acc 0.3818
00:40:51 [train] batch 7600/7649 | loss 1.0891 | acc 0.3818
00:40:52 [train] batch 7649/7649 | loss 1.0891 | acc 0.3818
00:40:59 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_28.png
00:40:59 Epoch 28 | train 1.0891/0.3818 | val 1.0940/0.3677 | lr 1.56e-07
00:41:02 [train] batch 200/7649 | loss 1.0906 | acc 0.3780
00:41:06 [train] batch 400/7649 | loss 1.0902 | acc 0.3787
00:41:09 [train] batch 600/7649 | loss 1.0899 | acc 0.3795
00:41:12 [train] batch 800/7649 | loss 1.0895 | acc 0.3800
00:41:16 [train] batch 1000/7649 | loss 1.0893 | acc 0.3813
00:41:19 [train] batch 1200/7649 | loss 1.0893 | acc 0.3812
00:41:22 [train] batch 1400/7649 | loss 1.0893 | acc 0.3817
00:41:25 [train] batch 1600/7649 | loss 1.0893 | acc 0.3818
00:41:29 [train] batch 1800/7649 | loss 1.0892 | acc 0.3816
00:41:32 [train] batch 2000/7649 | loss 1.0892 | acc 0.3817
00:41:35 [train] batch 2200/7649 | loss 1.0893 | acc 0.3815
00:41:39 [train] batch 2400/7649 | loss 1.0893 | acc 0.3814
00:41:42 [train] batch 2600/7649 | loss 1.0893 | acc 0.3813
00:41:45 [train] batch 2800/7649 | loss 1.0893 | acc 0.3812
00:41:48 [train] batch 3000/7649 | loss 1.0892 | acc 0.3813
00:41:52 [train] batch 3200/7649 | loss 1.0892 | acc 0.3813
00:41:55 [train] batch 3400/7649 | loss 1.0891 | acc 0.3815
00:41:59 [train] batch 3600/7649 | loss 1.0891 | acc 0.3814
00:42:02 [train] batch 3800/7649 | loss 1.0891 | acc 0.3815
00:42:05 [train] batch 4000/7649 | loss 1.0891 | acc 0.3815
00:42:09 [train] batch 4200/7649 | loss 1.0891 | acc 0.3815
00:42:12 [train] batch 4400/7649 | loss 1.0891 | acc 0.3816
00:42:15 [train] batch 4600/7649 | loss 1.0890 | acc 0.3817
00:42:19 [train] batch 4800/7649 | loss 1.0890 | acc 0.3819
00:42:22 [train] batch 5000/7649 | loss 1.0890 | acc 0.3817
00:42:25 [train] batch 5200/7649 | loss 1.0890 | acc 0.3816
00:42:29 [train] batch 5400/7649 | loss 1.0890 | acc 0.3817
00:42:32 [train] batch 5600/7649 | loss 1.0890 | acc 0.3818
00:42:35 [train] batch 5800/7649 | loss 1.0891 | acc 0.3818
00:42:39 [train] batch 6000/7649 | loss 1.0891 | acc 0.3817
00:42:42 [train] batch 6200/7649 | loss 1.0891 | acc 0.3818
00:42:45 [train] batch 6400/7649 | loss 1.0891 | acc 0.3817
00:42:49 [train] batch 6600/7649 | loss 1.0891 | acc 0.3818
00:42:52 [train] batch 6800/7649 | loss 1.0891 | acc 0.3819
00:42:55 [train] batch 7000/7649 | loss 1.0891 | acc 0.3818
00:42:59 [train] batch 7200/7649 | loss 1.0891 | acc 0.3819
00:43:02 [train] batch 7400/7649 | loss 1.0891 | acc 0.3818
00:43:06 [train] batch 7600/7649 | loss 1.0891 | acc 0.3818
00:43:07 [train] batch 7649/7649 | loss 1.0891 | acc 0.3818
00:43:13 ✔ saved validation confusion matrix → confusion_val/run_20250523_233825/epoch_29.png
00:43:13 Epoch 29 | train 1.0891/0.3818 | val 1.0939/0.3678 | lr 1.56e-07
00:43:13 Early-stop
00:43:14 [eval ] batch 200/2185 | loss 1.0944 | acc 0.3789
00:43:15 [eval ] batch 400/2185 | loss 1.0935 | acc 0.3721
00:43:16 [eval ] batch 600/2185 | loss 1.0926 | acc 0.3708
00:43:17 [eval ] batch 800/2185 | loss 1.0943 | acc 0.3688
00:43:18 [eval ] batch 1000/2185 | loss 1.0947 | acc 0.3677
00:43:20 [eval ] batch 1200/2185 | loss 1.0946 | acc 0.3668
00:43:21 [eval ] batch 1400/2185 | loss 1.0954 | acc 0.3661
00:43:22 [eval ] batch 1600/2185 | loss 1.0956 | acc 0.3656
00:43:23 [eval ] batch 1800/2185 | loss 1.0958 | acc 0.3657
00:43:24 [eval ] batch 2000/2185 | loss 1.0959 | acc 0.3653
00:43:25 [eval ] batch 2185/2185 | loss 1.0960 | acc 0.3650
00:43:25 TEST loss/acc 1.0960/0.3650
00:43:37 Confusion matrix saved ➜ confusion_matrix.png

归一化
/data4/private/rmy/hw/confusion_val/run_20250523_233825