15:56:19 Log file: logs/train_20250525_155619.log
15:56:51 ✔ Data split: 1958081/279725/559453 rows ➜ splits
15:56:53 train.csv: samples=1957961  class_dist=[ 242173 1465142  250766]
15:56:54 val.csv: samples=279605  class_dist=[ 29458 218014  32253]
15:56:54 test.csv: samples=559333  class_dist=[ 68225 420338  70890]
15:56:55 CFG:CFG(csv='/data4/private/rmy/hw/data/BTCUSDT_feature_derived.csv', label_col='label', seed=1337, test_pct=0.2, val_pct=0.1, seq_len=120, batch=256, lr=1e-05, epochs=50, patience=7, model='transformer', hidden=256, layers=2, dropout=0.4, nhead=4, resample=True, extra_feats=None, device='cuda')
15:57:03 [train] batch 200/7649 | loss 1.0790 | acc 0.5414
15:57:09 [train] batch 400/7649 | loss 1.0693 | acc 0.5585
15:57:16 [train] batch 600/7649 | loss 1.0669 | acc 0.5572
15:57:22 [train] batch 800/7649 | loss 1.0641 | acc 0.5570
15:57:29 [train] batch 1000/7649 | loss 1.0626 | acc 0.5551
15:57:35 [train] batch 1200/7649 | loss 1.0615 | acc 0.5537
15:57:42 [train] batch 1400/7649 | loss 1.0603 | acc 0.5520
15:57:49 [train] batch 1600/7649 | loss 1.0593 | acc 0.5503
15:57:55 [train] batch 1800/7649 | loss 1.0584 | acc 0.5502
15:58:02 [train] batch 2000/7649 | loss 1.0577 | acc 0.5502
15:58:08 [train] batch 2200/7649 | loss 1.0572 | acc 0.5495
15:58:15 [train] batch 2400/7649 | loss 1.0568 | acc 0.5491
15:58:22 [train] batch 2600/7649 | loss 1.0560 | acc 0.5497
15:58:28 [train] batch 2800/7649 | loss 1.0556 | acc 0.5491
15:58:35 [train] batch 3000/7649 | loss 1.0553 | acc 0.5492
15:58:42 [train] batch 3200/7649 | loss 1.0550 | acc 0.5492
15:58:48 [train] batch 3400/7649 | loss 1.0547 | acc 0.5494
15:58:55 [train] batch 3600/7649 | loss 1.0543 | acc 0.5496
15:59:02 [train] batch 3800/7649 | loss 1.0542 | acc 0.5491
15:59:08 [train] batch 4000/7649 | loss 1.0540 | acc 0.5491
15:59:15 [train] batch 4200/7649 | loss 1.0536 | acc 0.5495
15:59:22 [train] batch 4400/7649 | loss 1.0534 | acc 0.5497
15:59:29 [train] batch 4600/7649 | loss 1.0530 | acc 0.5504
15:59:35 [train] batch 4800/7649 | loss 1.0530 | acc 0.5505
15:59:42 [train] batch 5000/7649 | loss 1.0528 | acc 0.5506
15:59:49 [train] batch 5200/7649 | loss 1.0527 | acc 0.5506
15:59:55 [train] batch 5400/7649 | loss 1.0525 | acc 0.5508
16:00:02 [train] batch 5600/7649 | loss 1.0523 | acc 0.5512
16:00:09 [train] batch 5800/7649 | loss 1.0521 | acc 0.5513
16:00:15 [train] batch 6000/7649 | loss 1.0520 | acc 0.5515
16:00:22 [train] batch 6200/7649 | loss 1.0519 | acc 0.5518
16:00:29 [train] batch 6400/7649 | loss 1.0518 | acc 0.5518
16:00:35 [train] batch 6600/7649 | loss 1.0517 | acc 0.5518
16:00:42 [train] batch 6800/7649 | loss 1.0516 | acc 0.5520
16:00:49 [train] batch 7000/7649 | loss 1.0516 | acc 0.5521
16:00:56 [train] batch 7200/7649 | loss 1.0515 | acc 0.5521
16:01:02 [train] batch 7400/7649 | loss 1.0514 | acc 0.5523
16:01:09 [train] batch 7600/7649 | loss 1.0513 | acc 0.5523
16:01:11 [train] batch 7649/7649 | loss 1.0513 | acc 0.5525
16:01:23 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_01.png
16:01:23 Epoch 01 | train 1.0513/0.5525 | val 1.0089/0.5769 | lr 1.00e-05
16:01:23 ✓ save best
16:01:30 [train] batch 200/7649 | loss 1.0504 | acc 0.5558
16:01:37 [train] batch 400/7649 | loss 1.0474 | acc 0.5639
16:01:43 [train] batch 600/7649 | loss 1.0479 | acc 0.5639
16:01:50 [train] batch 800/7649 | loss 1.0480 | acc 0.5653
16:01:57 [train] batch 1000/7649 | loss 1.0484 | acc 0.5640
16:02:03 [train] batch 1200/7649 | loss 1.0483 | acc 0.5625
16:02:10 [train] batch 1400/7649 | loss 1.0483 | acc 0.5624
16:02:17 [train] batch 1600/7649 | loss 1.0484 | acc 0.5612
16:02:23 [train] batch 1800/7649 | loss 1.0485 | acc 0.5605
16:02:30 [train] batch 2000/7649 | loss 1.0485 | acc 0.5600
16:02:37 [train] batch 2200/7649 | loss 1.0482 | acc 0.5603
16:02:43 [train] batch 2400/7649 | loss 1.0481 | acc 0.5598
16:02:50 [train] batch 2600/7649 | loss 1.0481 | acc 0.5599
16:02:57 [train] batch 2800/7649 | loss 1.0481 | acc 0.5601
16:03:04 [train] batch 3000/7649 | loss 1.0481 | acc 0.5604
16:03:10 [train] batch 3200/7649 | loss 1.0480 | acc 0.5605
16:03:17 [train] batch 3400/7649 | loss 1.0480 | acc 0.5604
16:03:24 [train] batch 3600/7649 | loss 1.0479 | acc 0.5607
16:03:30 [train] batch 3800/7649 | loss 1.0478 | acc 0.5607
16:03:37 [train] batch 4000/7649 | loss 1.0478 | acc 0.5604
16:03:44 [train] batch 4200/7649 | loss 1.0477 | acc 0.5607
16:03:50 [train] batch 4400/7649 | loss 1.0477 | acc 0.5605
16:03:57 [train] batch 4600/7649 | loss 1.0477 | acc 0.5603
16:04:04 [train] batch 4800/7649 | loss 1.0478 | acc 0.5607
16:04:10 [train] batch 5000/7649 | loss 1.0477 | acc 0.5607
16:04:17 [train] batch 5200/7649 | loss 1.0476 | acc 0.5608
16:04:24 [train] batch 5400/7649 | loss 1.0476 | acc 0.5610
16:04:30 [train] batch 5600/7649 | loss 1.0475 | acc 0.5612
16:04:37 [train] batch 5800/7649 | loss 1.0475 | acc 0.5613
16:04:44 [train] batch 6000/7649 | loss 1.0474 | acc 0.5614
16:04:51 [train] batch 6200/7649 | loss 1.0474 | acc 0.5616
16:04:57 [train] batch 6400/7649 | loss 1.0473 | acc 0.5615
16:05:04 [train] batch 6600/7649 | loss 1.0472 | acc 0.5615
16:05:11 [train] batch 6800/7649 | loss 1.0470 | acc 0.5614
16:05:17 [train] batch 7000/7649 | loss 1.0469 | acc 0.5613
16:05:24 [train] batch 7200/7649 | loss 1.0469 | acc 0.5613
16:05:31 [train] batch 7400/7649 | loss 1.0469 | acc 0.5615
16:05:37 [train] batch 7600/7649 | loss 1.0469 | acc 0.5614
16:05:39 [train] batch 7649/7649 | loss 1.0470 | acc 0.5613
16:05:51 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_02.png
16:05:51 Epoch 02 | train 1.0470/0.5613 | val 1.0130/0.5652 | lr 1.00e-05
16:05:58 [train] batch 200/7649 | loss 1.0459 | acc 0.5601
16:06:05 [train] batch 400/7649 | loss 1.0474 | acc 0.5605
16:06:12 [train] batch 600/7649 | loss 1.0469 | acc 0.5616
16:06:18 [train] batch 800/7649 | loss 1.0465 | acc 0.5639
16:06:25 [train] batch 1000/7649 | loss 1.0460 | acc 0.5635
16:06:32 [train] batch 1200/7649 | loss 1.0460 | acc 0.5646
16:06:38 [train] batch 1400/7649 | loss 1.0461 | acc 0.5647
16:06:45 [train] batch 1600/7649 | loss 1.0461 | acc 0.5651
16:06:52 [train] batch 1800/7649 | loss 1.0463 | acc 0.5658
16:06:58 [train] batch 2000/7649 | loss 1.0462 | acc 0.5652
16:07:05 [train] batch 2200/7649 | loss 1.0464 | acc 0.5646
16:07:12 [train] batch 2400/7649 | loss 1.0465 | acc 0.5652
16:07:19 [train] batch 2600/7649 | loss 1.0467 | acc 0.5652
16:07:25 [train] batch 2800/7649 | loss 1.0465 | acc 0.5650
16:07:32 [train] batch 3000/7649 | loss 1.0466 | acc 0.5645
16:07:39 [train] batch 3200/7649 | loss 1.0467 | acc 0.5640
16:07:45 [train] batch 3400/7649 | loss 1.0467 | acc 0.5634
16:07:52 [train] batch 3600/7649 | loss 1.0469 | acc 0.5627
16:07:59 [train] batch 3800/7649 | loss 1.0467 | acc 0.5632
16:08:05 [train] batch 4000/7649 | loss 1.0466 | acc 0.5635
16:08:12 [train] batch 4200/7649 | loss 1.0466 | acc 0.5638
16:08:19 [train] batch 4400/7649 | loss 1.0464 | acc 0.5639
16:08:25 [train] batch 4600/7649 | loss 1.0464 | acc 0.5640
16:08:32 [train] batch 4800/7649 | loss 1.0464 | acc 0.5640
16:08:39 [train] batch 5000/7649 | loss 1.0464 | acc 0.5639
16:08:45 [train] batch 5200/7649 | loss 1.0464 | acc 0.5637
16:08:52 [train] batch 5400/7649 | loss 1.0464 | acc 0.5639
16:08:59 [train] batch 5600/7649 | loss 1.0465 | acc 0.5639
16:09:05 [train] batch 5800/7649 | loss 1.0465 | acc 0.5643
16:09:12 [train] batch 6000/7649 | loss 1.0464 | acc 0.5644
16:09:19 [train] batch 6200/7649 | loss 1.0464 | acc 0.5643
16:09:25 [train] batch 6400/7649 | loss 1.0464 | acc 0.5643
16:09:32 [train] batch 6600/7649 | loss 1.0464 | acc 0.5641
16:09:39 [train] batch 6800/7649 | loss 1.0463 | acc 0.5640
16:09:46 [train] batch 7000/7649 | loss 1.0463 | acc 0.5642
16:09:52 [train] batch 7200/7649 | loss 1.0462 | acc 0.5643
16:09:59 [train] batch 7400/7649 | loss 1.0462 | acc 0.5643
16:10:06 [train] batch 7600/7649 | loss 1.0462 | acc 0.5643
16:10:07 [train] batch 7649/7649 | loss 1.0462 | acc 0.5643
16:10:20 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_03.png
16:10:20 Epoch 03 | train 1.0462/0.5643 | val 1.0131/0.5770 | lr 1.00e-05
16:10:20 ✓ save best
16:10:27 [train] batch 200/7649 | loss 1.0454 | acc 0.5733
16:10:33 [train] batch 400/7649 | loss 1.0448 | acc 0.5702
16:10:40 [train] batch 600/7649 | loss 1.0451 | acc 0.5726
16:10:47 [train] batch 800/7649 | loss 1.0455 | acc 0.5715
16:10:53 [train] batch 1000/7649 | loss 1.0460 | acc 0.5715
16:11:00 [train] batch 1200/7649 | loss 1.0460 | acc 0.5707
16:11:07 [train] batch 1400/7649 | loss 1.0461 | acc 0.5697
16:11:13 [train] batch 1600/7649 | loss 1.0460 | acc 0.5690
16:11:20 [train] batch 1800/7649 | loss 1.0458 | acc 0.5685
16:11:27 [train] batch 2000/7649 | loss 1.0458 | acc 0.5685
16:11:33 [train] batch 2200/7649 | loss 1.0460 | acc 0.5678
16:11:40 [train] batch 2400/7649 | loss 1.0459 | acc 0.5683
16:11:47 [train] batch 2600/7649 | loss 1.0459 | acc 0.5674
16:11:53 [train] batch 2800/7649 | loss 1.0459 | acc 0.5671
16:12:00 [train] batch 3000/7649 | loss 1.0459 | acc 0.5670
16:12:07 [train] batch 3200/7649 | loss 1.0460 | acc 0.5672
16:12:13 [train] batch 3400/7649 | loss 1.0459 | acc 0.5670
16:12:20 [train] batch 3600/7649 | loss 1.0457 | acc 0.5672
16:12:27 [train] batch 3800/7649 | loss 1.0458 | acc 0.5668
16:12:34 [train] batch 4000/7649 | loss 1.0458 | acc 0.5667
16:12:40 [train] batch 4200/7649 | loss 1.0457 | acc 0.5666
16:12:47 [train] batch 4400/7649 | loss 1.0458 | acc 0.5659
16:12:54 [train] batch 4600/7649 | loss 1.0457 | acc 0.5657
16:13:00 [train] batch 4800/7649 | loss 1.0457 | acc 0.5654
16:13:07 [train] batch 5000/7649 | loss 1.0457 | acc 0.5651
16:13:14 [train] batch 5200/7649 | loss 1.0457 | acc 0.5649
16:13:20 [train] batch 5400/7649 | loss 1.0457 | acc 0.5648
16:13:27 [train] batch 5600/7649 | loss 1.0457 | acc 0.5648
16:13:34 [train] batch 5800/7649 | loss 1.0457 | acc 0.5651
16:13:40 [train] batch 6000/7649 | loss 1.0457 | acc 0.5651
16:13:47 [train] batch 6200/7649 | loss 1.0457 | acc 0.5653
16:13:54 [train] batch 6400/7649 | loss 1.0456 | acc 0.5652
16:14:00 [train] batch 6600/7649 | loss 1.0457 | acc 0.5651
16:14:07 [train] batch 6800/7649 | loss 1.0458 | acc 0.5652
16:14:14 [train] batch 7000/7649 | loss 1.0458 | acc 0.5652
16:14:20 [train] batch 7200/7649 | loss 1.0458 | acc 0.5650
16:14:27 [train] batch 7400/7649 | loss 1.0458 | acc 0.5651
16:14:34 [train] batch 7600/7649 | loss 1.0457 | acc 0.5653
16:14:36 [train] batch 7649/7649 | loss 1.0457 | acc 0.5652
16:14:48 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_04.png
16:14:48 Epoch 04 | train 1.0457/0.5652 | val 1.0176/0.5473 | lr 1.00e-05
16:14:55 [train] batch 200/7649 | loss 1.0463 | acc 0.5606
16:15:02 [train] batch 400/7649 | loss 1.0471 | acc 0.5622
16:15:08 [train] batch 600/7649 | loss 1.0465 | acc 0.5646
16:15:15 [train] batch 800/7649 | loss 1.0471 | acc 0.5638
16:15:22 [train] batch 1000/7649 | loss 1.0470 | acc 0.5639
16:15:28 [train] batch 1200/7649 | loss 1.0463 | acc 0.5646
16:15:35 [train] batch 1400/7649 | loss 1.0462 | acc 0.5654
16:15:42 [train] batch 1600/7649 | loss 1.0462 | acc 0.5651
16:15:48 [train] batch 1800/7649 | loss 1.0460 | acc 0.5652
16:15:55 [train] batch 2000/7649 | loss 1.0460 | acc 0.5651
16:16:02 [train] batch 2200/7649 | loss 1.0461 | acc 0.5640
16:16:08 [train] batch 2400/7649 | loss 1.0461 | acc 0.5640
16:16:15 [train] batch 2600/7649 | loss 1.0461 | acc 0.5647
16:16:22 [train] batch 2800/7649 | loss 1.0459 | acc 0.5656
16:16:28 [train] batch 3000/7649 | loss 1.0459 | acc 0.5656
16:16:35 [train] batch 3200/7649 | loss 1.0459 | acc 0.5661
16:16:42 [train] batch 3400/7649 | loss 1.0460 | acc 0.5659
16:16:48 [train] batch 3600/7649 | loss 1.0459 | acc 0.5659
16:16:55 [train] batch 3800/7649 | loss 1.0457 | acc 0.5659
16:17:02 [train] batch 4000/7649 | loss 1.0456 | acc 0.5658
16:17:09 [train] batch 4200/7649 | loss 1.0456 | acc 0.5660
16:17:15 [train] batch 4400/7649 | loss 1.0457 | acc 0.5657
16:17:22 [train] batch 4600/7649 | loss 1.0457 | acc 0.5656
16:17:29 [train] batch 4800/7649 | loss 1.0457 | acc 0.5652
16:17:35 [train] batch 5000/7649 | loss 1.0456 | acc 0.5653
16:17:42 [train] batch 5200/7649 | loss 1.0458 | acc 0.5653
16:17:49 [train] batch 5400/7649 | loss 1.0457 | acc 0.5655
16:17:55 [train] batch 5600/7649 | loss 1.0457 | acc 0.5655
16:18:02 [train] batch 5800/7649 | loss 1.0457 | acc 0.5654
16:18:09 [train] batch 6000/7649 | loss 1.0457 | acc 0.5654
16:18:15 [train] batch 6200/7649 | loss 1.0456 | acc 0.5658
16:18:22 [train] batch 6400/7649 | loss 1.0455 | acc 0.5659
16:18:29 [train] batch 6600/7649 | loss 1.0455 | acc 0.5662
16:18:35 [train] batch 6800/7649 | loss 1.0455 | acc 0.5660
16:18:42 [train] batch 7000/7649 | loss 1.0455 | acc 0.5659
16:18:49 [train] batch 7200/7649 | loss 1.0455 | acc 0.5658
16:18:55 [train] batch 7400/7649 | loss 1.0455 | acc 0.5656
16:19:02 [train] batch 7600/7649 | loss 1.0454 | acc 0.5656
16:19:04 [train] batch 7649/7649 | loss 1.0454 | acc 0.5655
16:19:16 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_05.png
16:19:16 Epoch 05 | train 1.0454/0.5655 | val 1.0113/0.5662 | lr 5.00e-06
16:19:23 [train] batch 200/7649 | loss 1.0458 | acc 0.5677
16:19:30 [train] batch 400/7649 | loss 1.0453 | acc 0.5679
16:19:37 [train] batch 600/7649 | loss 1.0451 | acc 0.5674
16:19:43 [train] batch 800/7649 | loss 1.0447 | acc 0.5680
16:19:50 [train] batch 1000/7649 | loss 1.0450 | acc 0.5680
16:19:57 [train] batch 1200/7649 | loss 1.0453 | acc 0.5670
16:20:03 [train] batch 1400/7649 | loss 1.0450 | acc 0.5677
16:20:10 [train] batch 1600/7649 | loss 1.0453 | acc 0.5667
16:20:17 [train] batch 1800/7649 | loss 1.0454 | acc 0.5668
16:20:23 [train] batch 2000/7649 | loss 1.0455 | acc 0.5666
16:20:30 [train] batch 2200/7649 | loss 1.0456 | acc 0.5664
16:20:37 [train] batch 2400/7649 | loss 1.0455 | acc 0.5666
16:20:44 [train] batch 2600/7649 | loss 1.0456 | acc 0.5664
16:20:50 [train] batch 2800/7649 | loss 1.0456 | acc 0.5658
16:20:57 [train] batch 3000/7649 | loss 1.0456 | acc 0.5658
16:21:04 [train] batch 3200/7649 | loss 1.0456 | acc 0.5658
16:21:10 [train] batch 3400/7649 | loss 1.0455 | acc 0.5662
16:21:17 [train] batch 3600/7649 | loss 1.0455 | acc 0.5663
16:21:24 [train] batch 3800/7649 | loss 1.0454 | acc 0.5661
16:21:30 [train] batch 4000/7649 | loss 1.0454 | acc 0.5660
16:21:37 [train] batch 4200/7649 | loss 1.0453 | acc 0.5659
16:21:44 [train] batch 4400/7649 | loss 1.0453 | acc 0.5653
16:21:50 [train] batch 4600/7649 | loss 1.0453 | acc 0.5654
16:21:57 [train] batch 4800/7649 | loss 1.0454 | acc 0.5653
16:22:04 [train] batch 5000/7649 | loss 1.0454 | acc 0.5652
16:22:10 [train] batch 5200/7649 | loss 1.0454 | acc 0.5653
16:22:17 [train] batch 5400/7649 | loss 1.0454 | acc 0.5654
16:22:24 [train] batch 5600/7649 | loss 1.0453 | acc 0.5654
16:22:31 [train] batch 5800/7649 | loss 1.0453 | acc 0.5657
16:22:37 [train] batch 6000/7649 | loss 1.0452 | acc 0.5658
16:22:44 [train] batch 6200/7649 | loss 1.0453 | acc 0.5655
16:22:51 [train] batch 6400/7649 | loss 1.0452 | acc 0.5657
16:22:57 [train] batch 6600/7649 | loss 1.0452 | acc 0.5659
16:23:04 [train] batch 6800/7649 | loss 1.0451 | acc 0.5663
16:23:11 [train] batch 7000/7649 | loss 1.0451 | acc 0.5663
16:23:17 [train] batch 7200/7649 | loss 1.0451 | acc 0.5665
16:23:24 [train] batch 7400/7649 | loss 1.0451 | acc 0.5664
16:23:31 [train] batch 7600/7649 | loss 1.0451 | acc 0.5664
16:23:32 [train] batch 7649/7649 | loss 1.0451 | acc 0.5663
16:23:45 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_06.png
16:23:45 Epoch 06 | train 1.0451/0.5663 | val 1.0146/0.5460 | lr 5.00e-06
16:23:52 [train] batch 200/7649 | loss 1.0440 | acc 0.5693
16:23:58 [train] batch 400/7649 | loss 1.0439 | acc 0.5687
16:24:05 [train] batch 600/7649 | loss 1.0440 | acc 0.5655
16:24:12 [train] batch 800/7649 | loss 1.0438 | acc 0.5655
16:24:18 [train] batch 1000/7649 | loss 1.0438 | acc 0.5659
16:24:25 [train] batch 1200/7649 | loss 1.0441 | acc 0.5661
16:24:32 [train] batch 1400/7649 | loss 1.0441 | acc 0.5671
16:24:39 [train] batch 1600/7649 | loss 1.0445 | acc 0.5672
16:24:45 [train] batch 1800/7649 | loss 1.0446 | acc 0.5679
16:24:52 [train] batch 2000/7649 | loss 1.0444 | acc 0.5680
16:24:59 [train] batch 2200/7649 | loss 1.0446 | acc 0.5673
16:25:05 [train] batch 2400/7649 | loss 1.0447 | acc 0.5672
16:25:12 [train] batch 2600/7649 | loss 1.0446 | acc 0.5670
16:25:19 [train] batch 2800/7649 | loss 1.0445 | acc 0.5668
16:25:25 [train] batch 3000/7649 | loss 1.0446 | acc 0.5668
16:25:32 [train] batch 3200/7649 | loss 1.0446 | acc 0.5667
16:25:39 [train] batch 3400/7649 | loss 1.0446 | acc 0.5663
16:25:45 [train] batch 3600/7649 | loss 1.0446 | acc 0.5658
16:25:52 [train] batch 3800/7649 | loss 1.0446 | acc 0.5657
16:25:59 [train] batch 4000/7649 | loss 1.0447 | acc 0.5658
16:26:05 [train] batch 4200/7649 | loss 1.0446 | acc 0.5663
16:26:12 [train] batch 4400/7649 | loss 1.0447 | acc 0.5663
16:26:19 [train] batch 4600/7649 | loss 1.0447 | acc 0.5666
16:26:26 [train] batch 4800/7649 | loss 1.0447 | acc 0.5664
16:26:32 [train] batch 5000/7649 | loss 1.0448 | acc 0.5663
16:26:39 [train] batch 5200/7649 | loss 1.0448 | acc 0.5661
16:26:46 [train] batch 5400/7649 | loss 1.0448 | acc 0.5661
16:26:52 [train] batch 5600/7649 | loss 1.0449 | acc 0.5659
16:26:59 [train] batch 5800/7649 | loss 1.0448 | acc 0.5661
16:27:06 [train] batch 6000/7649 | loss 1.0448 | acc 0.5661
16:27:12 [train] batch 6200/7649 | loss 1.0448 | acc 0.5660
16:27:19 [train] batch 6400/7649 | loss 1.0448 | acc 0.5661
16:27:26 [train] batch 6600/7649 | loss 1.0448 | acc 0.5660
16:27:32 [train] batch 6800/7649 | loss 1.0448 | acc 0.5659
16:27:39 [train] batch 7000/7649 | loss 1.0449 | acc 0.5656
16:27:46 [train] batch 7200/7649 | loss 1.0449 | acc 0.5655
16:27:53 [train] batch 7400/7649 | loss 1.0449 | acc 0.5655
16:27:59 [train] batch 7600/7649 | loss 1.0449 | acc 0.5656
16:28:01 [train] batch 7649/7649 | loss 1.0449 | acc 0.5657
16:28:14 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_07.png
16:28:14 Epoch 07 | train 1.0449/0.5657 | val 1.0129/0.5629 | lr 5.00e-06
16:28:20 [train] batch 200/7649 | loss 1.0462 | acc 0.5652
16:28:27 [train] batch 400/7649 | loss 1.0458 | acc 0.5675
16:28:34 [train] batch 600/7649 | loss 1.0453 | acc 0.5672
16:28:41 [train] batch 800/7649 | loss 1.0450 | acc 0.5677
16:28:47 [train] batch 1000/7649 | loss 1.0452 | acc 0.5669
16:28:54 [train] batch 1200/7649 | loss 1.0457 | acc 0.5668
16:29:01 [train] batch 1400/7649 | loss 1.0459 | acc 0.5659
16:29:07 [train] batch 1600/7649 | loss 1.0459 | acc 0.5661
16:29:14 [train] batch 1800/7649 | loss 1.0460 | acc 0.5654
16:29:21 [train] batch 2000/7649 | loss 1.0460 | acc 0.5650
16:29:28 [train] batch 2200/7649 | loss 1.0458 | acc 0.5657
16:29:34 [train] batch 2400/7649 | loss 1.0456 | acc 0.5661
16:29:41 [train] batch 2600/7649 | loss 1.0457 | acc 0.5664
16:29:48 [train] batch 2800/7649 | loss 1.0456 | acc 0.5667
16:29:54 [train] batch 3000/7649 | loss 1.0456 | acc 0.5670
16:30:01 [train] batch 3200/7649 | loss 1.0455 | acc 0.5670
16:30:08 [train] batch 3400/7649 | loss 1.0455 | acc 0.5666
16:30:14 [train] batch 3600/7649 | loss 1.0455 | acc 0.5665
16:30:21 [train] batch 3800/7649 | loss 1.0454 | acc 0.5667
16:30:28 [train] batch 4000/7649 | loss 1.0453 | acc 0.5666
16:30:34 [train] batch 4200/7649 | loss 1.0453 | acc 0.5667
16:30:41 [train] batch 4400/7649 | loss 1.0453 | acc 0.5668
16:30:48 [train] batch 4600/7649 | loss 1.0452 | acc 0.5667
16:30:54 [train] batch 4800/7649 | loss 1.0452 | acc 0.5668
16:31:01 [train] batch 5000/7649 | loss 1.0450 | acc 0.5669
16:31:08 [train] batch 5200/7649 | loss 1.0449 | acc 0.5669
16:31:15 [train] batch 5400/7649 | loss 1.0450 | acc 0.5669
16:31:21 [train] batch 5600/7649 | loss 1.0450 | acc 0.5672
16:31:28 [train] batch 5800/7649 | loss 1.0450 | acc 0.5674
16:31:35 [train] batch 6000/7649 | loss 1.0449 | acc 0.5677
16:31:41 [train] batch 6200/7649 | loss 1.0449 | acc 0.5677
16:31:48 [train] batch 6400/7649 | loss 1.0449 | acc 0.5676
16:31:55 [train] batch 6600/7649 | loss 1.0449 | acc 0.5675
16:32:01 [train] batch 6800/7649 | loss 1.0449 | acc 0.5672
16:32:08 [train] batch 7000/7649 | loss 1.0448 | acc 0.5671
16:32:15 [train] batch 7200/7649 | loss 1.0448 | acc 0.5667
16:32:21 [train] batch 7400/7649 | loss 1.0448 | acc 0.5665
16:32:28 [train] batch 7600/7649 | loss 1.0448 | acc 0.5663
16:32:30 [train] batch 7649/7649 | loss 1.0448 | acc 0.5663
16:32:43 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_08.png
16:32:43 Epoch 08 | train 1.0448/0.5663 | val 1.0171/0.5372 | lr 5.00e-06
16:32:49 [train] batch 200/7649 | loss 1.0430 | acc 0.5704
16:32:56 [train] batch 400/7649 | loss 1.0439 | acc 0.5703
16:33:03 [train] batch 600/7649 | loss 1.0440 | acc 0.5687
16:33:10 [train] batch 800/7649 | loss 1.0442 | acc 0.5676
16:33:16 [train] batch 1000/7649 | loss 1.0443 | acc 0.5671
16:33:23 [train] batch 1200/7649 | loss 1.0437 | acc 0.5692
16:33:30 [train] batch 1400/7649 | loss 1.0440 | acc 0.5678
16:33:36 [train] batch 1600/7649 | loss 1.0442 | acc 0.5681
16:33:43 [train] batch 1800/7649 | loss 1.0443 | acc 0.5674
16:33:50 [train] batch 2000/7649 | loss 1.0444 | acc 0.5672
16:33:56 [train] batch 2200/7649 | loss 1.0442 | acc 0.5678
16:34:03 [train] batch 2400/7649 | loss 1.0442 | acc 0.5682
16:34:10 [train] batch 2600/7649 | loss 1.0442 | acc 0.5682
16:34:17 [train] batch 2800/7649 | loss 1.0444 | acc 0.5680
16:34:23 [train] batch 3000/7649 | loss 1.0441 | acc 0.5685
16:34:30 [train] batch 3200/7649 | loss 1.0440 | acc 0.5681
16:34:37 [train] batch 3400/7649 | loss 1.0441 | acc 0.5678
16:34:43 [train] batch 3600/7649 | loss 1.0441 | acc 0.5678
16:34:50 [train] batch 3800/7649 | loss 1.0441 | acc 0.5673
16:34:57 [train] batch 4000/7649 | loss 1.0442 | acc 0.5674
16:35:03 [train] batch 4200/7649 | loss 1.0444 | acc 0.5672
16:35:10 [train] batch 4400/7649 | loss 1.0444 | acc 0.5672
16:35:17 [train] batch 4600/7649 | loss 1.0444 | acc 0.5672
16:35:24 [train] batch 4800/7649 | loss 1.0445 | acc 0.5670
16:35:30 [train] batch 5000/7649 | loss 1.0444 | acc 0.5666
16:35:37 [train] batch 5200/7649 | loss 1.0444 | acc 0.5663
16:35:44 [train] batch 5400/7649 | loss 1.0444 | acc 0.5664
16:35:50 [train] batch 5600/7649 | loss 1.0444 | acc 0.5662
16:35:57 [train] batch 5800/7649 | loss 1.0444 | acc 0.5664
16:36:04 [train] batch 6000/7649 | loss 1.0444 | acc 0.5665
16:36:10 [train] batch 6200/7649 | loss 1.0444 | acc 0.5665
16:36:17 [train] batch 6400/7649 | loss 1.0443 | acc 0.5665
16:36:24 [train] batch 6600/7649 | loss 1.0444 | acc 0.5666
16:36:30 [train] batch 6800/7649 | loss 1.0444 | acc 0.5663
16:36:37 [train] batch 7000/7649 | loss 1.0444 | acc 0.5662
16:36:44 [train] batch 7200/7649 | loss 1.0445 | acc 0.5661
16:36:51 [train] batch 7400/7649 | loss 1.0445 | acc 0.5662
16:36:57 [train] batch 7600/7649 | loss 1.0445 | acc 0.5662
16:36:59 [train] batch 7649/7649 | loss 1.0445 | acc 0.5662
16:37:12 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_09.png
16:37:12 Epoch 09 | train 1.0445/0.5662 | val 1.0156/0.5435 | lr 2.50e-06
16:37:19 [train] batch 200/7649 | loss 1.0462 | acc 0.5728
16:37:25 [train] batch 400/7649 | loss 1.0462 | acc 0.5684
16:37:32 [train] batch 600/7649 | loss 1.0451 | acc 0.5706
16:37:39 [train] batch 800/7649 | loss 1.0449 | acc 0.5699
16:37:45 [train] batch 1000/7649 | loss 1.0454 | acc 0.5695
16:37:52 [train] batch 1200/7649 | loss 1.0452 | acc 0.5685
16:37:59 [train] batch 1400/7649 | loss 1.0452 | acc 0.5690
16:38:06 [train] batch 1600/7649 | loss 1.0450 | acc 0.5691
16:38:12 [train] batch 1800/7649 | loss 1.0450 | acc 0.5693
16:38:19 [train] batch 2000/7649 | loss 1.0446 | acc 0.5692
16:38:26 [train] batch 2200/7649 | loss 1.0446 | acc 0.5699
16:38:32 [train] batch 2400/7649 | loss 1.0447 | acc 0.5690
16:38:39 [train] batch 2600/7649 | loss 1.0446 | acc 0.5689
16:38:46 [train] batch 2800/7649 | loss 1.0447 | acc 0.5686
16:38:52 [train] batch 3000/7649 | loss 1.0448 | acc 0.5687
16:38:59 [train] batch 3200/7649 | loss 1.0447 | acc 0.5689
16:39:06 [train] batch 3400/7649 | loss 1.0447 | acc 0.5690
16:39:13 [train] batch 3600/7649 | loss 1.0445 | acc 0.5690
16:39:19 [train] batch 3800/7649 | loss 1.0445 | acc 0.5688
16:39:26 [train] batch 4000/7649 | loss 1.0445 | acc 0.5685
16:39:33 [train] batch 4200/7649 | loss 1.0445 | acc 0.5681
16:39:39 [train] batch 4400/7649 | loss 1.0445 | acc 0.5680
16:39:46 [train] batch 4600/7649 | loss 1.0446 | acc 0.5681
16:39:53 [train] batch 4800/7649 | loss 1.0445 | acc 0.5678
16:39:59 [train] batch 5000/7649 | loss 1.0446 | acc 0.5675
16:40:06 [train] batch 5200/7649 | loss 1.0446 | acc 0.5670
16:40:13 [train] batch 5400/7649 | loss 1.0445 | acc 0.5669
16:40:20 [train] batch 5600/7649 | loss 1.0446 | acc 0.5667
16:40:26 [train] batch 5800/7649 | loss 1.0446 | acc 0.5668
16:40:33 [train] batch 6000/7649 | loss 1.0445 | acc 0.5669
16:40:40 [train] batch 6200/7649 | loss 1.0445 | acc 0.5668
16:40:46 [train] batch 6400/7649 | loss 1.0445 | acc 0.5668
16:40:53 [train] batch 6600/7649 | loss 1.0444 | acc 0.5669
16:41:00 [train] batch 6800/7649 | loss 1.0445 | acc 0.5667
16:41:06 [train] batch 7000/7649 | loss 1.0444 | acc 0.5667
16:41:13 [train] batch 7200/7649 | loss 1.0444 | acc 0.5666
16:41:20 [train] batch 7400/7649 | loss 1.0443 | acc 0.5668
16:41:27 [train] batch 7600/7649 | loss 1.0443 | acc 0.5668
16:41:28 [train] batch 7649/7649 | loss 1.0443 | acc 0.5667
16:41:41 ✔ saved validation confusion matrix → confusion_val/run_20250525_155656/epoch_10.png
16:41:41 Epoch 10 | train 1.0443/0.5667 | val 1.0190/0.5266 | lr 2.50e-06
16:41:41 Early-stop
16:41:44 [eval ] batch 200/2185 | loss 1.0823 | acc 0.4403
16:41:46 [eval ] batch 400/2185 | loss 1.0329 | acc 0.5640
16:41:48 [eval ] batch 600/2185 | loss 1.0275 | acc 0.5719
16:41:50 [eval ] batch 800/2185 | loss 1.0376 | acc 0.5507
16:41:52 [eval ] batch 1000/2185 | loss 1.0380 | acc 0.5611
16:41:54 [eval ] batch 1200/2185 | loss 1.0315 | acc 0.5811
16:41:57 [eval ] batch 1400/2185 | loss 1.0364 | acc 0.5660
16:41:59 [eval ] batch 1600/2185 | loss 1.0381 | acc 0.5638
16:42:01 [eval ] batch 1800/2185 | loss 1.0391 | acc 0.5587
16:42:03 [eval ] batch 2000/2185 | loss 1.0376 | acc 0.5535
16:42:05 [eval ] batch 2185/2185 | loss 1.0380 | acc 0.5557
16:42:05 TEST loss/acc 1.0380/0.5557
16:42:29 Confusion matrix saved ➜ confusion_matrix.png

0.8:1
/data4/private/rmy/hw/confusion_val/run_20250525_155656