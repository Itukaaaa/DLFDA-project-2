09:20:43 Log file: logs/train_20250524_092043.log
09:21:15 ✔ Data split: 1958081/279725/559453 rows ➜ splits
09:21:17 train.csv: samples=1957961  class_dist=[609313 731512 617256]
09:21:18 val.csv: samples=279605  class_dist=[90467 94550 94708]
09:21:18 test.csv: samples=559333  class_dist=[183495 190446 185512]
09:21:24 [train] batch 200/7649 | loss 1.0290 | acc 0.3254
09:21:27 [train] batch 400/7649 | loss 1.0036 | acc 0.3203
09:21:30 [train] batch 600/7649 | loss 0.9952 | acc 0.3181
09:21:34 [train] batch 800/7649 | loss 0.9895 | acc 0.3183
09:21:37 [train] batch 1000/7649 | loss 0.9856 | acc 0.3183
09:21:40 [train] batch 1200/7649 | loss 0.9831 | acc 0.3185
09:21:44 [train] batch 1400/7649 | loss 0.9812 | acc 0.3188
09:21:47 [train] batch 1600/7649 | loss 0.9797 | acc 0.3188
09:21:50 [train] batch 1800/7649 | loss 0.9783 | acc 0.3192
09:21:53 [train] batch 2000/7649 | loss 0.9774 | acc 0.3191
09:21:57 [train] batch 2200/7649 | loss 0.9767 | acc 0.3189
09:22:00 [train] batch 2400/7649 | loss 0.9760 | acc 0.3188
09:22:03 [train] batch 2600/7649 | loss 0.9754 | acc 0.3188
09:22:07 [train] batch 2800/7649 | loss 0.9749 | acc 0.3189
09:22:10 [train] batch 3000/7649 | loss 0.9742 | acc 0.3191
09:22:14 [train] batch 3200/7649 | loss 0.9736 | acc 0.3194
09:22:17 [train] batch 3400/7649 | loss 0.9731 | acc 0.3196
09:22:20 [train] batch 3600/7649 | loss 0.9727 | acc 0.3198
09:22:24 [train] batch 3800/7649 | loss 0.9723 | acc 0.3199
09:22:27 [train] batch 4000/7649 | loss 0.9721 | acc 0.3198
09:22:31 [train] batch 4200/7649 | loss 0.9718 | acc 0.3198
09:22:34 [train] batch 4400/7649 | loss 0.9716 | acc 0.3199
09:22:37 [train] batch 4600/7649 | loss 0.9714 | acc 0.3201
09:22:41 [train] batch 4800/7649 | loss 0.9711 | acc 0.3201
09:22:44 [train] batch 5000/7649 | loss 0.9708 | acc 0.3203
09:22:47 [train] batch 5200/7649 | loss 0.9705 | acc 0.3203
09:22:51 [train] batch 5400/7649 | loss 0.9703 | acc 0.3205
09:22:54 [train] batch 5600/7649 | loss 0.9702 | acc 0.3205
09:22:58 [train] batch 5800/7649 | loss 0.9700 | acc 0.3206
09:23:01 [train] batch 6000/7649 | loss 0.9698 | acc 0.3207
09:23:04 [train] batch 6200/7649 | loss 0.9697 | acc 0.3208
09:23:08 [train] batch 6400/7649 | loss 0.9695 | acc 0.3209
09:23:11 [train] batch 6600/7649 | loss 0.9692 | acc 0.3211
09:23:15 [train] batch 6800/7649 | loss 0.9691 | acc 0.3211
09:23:18 [train] batch 7000/7649 | loss 0.9689 | acc 0.3212
09:23:21 [train] batch 7200/7649 | loss 0.9688 | acc 0.3211
09:23:25 [train] batch 7400/7649 | loss 0.9687 | acc 0.3212
09:23:28 [train] batch 7600/7649 | loss 0.9685 | acc 0.3214
09:23:29 [train] batch 7649/7649 | loss 0.9685 | acc 0.3214
09:23:36 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_01.png
09:23:36 Epoch 01 | train 0.9685/0.3214 | val 0.9436/0.3427 | lr 1.00e-05
09:23:36 ✓ save best
09:23:40 [train] batch 200/7649 | loss 0.9642 | acc 0.3228
09:23:43 [train] batch 400/7649 | loss 0.9638 | acc 0.3246
09:23:46 [train] batch 600/7649 | loss 0.9636 | acc 0.3251
09:23:50 [train] batch 800/7649 | loss 0.9632 | acc 0.3256
09:23:53 [train] batch 1000/7649 | loss 0.9631 | acc 0.3255
09:23:56 [train] batch 1200/7649 | loss 0.9632 | acc 0.3256
09:24:00 [train] batch 1400/7649 | loss 0.9633 | acc 0.3251
09:24:03 [train] batch 1600/7649 | loss 0.9633 | acc 0.3253
09:24:07 [train] batch 1800/7649 | loss 0.9637 | acc 0.3249
09:24:10 [train] batch 2000/7649 | loss 0.9637 | acc 0.3247
09:24:13 [train] batch 2200/7649 | loss 0.9637 | acc 0.3248
09:24:17 [train] batch 2400/7649 | loss 0.9637 | acc 0.3249
09:24:20 [train] batch 2600/7649 | loss 0.9637 | acc 0.3251
09:24:23 [train] batch 2800/7649 | loss 0.9636 | acc 0.3252
09:24:27 [train] batch 3000/7649 | loss 0.9636 | acc 0.3252
09:24:30 [train] batch 3200/7649 | loss 0.9636 | acc 0.3251
09:24:33 [train] batch 3400/7649 | loss 0.9635 | acc 0.3252
09:24:37 [train] batch 3600/7649 | loss 0.9636 | acc 0.3254
09:24:40 [train] batch 3800/7649 | loss 0.9636 | acc 0.3254
09:24:43 [train] batch 4000/7649 | loss 0.9636 | acc 0.3255
09:24:46 [train] batch 4200/7649 | loss 0.9635 | acc 0.3256
09:24:50 [train] batch 4400/7649 | loss 0.9635 | acc 0.3257
09:24:53 [train] batch 4600/7649 | loss 0.9634 | acc 0.3258
09:24:56 [train] batch 4800/7649 | loss 0.9635 | acc 0.3259
09:25:00 [train] batch 5000/7649 | loss 0.9634 | acc 0.3260
09:25:03 [train] batch 5200/7649 | loss 0.9634 | acc 0.3260
09:25:06 [train] batch 5400/7649 | loss 0.9635 | acc 0.3259
09:25:09 [train] batch 5600/7649 | loss 0.9635 | acc 0.3259
09:25:13 [train] batch 5800/7649 | loss 0.9634 | acc 0.3260
09:25:16 [train] batch 6000/7649 | loss 0.9634 | acc 0.3261
09:25:19 [train] batch 6200/7649 | loss 0.9634 | acc 0.3261
09:25:23 [train] batch 6400/7649 | loss 0.9633 | acc 0.3262
09:25:26 [train] batch 6600/7649 | loss 0.9633 | acc 0.3263
09:25:29 [train] batch 6800/7649 | loss 0.9632 | acc 0.3264
09:25:33 [train] batch 7000/7649 | loss 0.9632 | acc 0.3265
09:25:36 [train] batch 7200/7649 | loss 0.9632 | acc 0.3266
09:25:40 [train] batch 7400/7649 | loss 0.9632 | acc 0.3266
09:25:43 [train] batch 7600/7649 | loss 0.9631 | acc 0.3266
09:25:44 [train] batch 7649/7649 | loss 0.9631 | acc 0.3266
09:25:50 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_02.png
09:25:50 Epoch 02 | train 0.9631/0.3266 | val 0.9439/0.3437 | lr 1.00e-05
09:25:50 ✓ save best
09:25:54 [train] batch 200/7649 | loss 0.9629 | acc 0.3263
09:25:57 [train] batch 400/7649 | loss 0.9637 | acc 0.3269
09:26:01 [train] batch 600/7649 | loss 0.9634 | acc 0.3277
09:26:04 [train] batch 800/7649 | loss 0.9629 | acc 0.3275
09:26:08 [train] batch 1000/7649 | loss 0.9629 | acc 0.3270
09:26:11 [train] batch 1200/7649 | loss 0.9631 | acc 0.3270
09:26:14 [train] batch 1400/7649 | loss 0.9628 | acc 0.3274
09:26:18 [train] batch 1600/7649 | loss 0.9627 | acc 0.3279
09:26:21 [train] batch 1800/7649 | loss 0.9627 | acc 0.3283
09:26:25 [train] batch 2000/7649 | loss 0.9626 | acc 0.3284
09:26:28 [train] batch 2200/7649 | loss 0.9624 | acc 0.3287
09:26:31 [train] batch 2400/7649 | loss 0.9625 | acc 0.3285
09:26:35 [train] batch 2600/7649 | loss 0.9624 | acc 0.3286
09:26:39 [train] batch 2800/7649 | loss 0.9625 | acc 0.3286
09:26:42 [train] batch 3000/7649 | loss 0.9624 | acc 0.3286
09:26:45 [train] batch 3200/7649 | loss 0.9625 | acc 0.3285
09:26:49 [train] batch 3400/7649 | loss 0.9624 | acc 0.3285
09:26:52 [train] batch 3600/7649 | loss 0.9623 | acc 0.3287
09:26:56 [train] batch 3800/7649 | loss 0.9624 | acc 0.3286
09:26:59 [train] batch 4000/7649 | loss 0.9625 | acc 0.3286
09:27:02 [train] batch 4200/7649 | loss 0.9624 | acc 0.3286
09:27:06 [train] batch 4400/7649 | loss 0.9624 | acc 0.3287
09:27:09 [train] batch 4600/7649 | loss 0.9623 | acc 0.3289
09:27:13 [train] batch 4800/7649 | loss 0.9624 | acc 0.3289
09:27:16 [train] batch 5000/7649 | loss 0.9624 | acc 0.3289
09:27:19 [train] batch 5200/7649 | loss 0.9623 | acc 0.3288
09:27:23 [train] batch 5400/7649 | loss 0.9623 | acc 0.3289
09:27:26 [train] batch 5600/7649 | loss 0.9624 | acc 0.3289
09:27:30 [train] batch 5800/7649 | loss 0.9623 | acc 0.3290
09:27:33 [train] batch 6000/7649 | loss 0.9622 | acc 0.3290
09:27:37 [train] batch 6200/7649 | loss 0.9622 | acc 0.3291
09:27:40 [train] batch 6400/7649 | loss 0.9622 | acc 0.3291
09:27:44 [train] batch 6600/7649 | loss 0.9622 | acc 0.3291
09:27:47 [train] batch 6800/7649 | loss 0.9622 | acc 0.3291
09:27:50 [train] batch 7000/7649 | loss 0.9622 | acc 0.3292
09:27:54 [train] batch 7200/7649 | loss 0.9622 | acc 0.3291
09:27:57 [train] batch 7400/7649 | loss 0.9622 | acc 0.3292
09:28:01 [train] batch 7600/7649 | loss 0.9622 | acc 0.3292
09:28:02 [train] batch 7649/7649 | loss 0.9621 | acc 0.3292
09:28:08 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_03.png
09:28:08 Epoch 03 | train 0.9621/0.3292 | val 0.9434/0.3463 | lr 1.00e-05
09:28:08 ✓ save best
09:28:12 [train] batch 200/7649 | loss 0.9628 | acc 0.3315
09:28:15 [train] batch 400/7649 | loss 0.9623 | acc 0.3304
09:28:19 [train] batch 600/7649 | loss 0.9618 | acc 0.3297
09:28:22 [train] batch 800/7649 | loss 0.9619 | acc 0.3307
09:28:25 [train] batch 1000/7649 | loss 0.9623 | acc 0.3304
09:28:29 [train] batch 1200/7649 | loss 0.9623 | acc 0.3300
09:28:32 [train] batch 1400/7649 | loss 0.9619 | acc 0.3301
09:28:35 [train] batch 1600/7649 | loss 0.9622 | acc 0.3300
09:28:39 [train] batch 1800/7649 | loss 0.9622 | acc 0.3301
09:28:42 [train] batch 2000/7649 | loss 0.9623 | acc 0.3298
09:28:45 [train] batch 2200/7649 | loss 0.9622 | acc 0.3297
09:28:49 [train] batch 2400/7649 | loss 0.9622 | acc 0.3296
09:28:52 [train] batch 2600/7649 | loss 0.9621 | acc 0.3296
09:28:55 [train] batch 2800/7649 | loss 0.9621 | acc 0.3297
09:28:59 [train] batch 3000/7649 | loss 0.9619 | acc 0.3298
09:29:02 [train] batch 3200/7649 | loss 0.9618 | acc 0.3300
09:29:05 [train] batch 3400/7649 | loss 0.9617 | acc 0.3300
09:29:08 [train] batch 3600/7649 | loss 0.9618 | acc 0.3299
09:29:12 [train] batch 3800/7649 | loss 0.9618 | acc 0.3299
09:29:15 [train] batch 4000/7649 | loss 0.9617 | acc 0.3301
09:29:18 [train] batch 4200/7649 | loss 0.9617 | acc 0.3301
09:29:22 [train] batch 4400/7649 | loss 0.9616 | acc 0.3302
09:29:25 [train] batch 4600/7649 | loss 0.9615 | acc 0.3303
09:29:28 [train] batch 4800/7649 | loss 0.9615 | acc 0.3305
09:29:31 [train] batch 5000/7649 | loss 0.9615 | acc 0.3305
09:29:35 [train] batch 5200/7649 | loss 0.9616 | acc 0.3303
09:29:38 [train] batch 5400/7649 | loss 0.9615 | acc 0.3305
09:29:41 [train] batch 5600/7649 | loss 0.9616 | acc 0.3305
09:29:45 [train] batch 5800/7649 | loss 0.9615 | acc 0.3306
09:29:48 [train] batch 6000/7649 | loss 0.9615 | acc 0.3307
09:29:52 [train] batch 6200/7649 | loss 0.9616 | acc 0.3307
09:29:55 [train] batch 6400/7649 | loss 0.9615 | acc 0.3309
09:29:58 [train] batch 6600/7649 | loss 0.9615 | acc 0.3309
09:30:02 [train] batch 6800/7649 | loss 0.9614 | acc 0.3310
09:30:05 [train] batch 7000/7649 | loss 0.9614 | acc 0.3310
09:30:09 [train] batch 7200/7649 | loss 0.9615 | acc 0.3309
09:30:12 [train] batch 7400/7649 | loss 0.9614 | acc 0.3310
09:30:15 [train] batch 7600/7649 | loss 0.9615 | acc 0.3309
09:30:16 [train] batch 7649/7649 | loss 0.9615 | acc 0.3310
09:30:23 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_04.png
09:30:23 Epoch 04 | train 0.9615/0.3310 | val 0.9432/0.3479 | lr 1.00e-05
09:30:23 ✓ save best
09:30:27 [train] batch 200/7649 | loss 0.9618 | acc 0.3302
09:30:30 [train] batch 400/7649 | loss 0.9611 | acc 0.3308
09:30:34 [train] batch 600/7649 | loss 0.9621 | acc 0.3305
09:30:37 [train] batch 800/7649 | loss 0.9621 | acc 0.3308
09:30:41 [train] batch 1000/7649 | loss 0.9620 | acc 0.3310
09:30:44 [train] batch 1200/7649 | loss 0.9620 | acc 0.3312
09:30:47 [train] batch 1400/7649 | loss 0.9621 | acc 0.3309
09:30:51 [train] batch 1600/7649 | loss 0.9617 | acc 0.3316
09:30:55 [train] batch 1800/7649 | loss 0.9617 | acc 0.3314
09:30:58 [train] batch 2000/7649 | loss 0.9616 | acc 0.3314
09:31:01 [train] batch 2200/7649 | loss 0.9615 | acc 0.3316
09:31:05 [train] batch 2400/7649 | loss 0.9615 | acc 0.3315
09:31:08 [train] batch 2600/7649 | loss 0.9615 | acc 0.3316
09:31:11 [train] batch 2800/7649 | loss 0.9615 | acc 0.3315
09:31:15 [train] batch 3000/7649 | loss 0.9615 | acc 0.3314
09:31:18 [train] batch 3200/7649 | loss 0.9615 | acc 0.3313
09:31:22 [train] batch 3400/7649 | loss 0.9615 | acc 0.3312
09:31:25 [train] batch 3600/7649 | loss 0.9614 | acc 0.3312
09:31:28 [train] batch 3800/7649 | loss 0.9613 | acc 0.3315
09:31:32 [train] batch 4000/7649 | loss 0.9614 | acc 0.3315
09:31:35 [train] batch 4200/7649 | loss 0.9613 | acc 0.3317
09:31:38 [train] batch 4400/7649 | loss 0.9613 | acc 0.3319
09:31:42 [train] batch 4600/7649 | loss 0.9612 | acc 0.3320
09:31:45 [train] batch 4800/7649 | loss 0.9611 | acc 0.3319
09:31:48 [train] batch 5000/7649 | loss 0.9610 | acc 0.3320
09:31:52 [train] batch 5200/7649 | loss 0.9610 | acc 0.3320
09:31:55 [train] batch 5400/7649 | loss 0.9611 | acc 0.3319
09:31:59 [train] batch 5600/7649 | loss 0.9611 | acc 0.3320
09:32:02 [train] batch 5800/7649 | loss 0.9610 | acc 0.3321
09:32:06 [train] batch 6000/7649 | loss 0.9610 | acc 0.3321
09:32:09 [train] batch 6200/7649 | loss 0.9610 | acc 0.3321
09:32:12 [train] batch 6400/7649 | loss 0.9610 | acc 0.3321
09:32:16 [train] batch 6600/7649 | loss 0.9609 | acc 0.3321
09:32:19 [train] batch 6800/7649 | loss 0.9610 | acc 0.3319
09:32:22 [train] batch 7000/7649 | loss 0.9609 | acc 0.3319
09:32:26 [train] batch 7200/7649 | loss 0.9610 | acc 0.3319
09:32:29 [train] batch 7400/7649 | loss 0.9610 | acc 0.3319
09:32:32 [train] batch 7600/7649 | loss 0.9610 | acc 0.3319
09:32:33 [train] batch 7649/7649 | loss 0.9610 | acc 0.3318
09:32:40 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_05.png
09:32:40 Epoch 05 | train 0.9610/0.3318 | val 0.9436/0.3477 | lr 1.00e-05
09:32:43 [train] batch 200/7649 | loss 0.9624 | acc 0.3315
09:32:47 [train] batch 400/7649 | loss 0.9603 | acc 0.3339
09:32:50 [train] batch 600/7649 | loss 0.9599 | acc 0.3345
09:32:53 [train] batch 800/7649 | loss 0.9605 | acc 0.3335
09:32:57 [train] batch 1000/7649 | loss 0.9608 | acc 0.3333
09:33:00 [train] batch 1200/7649 | loss 0.9610 | acc 0.3327
09:33:03 [train] batch 1400/7649 | loss 0.9612 | acc 0.3325
09:33:07 [train] batch 1600/7649 | loss 0.9608 | acc 0.3326
09:33:10 [train] batch 1800/7649 | loss 0.9610 | acc 0.3322
09:33:13 [train] batch 2000/7649 | loss 0.9613 | acc 0.3322
09:33:16 [train] batch 2200/7649 | loss 0.9610 | acc 0.3326
09:33:20 [train] batch 2400/7649 | loss 0.9609 | acc 0.3324
09:33:23 [train] batch 2600/7649 | loss 0.9609 | acc 0.3323
09:33:26 [train] batch 2800/7649 | loss 0.9608 | acc 0.3325
09:33:30 [train] batch 3000/7649 | loss 0.9609 | acc 0.3325
09:33:33 [train] batch 3200/7649 | loss 0.9608 | acc 0.3330
09:33:36 [train] batch 3400/7649 | loss 0.9607 | acc 0.3330
09:33:39 [train] batch 3600/7649 | loss 0.9606 | acc 0.3332
09:33:43 [train] batch 3800/7649 | loss 0.9606 | acc 0.3331
09:33:46 [train] batch 4000/7649 | loss 0.9606 | acc 0.3332
09:33:49 [train] batch 4200/7649 | loss 0.9606 | acc 0.3332
09:33:53 [train] batch 4400/7649 | loss 0.9606 | acc 0.3333
09:33:56 [train] batch 4600/7649 | loss 0.9606 | acc 0.3332
09:33:59 [train] batch 4800/7649 | loss 0.9607 | acc 0.3331
09:34:02 [train] batch 5000/7649 | loss 0.9607 | acc 0.3331
09:34:06 [train] batch 5200/7649 | loss 0.9607 | acc 0.3332
09:34:09 [train] batch 5400/7649 | loss 0.9607 | acc 0.3332
09:34:12 [train] batch 5600/7649 | loss 0.9607 | acc 0.3332
09:34:16 [train] batch 5800/7649 | loss 0.9607 | acc 0.3333
09:34:19 [train] batch 6000/7649 | loss 0.9606 | acc 0.3332
09:34:23 [train] batch 6200/7649 | loss 0.9607 | acc 0.3332
09:34:26 [train] batch 6400/7649 | loss 0.9607 | acc 0.3331
09:34:29 [train] batch 6600/7649 | loss 0.9607 | acc 0.3330
09:34:33 [train] batch 6800/7649 | loss 0.9607 | acc 0.3330
09:34:36 [train] batch 7000/7649 | loss 0.9607 | acc 0.3330
09:34:40 [train] batch 7200/7649 | loss 0.9606 | acc 0.3331
09:34:43 [train] batch 7400/7649 | loss 0.9606 | acc 0.3331
09:34:47 [train] batch 7600/7649 | loss 0.9606 | acc 0.3331
09:34:47 [train] batch 7649/7649 | loss 0.9606 | acc 0.3331
09:34:54 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_06.png
09:34:54 Epoch 06 | train 0.9606/0.3331 | val 0.9438/0.3483 | lr 1.00e-05
09:34:54 ✓ save best
09:34:58 [train] batch 200/7649 | loss 0.9614 | acc 0.3311
09:35:01 [train] batch 400/7649 | loss 0.9601 | acc 0.3337
09:35:05 [train] batch 600/7649 | loss 0.9600 | acc 0.3338
09:35:08 [train] batch 800/7649 | loss 0.9604 | acc 0.3331
09:35:12 [train] batch 1000/7649 | loss 0.9607 | acc 0.3333
09:35:15 [train] batch 1200/7649 | loss 0.9608 | acc 0.3334
09:35:19 [train] batch 1400/7649 | loss 0.9610 | acc 0.3328
09:35:22 [train] batch 1600/7649 | loss 0.9609 | acc 0.3330
09:35:25 [train] batch 1800/7649 | loss 0.9608 | acc 0.3332
09:35:29 [train] batch 2000/7649 | loss 0.9606 | acc 0.3334
09:35:32 [train] batch 2200/7649 | loss 0.9608 | acc 0.3331
09:35:35 [train] batch 2400/7649 | loss 0.9608 | acc 0.3332
09:35:39 [train] batch 2600/7649 | loss 0.9605 | acc 0.3336
09:35:42 [train] batch 2800/7649 | loss 0.9607 | acc 0.3334
09:35:46 [train] batch 3000/7649 | loss 0.9605 | acc 0.3337
09:35:49 [train] batch 3200/7649 | loss 0.9606 | acc 0.3334
09:35:52 [train] batch 3400/7649 | loss 0.9606 | acc 0.3333
09:35:56 [train] batch 3600/7649 | loss 0.9606 | acc 0.3333
09:35:59 [train] batch 3800/7649 | loss 0.9605 | acc 0.3335
09:36:03 [train] batch 4000/7649 | loss 0.9605 | acc 0.3334
09:36:06 [train] batch 4200/7649 | loss 0.9605 | acc 0.3335
09:36:09 [train] batch 4400/7649 | loss 0.9606 | acc 0.3333
09:36:13 [train] batch 4600/7649 | loss 0.9606 | acc 0.3334
09:36:16 [train] batch 4800/7649 | loss 0.9606 | acc 0.3332
09:36:20 [train] batch 5000/7649 | loss 0.9607 | acc 0.3332
09:36:23 [train] batch 5200/7649 | loss 0.9607 | acc 0.3332
09:36:27 [train] batch 5400/7649 | loss 0.9606 | acc 0.3334
09:36:30 [train] batch 5600/7649 | loss 0.9605 | acc 0.3335
09:36:33 [train] batch 5800/7649 | loss 0.9605 | acc 0.3335
09:36:37 [train] batch 6000/7649 | loss 0.9605 | acc 0.3336
09:36:40 [train] batch 6200/7649 | loss 0.9606 | acc 0.3336
09:36:43 [train] batch 6400/7649 | loss 0.9605 | acc 0.3336
09:36:47 [train] batch 6600/7649 | loss 0.9605 | acc 0.3336
09:36:50 [train] batch 6800/7649 | loss 0.9604 | acc 0.3337
09:36:53 [train] batch 7000/7649 | loss 0.9603 | acc 0.3338
09:36:57 [train] batch 7200/7649 | loss 0.9603 | acc 0.3337
09:37:00 [train] batch 7400/7649 | loss 0.9603 | acc 0.3338
09:37:03 [train] batch 7600/7649 | loss 0.9603 | acc 0.3338
09:37:04 [train] batch 7649/7649 | loss 0.9603 | acc 0.3338
09:37:10 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_07.png
09:37:10 Epoch 07 | train 0.9603/0.3338 | val 0.9438/0.3473 | lr 1.00e-05
09:37:14 [train] batch 200/7649 | loss 0.9613 | acc 0.3330
09:37:17 [train] batch 400/7649 | loss 0.9611 | acc 0.3327
09:37:21 [train] batch 600/7649 | loss 0.9609 | acc 0.3335
09:37:24 [train] batch 800/7649 | loss 0.9614 | acc 0.3327
09:37:27 [train] batch 1000/7649 | loss 0.9616 | acc 0.3329
09:37:31 [train] batch 1200/7649 | loss 0.9613 | acc 0.3336
09:37:34 [train] batch 1400/7649 | loss 0.9610 | acc 0.3338
09:37:37 [train] batch 1600/7649 | loss 0.9610 | acc 0.3336
09:37:41 [train] batch 1800/7649 | loss 0.9610 | acc 0.3335
09:37:44 [train] batch 2000/7649 | loss 0.9612 | acc 0.3329
09:37:47 [train] batch 2200/7649 | loss 0.9612 | acc 0.3330
09:37:50 [train] batch 2400/7649 | loss 0.9610 | acc 0.3334
09:37:54 [train] batch 2600/7649 | loss 0.9610 | acc 0.3333
09:37:57 [train] batch 2800/7649 | loss 0.9609 | acc 0.3335
09:38:00 [train] batch 3000/7649 | loss 0.9608 | acc 0.3337
09:38:04 [train] batch 3200/7649 | loss 0.9607 | acc 0.3340
09:38:07 [train] batch 3400/7649 | loss 0.9605 | acc 0.3342
09:38:10 [train] batch 3600/7649 | loss 0.9605 | acc 0.3343
09:38:14 [train] batch 3800/7649 | loss 0.9605 | acc 0.3343
09:38:17 [train] batch 4000/7649 | loss 0.9604 | acc 0.3342
09:38:20 [train] batch 4200/7649 | loss 0.9604 | acc 0.3342
09:38:24 [train] batch 4400/7649 | loss 0.9604 | acc 0.3343
09:38:27 [train] batch 4600/7649 | loss 0.9603 | acc 0.3344
09:38:30 [train] batch 4800/7649 | loss 0.9603 | acc 0.3344
09:38:34 [train] batch 5000/7649 | loss 0.9602 | acc 0.3345
09:38:37 [train] batch 5200/7649 | loss 0.9602 | acc 0.3346
09:38:41 [train] batch 5400/7649 | loss 0.9602 | acc 0.3346
09:38:44 [train] batch 5600/7649 | loss 0.9601 | acc 0.3347
09:38:48 [train] batch 5800/7649 | loss 0.9602 | acc 0.3345
09:38:51 [train] batch 6000/7649 | loss 0.9601 | acc 0.3346
09:38:54 [train] batch 6200/7649 | loss 0.9602 | acc 0.3345
09:38:58 [train] batch 6400/7649 | loss 0.9602 | acc 0.3345
09:39:01 [train] batch 6600/7649 | loss 0.9601 | acc 0.3346
09:39:05 [train] batch 6800/7649 | loss 0.9601 | acc 0.3346
09:39:08 [train] batch 7000/7649 | loss 0.9600 | acc 0.3347
09:39:12 [train] batch 7200/7649 | loss 0.9600 | acc 0.3347
09:39:15 [train] batch 7400/7649 | loss 0.9600 | acc 0.3347
09:39:18 [train] batch 7600/7649 | loss 0.9600 | acc 0.3348
09:39:19 [train] batch 7649/7649 | loss 0.9599 | acc 0.3348
09:39:27 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_08.png
09:39:27 Epoch 08 | train 0.9599/0.3348 | val 0.9437/0.3484 | lr 5.00e-06
09:39:27 ✓ save best
09:39:30 [train] batch 200/7649 | loss 0.9604 | acc 0.3340
09:39:34 [train] batch 400/7649 | loss 0.9612 | acc 0.3330
09:39:37 [train] batch 600/7649 | loss 0.9607 | acc 0.3334
09:39:41 [train] batch 800/7649 | loss 0.9605 | acc 0.3339
09:39:44 [train] batch 1000/7649 | loss 0.9605 | acc 0.3349
09:39:48 [train] batch 1200/7649 | loss 0.9600 | acc 0.3359
09:39:51 [train] batch 1400/7649 | loss 0.9599 | acc 0.3359
09:39:55 [train] batch 1600/7649 | loss 0.9598 | acc 0.3359
09:39:58 [train] batch 1800/7649 | loss 0.9598 | acc 0.3360
09:40:01 [train] batch 2000/7649 | loss 0.9598 | acc 0.3358
09:40:05 [train] batch 2200/7649 | loss 0.9600 | acc 0.3356
09:40:08 [train] batch 2400/7649 | loss 0.9600 | acc 0.3358
09:40:12 [train] batch 2600/7649 | loss 0.9600 | acc 0.3356
09:40:15 [train] batch 2800/7649 | loss 0.9599 | acc 0.3357
09:40:18 [train] batch 3000/7649 | loss 0.9598 | acc 0.3358
09:40:22 [train] batch 3200/7649 | loss 0.9597 | acc 0.3361
09:40:25 [train] batch 3400/7649 | loss 0.9596 | acc 0.3363
09:40:29 [train] batch 3600/7649 | loss 0.9596 | acc 0.3361
09:40:32 [train] batch 3800/7649 | loss 0.9596 | acc 0.3361
09:40:35 [train] batch 4000/7649 | loss 0.9597 | acc 0.3360
09:40:39 [train] batch 4200/7649 | loss 0.9598 | acc 0.3358
09:40:42 [train] batch 4400/7649 | loss 0.9598 | acc 0.3358
09:40:46 [train] batch 4600/7649 | loss 0.9597 | acc 0.3358
09:40:49 [train] batch 4800/7649 | loss 0.9598 | acc 0.3358
09:40:53 [train] batch 5000/7649 | loss 0.9597 | acc 0.3359
09:40:56 [train] batch 5200/7649 | loss 0.9597 | acc 0.3359
09:40:59 [train] batch 5400/7649 | loss 0.9597 | acc 0.3359
09:41:03 [train] batch 5600/7649 | loss 0.9597 | acc 0.3359
09:41:06 [train] batch 5800/7649 | loss 0.9597 | acc 0.3360
09:41:09 [train] batch 6000/7649 | loss 0.9597 | acc 0.3359
09:41:13 [train] batch 6200/7649 | loss 0.9597 | acc 0.3359
09:41:16 [train] batch 6400/7649 | loss 0.9596 | acc 0.3360
09:41:19 [train] batch 6600/7649 | loss 0.9596 | acc 0.3359
09:41:23 [train] batch 6800/7649 | loss 0.9596 | acc 0.3360
09:41:26 [train] batch 7000/7649 | loss 0.9596 | acc 0.3359
09:41:29 [train] batch 7200/7649 | loss 0.9596 | acc 0.3359
09:41:33 [train] batch 7400/7649 | loss 0.9596 | acc 0.3359
09:41:36 [train] batch 7600/7649 | loss 0.9597 | acc 0.3359
09:41:37 [train] batch 7649/7649 | loss 0.9596 | acc 0.3360
09:41:44 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_09.png
09:41:44 Epoch 09 | train 0.9596/0.3360 | val 0.9437/0.3495 | lr 5.00e-06
09:41:44 ✓ save best
09:41:48 [train] batch 200/7649 | loss 0.9596 | acc 0.3368
09:41:51 [train] batch 400/7649 | loss 0.9599 | acc 0.3359
09:41:54 [train] batch 600/7649 | loss 0.9604 | acc 0.3353
09:41:57 [train] batch 800/7649 | loss 0.9608 | acc 0.3352
09:42:01 [train] batch 1000/7649 | loss 0.9607 | acc 0.3351
09:42:04 [train] batch 1200/7649 | loss 0.9608 | acc 0.3347
09:42:07 [train] batch 1400/7649 | loss 0.9604 | acc 0.3353
09:42:10 [train] batch 1600/7649 | loss 0.9603 | acc 0.3356
09:42:14 [train] batch 1800/7649 | loss 0.9603 | acc 0.3354
09:42:17 [train] batch 2000/7649 | loss 0.9600 | acc 0.3356
09:42:20 [train] batch 2200/7649 | loss 0.9602 | acc 0.3353
09:42:24 [train] batch 2400/7649 | loss 0.9600 | acc 0.3354
09:42:27 [train] batch 2600/7649 | loss 0.9600 | acc 0.3355
09:42:30 [train] batch 2800/7649 | loss 0.9598 | acc 0.3358
09:42:34 [train] batch 3000/7649 | loss 0.9598 | acc 0.3359
09:42:37 [train] batch 3200/7649 | loss 0.9597 | acc 0.3359
09:42:40 [train] batch 3400/7649 | loss 0.9598 | acc 0.3358
09:42:44 [train] batch 3600/7649 | loss 0.9597 | acc 0.3358
09:42:47 [train] batch 3800/7649 | loss 0.9596 | acc 0.3359
09:42:50 [train] batch 4000/7649 | loss 0.9596 | acc 0.3361
09:42:54 [train] batch 4200/7649 | loss 0.9596 | acc 0.3361
09:42:57 [train] batch 4400/7649 | loss 0.9596 | acc 0.3362
09:43:01 [train] batch 4600/7649 | loss 0.9596 | acc 0.3362
09:43:04 [train] batch 4800/7649 | loss 0.9596 | acc 0.3361
09:43:08 [train] batch 5000/7649 | loss 0.9595 | acc 0.3362
09:43:11 [train] batch 5200/7649 | loss 0.9595 | acc 0.3363
09:43:14 [train] batch 5400/7649 | loss 0.9596 | acc 0.3361
09:43:18 [train] batch 5600/7649 | loss 0.9596 | acc 0.3362
09:43:21 [train] batch 5800/7649 | loss 0.9596 | acc 0.3362
09:43:24 [train] batch 6000/7649 | loss 0.9595 | acc 0.3362
09:43:28 [train] batch 6200/7649 | loss 0.9595 | acc 0.3363
09:43:31 [train] batch 6400/7649 | loss 0.9595 | acc 0.3363
09:43:34 [train] batch 6600/7649 | loss 0.9595 | acc 0.3363
09:43:38 [train] batch 6800/7649 | loss 0.9595 | acc 0.3362
09:43:41 [train] batch 7000/7649 | loss 0.9594 | acc 0.3363
09:43:45 [train] batch 7200/7649 | loss 0.9595 | acc 0.3363
09:43:48 [train] batch 7400/7649 | loss 0.9594 | acc 0.3363
09:43:51 [train] batch 7600/7649 | loss 0.9594 | acc 0.3363
09:43:52 [train] batch 7649/7649 | loss 0.9594 | acc 0.3363
09:43:59 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_10.png
09:44:00 Epoch 10 | train 0.9594/0.3363 | val 0.9434/0.3500 | lr 5.00e-06
09:44:00 ✓ save best
09:44:03 [train] batch 200/7649 | loss 0.9604 | acc 0.3362
09:44:07 [train] batch 400/7649 | loss 0.9599 | acc 0.3367
09:44:10 [train] batch 600/7649 | loss 0.9596 | acc 0.3364
09:44:14 [train] batch 800/7649 | loss 0.9597 | acc 0.3365
09:44:17 [train] batch 1000/7649 | loss 0.9600 | acc 0.3361
09:44:20 [train] batch 1200/7649 | loss 0.9597 | acc 0.3363
09:44:24 [train] batch 1400/7649 | loss 0.9594 | acc 0.3368
09:44:27 [train] batch 1600/7649 | loss 0.9593 | acc 0.3369
09:44:31 [train] batch 1800/7649 | loss 0.9596 | acc 0.3362
09:44:34 [train] batch 2000/7649 | loss 0.9594 | acc 0.3365
09:44:37 [train] batch 2200/7649 | loss 0.9593 | acc 0.3364
09:44:41 [train] batch 2400/7649 | loss 0.9594 | acc 0.3365
09:44:44 [train] batch 2600/7649 | loss 0.9593 | acc 0.3364
09:44:48 [train] batch 2800/7649 | loss 0.9593 | acc 0.3366
09:44:51 [train] batch 3000/7649 | loss 0.9592 | acc 0.3365
09:44:55 [train] batch 3200/7649 | loss 0.9591 | acc 0.3366
09:44:58 [train] batch 3400/7649 | loss 0.9591 | acc 0.3366
09:45:01 [train] batch 3600/7649 | loss 0.9593 | acc 0.3366
09:45:05 [train] batch 3800/7649 | loss 0.9593 | acc 0.3366
09:45:08 [train] batch 4000/7649 | loss 0.9593 | acc 0.3367
09:45:12 [train] batch 4200/7649 | loss 0.9592 | acc 0.3368
09:45:15 [train] batch 4400/7649 | loss 0.9591 | acc 0.3369
09:45:18 [train] batch 4600/7649 | loss 0.9591 | acc 0.3369
09:45:22 [train] batch 4800/7649 | loss 0.9590 | acc 0.3370
09:45:25 [train] batch 5000/7649 | loss 0.9590 | acc 0.3370
09:45:28 [train] batch 5200/7649 | loss 0.9590 | acc 0.3369
09:45:32 [train] batch 5400/7649 | loss 0.9589 | acc 0.3370
09:45:35 [train] batch 5600/7649 | loss 0.9590 | acc 0.3370
09:45:38 [train] batch 5800/7649 | loss 0.9591 | acc 0.3369
09:45:41 [train] batch 6000/7649 | loss 0.9591 | acc 0.3370
09:45:45 [train] batch 6200/7649 | loss 0.9591 | acc 0.3369
09:45:48 [train] batch 6400/7649 | loss 0.9591 | acc 0.3368
09:45:51 [train] batch 6600/7649 | loss 0.9591 | acc 0.3368
09:45:55 [train] batch 6800/7649 | loss 0.9591 | acc 0.3368
09:45:58 [train] batch 7000/7649 | loss 0.9591 | acc 0.3367
09:46:01 [train] batch 7200/7649 | loss 0.9592 | acc 0.3367
09:46:04 [train] batch 7400/7649 | loss 0.9592 | acc 0.3367
09:46:08 [train] batch 7600/7649 | loss 0.9592 | acc 0.3367
09:46:09 [train] batch 7649/7649 | loss 0.9592 | acc 0.3367
09:46:16 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_11.png
09:46:16 Epoch 11 | train 0.9592/0.3367 | val 0.9435/0.3512 | lr 5.00e-06
09:46:16 ✓ save best
09:46:19 [train] batch 200/7649 | loss 0.9586 | acc 0.3371
09:46:23 [train] batch 400/7649 | loss 0.9584 | acc 0.3371
09:46:26 [train] batch 600/7649 | loss 0.9581 | acc 0.3379
09:46:29 [train] batch 800/7649 | loss 0.9587 | acc 0.3377
09:46:33 [train] batch 1000/7649 | loss 0.9591 | acc 0.3375
09:46:36 [train] batch 1200/7649 | loss 0.9597 | acc 0.3362
09:46:40 [train] batch 1400/7649 | loss 0.9595 | acc 0.3363
09:46:43 [train] batch 1600/7649 | loss 0.9597 | acc 0.3360
09:46:46 [train] batch 1800/7649 | loss 0.9597 | acc 0.3362
09:46:50 [train] batch 2000/7649 | loss 0.9596 | acc 0.3362
09:46:53 [train] batch 2200/7649 | loss 0.9596 | acc 0.3363
09:46:56 [train] batch 2400/7649 | loss 0.9594 | acc 0.3366
09:47:00 [train] batch 2600/7649 | loss 0.9593 | acc 0.3367
09:47:03 [train] batch 2800/7649 | loss 0.9593 | acc 0.3368
09:47:07 [train] batch 3000/7649 | loss 0.9593 | acc 0.3366
09:47:10 [train] batch 3200/7649 | loss 0.9592 | acc 0.3368
09:47:13 [train] batch 3400/7649 | loss 0.9593 | acc 0.3367
09:47:17 [train] batch 3600/7649 | loss 0.9592 | acc 0.3367
09:47:20 [train] batch 3800/7649 | loss 0.9593 | acc 0.3366
09:47:24 [train] batch 4000/7649 | loss 0.9592 | acc 0.3366
09:47:28 [train] batch 4200/7649 | loss 0.9592 | acc 0.3367
09:47:31 [train] batch 4400/7649 | loss 0.9592 | acc 0.3368
09:47:35 [train] batch 4600/7649 | loss 0.9592 | acc 0.3369
09:47:38 [train] batch 4800/7649 | loss 0.9592 | acc 0.3368
09:47:41 [train] batch 5000/7649 | loss 0.9592 | acc 0.3368
09:47:45 [train] batch 5200/7649 | loss 0.9592 | acc 0.3369
09:47:48 [train] batch 5400/7649 | loss 0.9591 | acc 0.3370
09:47:52 [train] batch 5600/7649 | loss 0.9591 | acc 0.3370
09:47:55 [train] batch 5800/7649 | loss 0.9591 | acc 0.3370
09:47:59 [train] batch 6000/7649 | loss 0.9591 | acc 0.3370
09:48:02 [train] batch 6200/7649 | loss 0.9591 | acc 0.3371
09:48:05 [train] batch 6400/7649 | loss 0.9591 | acc 0.3371
09:48:09 [train] batch 6600/7649 | loss 0.9591 | acc 0.3371
09:48:12 [train] batch 6800/7649 | loss 0.9591 | acc 0.3371
09:48:15 [train] batch 7000/7649 | loss 0.9591 | acc 0.3371
09:48:19 [train] batch 7200/7649 | loss 0.9591 | acc 0.3371
09:48:22 [train] batch 7400/7649 | loss 0.9591 | acc 0.3371
09:48:25 [train] batch 7600/7649 | loss 0.9591 | acc 0.3371
09:48:26 [train] batch 7649/7649 | loss 0.9591 | acc 0.3371
09:48:33 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_12.png
09:48:33 Epoch 12 | train 0.9591/0.3371 | val 0.9437/0.3487 | lr 2.50e-06
09:48:36 [train] batch 200/7649 | loss 0.9579 | acc 0.3405
09:48:40 [train] batch 400/7649 | loss 0.9575 | acc 0.3416
09:48:43 [train] batch 600/7649 | loss 0.9587 | acc 0.3396
09:48:46 [train] batch 800/7649 | loss 0.9592 | acc 0.3385
09:48:50 [train] batch 1000/7649 | loss 0.9595 | acc 0.3377
09:48:53 [train] batch 1200/7649 | loss 0.9598 | acc 0.3373
09:48:56 [train] batch 1400/7649 | loss 0.9600 | acc 0.3367
09:49:00 [train] batch 1600/7649 | loss 0.9596 | acc 0.3370
09:49:03 [train] batch 1800/7649 | loss 0.9596 | acc 0.3371
09:49:06 [train] batch 2000/7649 | loss 0.9595 | acc 0.3373
09:49:10 [train] batch 2200/7649 | loss 0.9595 | acc 0.3372
09:49:13 [train] batch 2400/7649 | loss 0.9596 | acc 0.3373
09:49:17 [train] batch 2600/7649 | loss 0.9595 | acc 0.3373
09:49:20 [train] batch 2800/7649 | loss 0.9595 | acc 0.3374
09:49:23 [train] batch 3000/7649 | loss 0.9595 | acc 0.3371
09:49:27 [train] batch 3200/7649 | loss 0.9594 | acc 0.3373
09:49:30 [train] batch 3400/7649 | loss 0.9595 | acc 0.3372
09:49:33 [train] batch 3600/7649 | loss 0.9595 | acc 0.3371
09:49:37 [train] batch 3800/7649 | loss 0.9594 | acc 0.3373
09:49:40 [train] batch 4000/7649 | loss 0.9594 | acc 0.3374
09:49:44 [train] batch 4200/7649 | loss 0.9593 | acc 0.3374
09:49:47 [train] batch 4400/7649 | loss 0.9593 | acc 0.3375
09:49:50 [train] batch 4600/7649 | loss 0.9593 | acc 0.3375
09:49:53 [train] batch 4800/7649 | loss 0.9593 | acc 0.3374
09:49:57 [train] batch 5000/7649 | loss 0.9592 | acc 0.3374
09:50:00 [train] batch 5200/7649 | loss 0.9591 | acc 0.3374
09:50:03 [train] batch 5400/7649 | loss 0.9591 | acc 0.3374
09:50:07 [train] batch 5600/7649 | loss 0.9591 | acc 0.3375
09:50:10 [train] batch 5800/7649 | loss 0.9591 | acc 0.3374
09:50:13 [train] batch 6000/7649 | loss 0.9590 | acc 0.3375
09:50:16 [train] batch 6200/7649 | loss 0.9590 | acc 0.3376
09:50:20 [train] batch 6400/7649 | loss 0.9590 | acc 0.3376
09:50:23 [train] batch 6600/7649 | loss 0.9590 | acc 0.3377
09:50:26 [train] batch 6800/7649 | loss 0.9590 | acc 0.3377
09:50:30 [train] batch 7000/7649 | loss 0.9590 | acc 0.3376
09:50:33 [train] batch 7200/7649 | loss 0.9589 | acc 0.3376
09:50:36 [train] batch 7400/7649 | loss 0.9589 | acc 0.3376
09:50:40 [train] batch 7600/7649 | loss 0.9589 | acc 0.3376
09:50:41 [train] batch 7649/7649 | loss 0.9589 | acc 0.3376
09:50:47 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_13.png
09:50:47 Epoch 13 | train 0.9589/0.3376 | val 0.9434/0.3507 | lr 2.50e-06
09:50:51 [train] batch 200/7649 | loss 0.9594 | acc 0.3379
09:50:54 [train] batch 400/7649 | loss 0.9595 | acc 0.3371
09:50:58 [train] batch 600/7649 | loss 0.9591 | acc 0.3376
09:51:01 [train] batch 800/7649 | loss 0.9590 | acc 0.3379
09:51:04 [train] batch 1000/7649 | loss 0.9590 | acc 0.3383
09:51:08 [train] batch 1200/7649 | loss 0.9589 | acc 0.3380
09:51:11 [train] batch 1400/7649 | loss 0.9589 | acc 0.3381
09:51:14 [train] batch 1600/7649 | loss 0.9588 | acc 0.3382
09:51:18 [train] batch 1800/7649 | loss 0.9587 | acc 0.3384
09:51:21 [train] batch 2000/7649 | loss 0.9589 | acc 0.3380
09:51:25 [train] batch 2200/7649 | loss 0.9588 | acc 0.3383
09:51:28 [train] batch 2400/7649 | loss 0.9589 | acc 0.3379
09:51:32 [train] batch 2600/7649 | loss 0.9588 | acc 0.3382
09:51:35 [train] batch 2800/7649 | loss 0.9586 | acc 0.3384
09:51:38 [train] batch 3000/7649 | loss 0.9585 | acc 0.3384
09:51:42 [train] batch 3200/7649 | loss 0.9586 | acc 0.3382
09:51:45 [train] batch 3400/7649 | loss 0.9587 | acc 0.3381
09:51:49 [train] batch 3600/7649 | loss 0.9589 | acc 0.3380
09:51:52 [train] batch 3800/7649 | loss 0.9588 | acc 0.3381
09:51:56 [train] batch 4000/7649 | loss 0.9587 | acc 0.3381
09:51:59 [train] batch 4200/7649 | loss 0.9587 | acc 0.3382
09:52:03 [train] batch 4400/7649 | loss 0.9587 | acc 0.3382
09:52:06 [train] batch 4600/7649 | loss 0.9587 | acc 0.3382
09:52:09 [train] batch 4800/7649 | loss 0.9587 | acc 0.3380
09:52:13 [train] batch 5000/7649 | loss 0.9587 | acc 0.3380
09:52:16 [train] batch 5200/7649 | loss 0.9587 | acc 0.3381
09:52:20 [train] batch 5400/7649 | loss 0.9587 | acc 0.3381
09:52:23 [train] batch 5600/7649 | loss 0.9586 | acc 0.3383
09:52:26 [train] batch 5800/7649 | loss 0.9586 | acc 0.3383
09:52:30 [train] batch 6000/7649 | loss 0.9587 | acc 0.3382
09:52:33 [train] batch 6200/7649 | loss 0.9587 | acc 0.3381
09:52:36 [train] batch 6400/7649 | loss 0.9588 | acc 0.3380
09:52:40 [train] batch 6600/7649 | loss 0.9587 | acc 0.3381
09:52:43 [train] batch 6800/7649 | loss 0.9588 | acc 0.3381
09:52:46 [train] batch 7000/7649 | loss 0.9587 | acc 0.3382
09:52:50 [train] batch 7200/7649 | loss 0.9587 | acc 0.3381
09:52:53 [train] batch 7400/7649 | loss 0.9587 | acc 0.3381
09:52:57 [train] batch 7600/7649 | loss 0.9588 | acc 0.3380
09:52:58 [train] batch 7649/7649 | loss 0.9588 | acc 0.3380
09:53:04 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_14.png
09:53:04 Epoch 14 | train 0.9588/0.3380 | val 0.9434/0.3509 | lr 2.50e-06
09:53:08 [train] batch 200/7649 | loss 0.9602 | acc 0.3368
09:53:12 [train] batch 400/7649 | loss 0.9582 | acc 0.3387
09:53:15 [train] batch 600/7649 | loss 0.9592 | acc 0.3376
09:53:18 [train] batch 800/7649 | loss 0.9593 | acc 0.3376
09:53:22 [train] batch 1000/7649 | loss 0.9590 | acc 0.3377
09:53:25 [train] batch 1200/7649 | loss 0.9591 | acc 0.3380
09:53:28 [train] batch 1400/7649 | loss 0.9591 | acc 0.3381
09:53:32 [train] batch 1600/7649 | loss 0.9589 | acc 0.3385
09:53:35 [train] batch 1800/7649 | loss 0.9588 | acc 0.3384
09:53:38 [train] batch 2000/7649 | loss 0.9590 | acc 0.3384
09:53:42 [train] batch 2200/7649 | loss 0.9589 | acc 0.3385
09:53:45 [train] batch 2400/7649 | loss 0.9588 | acc 0.3386
09:53:48 [train] batch 2600/7649 | loss 0.9588 | acc 0.3384
09:53:52 [train] batch 2800/7649 | loss 0.9587 | acc 0.3385
09:53:55 [train] batch 3000/7649 | loss 0.9587 | acc 0.3386
09:53:59 [train] batch 3200/7649 | loss 0.9587 | acc 0.3384
09:54:02 [train] batch 3400/7649 | loss 0.9587 | acc 0.3384
09:54:05 [train] batch 3600/7649 | loss 0.9586 | acc 0.3384
09:54:08 [train] batch 3800/7649 | loss 0.9586 | acc 0.3383
09:54:12 [train] batch 4000/7649 | loss 0.9586 | acc 0.3383
09:54:15 [train] batch 4200/7649 | loss 0.9586 | acc 0.3382
09:54:18 [train] batch 4400/7649 | loss 0.9585 | acc 0.3383
09:54:22 [train] batch 4600/7649 | loss 0.9585 | acc 0.3384
09:54:25 [train] batch 4800/7649 | loss 0.9585 | acc 0.3384
09:54:28 [train] batch 5000/7649 | loss 0.9585 | acc 0.3385
09:54:31 [train] batch 5200/7649 | loss 0.9585 | acc 0.3385
09:54:35 [train] batch 5400/7649 | loss 0.9586 | acc 0.3384
09:54:38 [train] batch 5600/7649 | loss 0.9586 | acc 0.3383
09:54:41 [train] batch 5800/7649 | loss 0.9587 | acc 0.3382
09:54:45 [train] batch 6000/7649 | loss 0.9586 | acc 0.3383
09:54:48 [train] batch 6200/7649 | loss 0.9586 | acc 0.3384
09:54:51 [train] batch 6400/7649 | loss 0.9587 | acc 0.3384
09:54:55 [train] batch 6600/7649 | loss 0.9587 | acc 0.3383
09:54:58 [train] batch 6800/7649 | loss 0.9587 | acc 0.3384
09:55:01 [train] batch 7000/7649 | loss 0.9587 | acc 0.3385
09:55:05 [train] batch 7200/7649 | loss 0.9587 | acc 0.3384
09:55:08 [train] batch 7400/7649 | loss 0.9587 | acc 0.3383
09:55:12 [train] batch 7600/7649 | loss 0.9587 | acc 0.3383
09:55:13 [train] batch 7649/7649 | loss 0.9587 | acc 0.3383
09:55:19 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_15.png
09:55:19 Epoch 15 | train 0.9587/0.3383 | val 0.9434/0.3503 | lr 2.50e-06
09:55:23 [train] batch 200/7649 | loss 0.9586 | acc 0.3374
09:55:26 [train] batch 400/7649 | loss 0.9591 | acc 0.3357
09:55:30 [train] batch 600/7649 | loss 0.9588 | acc 0.3373
09:55:33 [train] batch 800/7649 | loss 0.9587 | acc 0.3377
09:55:36 [train] batch 1000/7649 | loss 0.9589 | acc 0.3381
09:55:40 [train] batch 1200/7649 | loss 0.9591 | acc 0.3377
09:55:43 [train] batch 1400/7649 | loss 0.9588 | acc 0.3379
09:55:47 [train] batch 1600/7649 | loss 0.9586 | acc 0.3381
09:55:50 [train] batch 1800/7649 | loss 0.9587 | acc 0.3380
09:55:53 [train] batch 2000/7649 | loss 0.9588 | acc 0.3378
09:55:57 [train] batch 2200/7649 | loss 0.9587 | acc 0.3379
09:56:00 [train] batch 2400/7649 | loss 0.9586 | acc 0.3381
09:56:04 [train] batch 2600/7649 | loss 0.9587 | acc 0.3381
09:56:07 [train] batch 2800/7649 | loss 0.9587 | acc 0.3380
09:56:11 [train] batch 3000/7649 | loss 0.9585 | acc 0.3382
09:56:14 [train] batch 3200/7649 | loss 0.9585 | acc 0.3384
09:56:18 [train] batch 3400/7649 | loss 0.9585 | acc 0.3384
09:56:21 [train] batch 3600/7649 | loss 0.9585 | acc 0.3385
09:56:25 [train] batch 3800/7649 | loss 0.9585 | acc 0.3384
09:56:28 [train] batch 4000/7649 | loss 0.9585 | acc 0.3385
09:56:31 [train] batch 4200/7649 | loss 0.9585 | acc 0.3384
09:56:35 [train] batch 4400/7649 | loss 0.9585 | acc 0.3384
09:56:38 [train] batch 4600/7649 | loss 0.9586 | acc 0.3384
09:56:42 [train] batch 4800/7649 | loss 0.9586 | acc 0.3383
09:56:45 [train] batch 5000/7649 | loss 0.9586 | acc 0.3383
09:56:48 [train] batch 5200/7649 | loss 0.9586 | acc 0.3383
09:56:52 [train] batch 5400/7649 | loss 0.9587 | acc 0.3382
09:56:55 [train] batch 5600/7649 | loss 0.9586 | acc 0.3383
09:56:59 [train] batch 5800/7649 | loss 0.9586 | acc 0.3382
09:57:02 [train] batch 6000/7649 | loss 0.9586 | acc 0.3382
09:57:05 [train] batch 6200/7649 | loss 0.9586 | acc 0.3383
09:57:09 [train] batch 6400/7649 | loss 0.9586 | acc 0.3383
09:57:12 [train] batch 6600/7649 | loss 0.9587 | acc 0.3383
09:57:16 [train] batch 6800/7649 | loss 0.9587 | acc 0.3382
09:57:19 [train] batch 7000/7649 | loss 0.9587 | acc 0.3381
09:57:23 [train] batch 7200/7649 | loss 0.9586 | acc 0.3382
09:57:26 [train] batch 7400/7649 | loss 0.9587 | acc 0.3382
09:57:29 [train] batch 7600/7649 | loss 0.9587 | acc 0.3382
09:57:30 [train] batch 7649/7649 | loss 0.9587 | acc 0.3383
09:57:37 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_16.png
09:57:37 Epoch 16 | train 0.9587/0.3383 | val 0.9436/0.3509 | lr 1.25e-06
09:57:41 [train] batch 200/7649 | loss 0.9592 | acc 0.3373
09:57:44 [train] batch 400/7649 | loss 0.9597 | acc 0.3377
09:57:47 [train] batch 600/7649 | loss 0.9593 | acc 0.3375
09:57:51 [train] batch 800/7649 | loss 0.9591 | acc 0.3380
09:57:54 [train] batch 1000/7649 | loss 0.9593 | acc 0.3375
09:57:57 [train] batch 1200/7649 | loss 0.9591 | acc 0.3375
09:58:01 [train] batch 1400/7649 | loss 0.9589 | acc 0.3378
09:58:04 [train] batch 1600/7649 | loss 0.9589 | acc 0.3378
09:58:07 [train] batch 1800/7649 | loss 0.9587 | acc 0.3380
09:58:11 [train] batch 2000/7649 | loss 0.9588 | acc 0.3379
09:58:14 [train] batch 2200/7649 | loss 0.9586 | acc 0.3382
09:58:17 [train] batch 2400/7649 | loss 0.9589 | acc 0.3380
09:58:21 [train] batch 2600/7649 | loss 0.9588 | acc 0.3381
09:58:24 [train] batch 2800/7649 | loss 0.9588 | acc 0.3381
09:58:27 [train] batch 3000/7649 | loss 0.9589 | acc 0.3381
09:58:30 [train] batch 3200/7649 | loss 0.9590 | acc 0.3380
09:58:34 [train] batch 3400/7649 | loss 0.9589 | acc 0.3381
09:58:37 [train] batch 3600/7649 | loss 0.9588 | acc 0.3382
09:58:40 [train] batch 3800/7649 | loss 0.9588 | acc 0.3383
09:58:44 [train] batch 4000/7649 | loss 0.9587 | acc 0.3384
09:58:47 [train] batch 4200/7649 | loss 0.9586 | acc 0.3385
09:58:50 [train] batch 4400/7649 | loss 0.9587 | acc 0.3386
09:58:53 [train] batch 4600/7649 | loss 0.9587 | acc 0.3386
09:58:57 [train] batch 4800/7649 | loss 0.9586 | acc 0.3387
09:59:00 [train] batch 5000/7649 | loss 0.9586 | acc 0.3387
09:59:03 [train] batch 5200/7649 | loss 0.9586 | acc 0.3387
09:59:07 [train] batch 5400/7649 | loss 0.9587 | acc 0.3386
09:59:10 [train] batch 5600/7649 | loss 0.9586 | acc 0.3386
09:59:13 [train] batch 5800/7649 | loss 0.9586 | acc 0.3387
09:59:17 [train] batch 6000/7649 | loss 0.9586 | acc 0.3386
09:59:20 [train] batch 6200/7649 | loss 0.9586 | acc 0.3385
09:59:23 [train] batch 6400/7649 | loss 0.9586 | acc 0.3386
09:59:27 [train] batch 6600/7649 | loss 0.9586 | acc 0.3387
09:59:30 [train] batch 6800/7649 | loss 0.9586 | acc 0.3386
09:59:34 [train] batch 7000/7649 | loss 0.9586 | acc 0.3386
09:59:37 [train] batch 7200/7649 | loss 0.9586 | acc 0.3386
09:59:41 [train] batch 7400/7649 | loss 0.9586 | acc 0.3386
09:59:44 [train] batch 7600/7649 | loss 0.9586 | acc 0.3386
09:59:45 [train] batch 7649/7649 | loss 0.9585 | acc 0.3387
09:59:52 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_17.png
09:59:52 Epoch 17 | train 0.9585/0.3387 | val 0.9435/0.3507 | lr 1.25e-06
09:59:55 [train] batch 200/7649 | loss 0.9581 | acc 0.3386
09:59:59 [train] batch 400/7649 | loss 0.9580 | acc 0.3391
10:00:02 [train] batch 600/7649 | loss 0.9574 | acc 0.3400
10:00:05 [train] batch 800/7649 | loss 0.9581 | acc 0.3389
10:00:09 [train] batch 1000/7649 | loss 0.9585 | acc 0.3385
10:00:12 [train] batch 1200/7649 | loss 0.9585 | acc 0.3385
10:00:16 [train] batch 1400/7649 | loss 0.9586 | acc 0.3385
10:00:19 [train] batch 1600/7649 | loss 0.9587 | acc 0.3382
10:00:22 [train] batch 1800/7649 | loss 0.9588 | acc 0.3380
10:00:26 [train] batch 2000/7649 | loss 0.9587 | acc 0.3380
10:00:30 [train] batch 2200/7649 | loss 0.9587 | acc 0.3381
10:00:33 [train] batch 2400/7649 | loss 0.9588 | acc 0.3379
10:00:36 [train] batch 2600/7649 | loss 0.9588 | acc 0.3380
10:00:40 [train] batch 2800/7649 | loss 0.9588 | acc 0.3380
10:00:43 [train] batch 3000/7649 | loss 0.9588 | acc 0.3382
10:00:46 [train] batch 3200/7649 | loss 0.9588 | acc 0.3381
10:00:50 [train] batch 3400/7649 | loss 0.9588 | acc 0.3381
10:00:53 [train] batch 3600/7649 | loss 0.9587 | acc 0.3382
10:00:56 [train] batch 3800/7649 | loss 0.9587 | acc 0.3383
10:01:00 [train] batch 4000/7649 | loss 0.9588 | acc 0.3382
10:01:03 [train] batch 4200/7649 | loss 0.9588 | acc 0.3383
10:01:07 [train] batch 4400/7649 | loss 0.9588 | acc 0.3384
10:01:10 [train] batch 4600/7649 | loss 0.9587 | acc 0.3385
10:01:13 [train] batch 4800/7649 | loss 0.9587 | acc 0.3386
10:01:17 [train] batch 5000/7649 | loss 0.9587 | acc 0.3386
10:01:20 [train] batch 5200/7649 | loss 0.9587 | acc 0.3386
10:01:23 [train] batch 5400/7649 | loss 0.9587 | acc 0.3386
10:01:27 [train] batch 5600/7649 | loss 0.9587 | acc 0.3385
10:01:30 [train] batch 5800/7649 | loss 0.9586 | acc 0.3384
10:01:33 [train] batch 6000/7649 | loss 0.9586 | acc 0.3384
10:01:37 [train] batch 6200/7649 | loss 0.9587 | acc 0.3383
10:01:40 [train] batch 6400/7649 | loss 0.9586 | acc 0.3383
10:01:44 [train] batch 6600/7649 | loss 0.9587 | acc 0.3383
10:01:47 [train] batch 6800/7649 | loss 0.9586 | acc 0.3384
10:01:50 [train] batch 7000/7649 | loss 0.9586 | acc 0.3383
10:01:54 [train] batch 7200/7649 | loss 0.9586 | acc 0.3383
10:01:57 [train] batch 7400/7649 | loss 0.9586 | acc 0.3384
10:02:00 [train] batch 7600/7649 | loss 0.9585 | acc 0.3385
10:02:01 [train] batch 7649/7649 | loss 0.9585 | acc 0.3385
10:02:08 ✔ saved validation confusion matrix → confusion_val/run_20250524_092120/epoch_18.png
10:02:08 Epoch 18 | train 0.9585/0.3385 | val 0.9434/0.3501 | lr 1.25e-06
10:02:08 Early-stop
10:02:09 [eval ] batch 200/2185 | loss 0.9640 | acc 0.3364
10:02:10 [eval ] batch 400/2185 | loss 0.9485 | acc 0.3487
10:02:11 [eval ] batch 600/2185 | loss 0.9456 | acc 0.3500
10:02:12 [eval ] batch 800/2185 | loss 0.9474 | acc 0.3482
10:02:13 [eval ] batch 1000/2185 | loss 0.9475 | acc 0.3478
10:02:14 [eval ] batch 1200/2185 | loss 0.9460 | acc 0.3487
10:02:15 [eval ] batch 1400/2185 | loss 0.9468 | acc 0.3475
10:02:16 [eval ] batch 1600/2185 | loss 0.9468 | acc 0.3474
10:02:18 [eval ] batch 1800/2185 | loss 0.9472 | acc 0.3468
10:02:19 [eval ] batch 2000/2185 | loss 0.9473 | acc 0.3460
10:02:20 [eval ] batch 2185/2185 | loss 0.9469 | acc 0.3463
10:02:20 TEST loss/acc 0.9469/0.3463
10:02:32 Confusion matrix saved ➜ confusion_matrix.png

weight 改变 2:0.5
/data4/private/rmy/hw/confusion_val/run_20250524_092120