# 回测笔记

## infer_result

- example.csv应该是三标签，并且类别均衡
- example1.csv标签不均衡，应该是02标签添加了1.5倍的权重
- example_bin1.csv是二分类，没有额外权重
- big_004530是增大后的测试数据集（20MB）
- middle_004530是采用不均匀标签训练模型，在中等测试集上的结果
- middle_204822是采用均匀标签训练模型，在中等测试集上的结果
- big_1-02_105510是将02归为一类，1作为另外一类，在大测试集上的结果
- big_230741和example1对应的是同一个checkpoint，只不过更换了更大的测试集
- big_204822和example对应的是同一个checkpoint，只不过更换了更大的测试集
- big_161224是使用了新的FocusAcc之后的checkpoint
- big_214403:不均匀标签,30~50%数据,训练一轮之后损失函数变成软混淆矩阵*0.95+交叉熵*0.05,软混淆矩阵更新为:
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)
- bigbal_105230：均匀标签,30~50%数据,训练一轮之后损失函数变成软混淆矩阵*0.95+交叉熵*0.05,软混淆矩阵更新为:
  _ = cm[0,0] + cm[2,2]
  P0 = cm[0,1] + cm[0,2] * 2.0 + cm[0,0]
  P2 = cm[2,0] * 2.0 + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)
- bigbal_134843：均匀标签,30~50%数据,训练一轮之后损失函数变成软混淆矩阵*0.95+交叉熵*0.05,软混淆矩阵更新为:
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)

## 单独回测结果

- example是比较好的，目前来看平均pnl最高的是20250531_004640对应的，平均pnl为3.56
- example1由于标签不平衡的问题，不如前一个，目前来看平均pnl最高的应该是20250531_105958对应的，平均pnl为2.31

## 多模型投票回测结果

- example和example1来投票，最好的结果是20250531_111727对应的，平均pnl是3.95
- example1和example_bin1来投票，最好的结果是20250531_115044对应的，平均pnl是3.34
- 上述结论基本表明，两个三分类器投票结果要比三分类+二分类要好，这个结果不难解释。可以看到当三分类器阈值较高的时候，二分类几乎不再对结果产生贡献，因为不均衡三分类当中，预测为2实际为1的，很可能是小涨，2分类器很容易将其分类为1，因此二分类器加三分类器没有用
- middle_004530和middle_204822两个投票的结果屠榜了，平均pnl是4.50，对应的时间段是20250601_014143
- big_1-02_105510和big_230741投出来的烂如J，最高平均pnl不超过1.5
- 接下来应该可以用大数据集，一个是不均匀标签训练出来的，一个是均匀标签训练出来的

## follow数据集

- follow_134843：均匀标签,30~50%数据,训练一轮之后损失函数变成软混淆矩阵*0.95+交叉熵*0.05,软混淆矩阵更新为:
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)
- follow_214403：不均匀标签,30~50%数据,训练一轮之后损失函数变成软混淆矩阵*0.95+交叉熵*0.05,软混淆矩阵更新为:
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)
- follow_141202：均匀标签,30~50%数据,交叉熵损失
- follow_144455：不均匀标签,30~50%数据,交叉熵损失
- follow_155307：均匀标签,2~5训练,14-15验证,17-18测试,软混淆目标如下
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)
- follow_162953：不均匀标签,2~5训练,14-15验证,17-18测试,软混淆目标如下
  _ = cm[0,0] + cm[2,2] - cm[2,0] * 1.1 - cm[0,2] * 1.1 - cm[0,1] * 0.1 - cm[2,1] * 0.1
  P0 = cm[0,1] + cm[0,2] + cm[0,0]
  P2 = cm[2,0] + cm[2,1] + cm[2,2]
  acc02 = _ / (P0 + P2 + self.eps)

## follow数据集回测的结果
